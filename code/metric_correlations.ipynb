{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f22a5e1e",
   "metadata": {},
   "source": [
    "# Metric correlation analysis (Spearman)\n",
    "\n",
    "This notebook produces the **pairwise Spearman rank correlations** between the geometric metrics used in the paper and saves:\n",
    "\n",
    "- `spearman_corr.csv` (correlation coefficients)\n",
    "- `spearman_pvals.csv` (p-values)\n",
    "- `spearman_corr_with_stars.csv` (pretty table with significance stars)\n",
    "- `metric_correlation_heatmap.pdf` (figure)\n",
    "\n",
    "**Input:** a `metric_points.csv` file (one row = one random subsample / “point”; columns = metric values).  \n",
    "The notebook is intentionally lightweight: it does *not* re-embed a model unless you want it to.\n",
    "\n",
    "> Tip: if your `metric_points.csv` contains multiple sample sizes (column `n`), set `N_FILTER` below to select one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a7b2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# seaborn is optional; matplotlib-only also works\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    _HAS_SNS = True\n",
    "except Exception:\n",
    "    _HAS_SNS = False\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# -------------------- paths --------------------\n",
    "# Point this to your exported metric points\n",
    "POINTS_CSV = Path(\"metric_points.csv\")  # <- change if needed\n",
    "\n",
    "OUT_DIR = Path(\"outputs\") / \"metric_correlations\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# -------------------- filtering --------------------\n",
    "# If your file contains multiple values of n (subsample size), set N_FILTER to an int (e.g., 2000).\n",
    "# Otherwise leave as None.\n",
    "N_FILTER = None\n",
    "\n",
    "# -------------------- plot style --------------------\n",
    "AXIS_FONTSIZE = 12\n",
    "TICK_FONTSIZE = 10\n",
    "TITLE_FONTSIZE = 12\n",
    "\n",
    "HEATMAP_FIGSIZE = (10, 8)   # adjust for number of metrics\n",
    "HEATMAP_VMIN, HEATMAP_VMAX = -1.0, 1.0\n",
    "\n",
    "print(\"POINTS_CSV:\", POINTS_CSV.resolve())\n",
    "print(\"OUT_DIR   :\", OUT_DIR.resolve())\n",
    "print(\"seaborn   :\", _HAS_SNS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acef1e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- load metric points --------------------\n",
    "assert POINTS_CSV.exists(), f\"Could not find {POINTS_CSV} (set POINTS_CSV to the right path).\"\n",
    "\n",
    "points = pd.read_csv(POINTS_CSV)\n",
    "\n",
    "# Optional: if a point_id column exists, make it the index\n",
    "for idx_col in [\"point_id\", \"id\"]:\n",
    "    if idx_col in points.columns:\n",
    "        points = points.set_index(idx_col)\n",
    "        break\n",
    "\n",
    "# If your generator wrote an 'n' column, optionally filter by n\n",
    "if \"n\" in points.columns:\n",
    "    uniq_n = sorted(points[\"n\"].dropna().unique().tolist())\n",
    "    print(\"n values in file:\", uniq_n)\n",
    "    if N_FILTER is not None:\n",
    "        points = points[points[\"n\"] == int(N_FILTER)].copy()\n",
    "        print(\"Filtered to n =\", N_FILTER, \"-> rows:\", len(points))\n",
    "    else:\n",
    "        # if multiple n exist and N_FILTER is None, keep all rows but warn\n",
    "        if len(uniq_n) > 1:\n",
    "            print(\"Warning: multiple n present. Consider setting N_FILTER to avoid mixing scales.\")\n",
    "\n",
    "print(\"rows:\", len(points), \"cols:\", len(points.columns))\n",
    "points.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba18109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- metric name cleanup --------------------\n",
    "# These are *display* names used in the plot/table. They don't change your raw data.\n",
    "RENAME_METRICS = {\n",
    "    # PCA naming\n",
    "    \"PCA\": \"PCA@99\",\n",
    "    \"pca\": \"PCA@99\",\n",
    "    \"pca99\": \"PCA@99\",\n",
    "    \"PCA (99%)\": \"PCA@99\",\n",
    "\n",
    "    # skdim lPCA global-fit labels (your usage) -> clearer names\n",
    "    \"lpca99\": \"PCA@99\",\n",
    "    \"lpca95\": \"PCA@95\",\n",
    "    \"lpca\": \"PCA FO\",  # FO rule / eigen-threshold variant\n",
    "    \"lPCA\": \"PCA FO\",\n",
    "    \"lPCA FO\": \"PCA FO\",\n",
    "    \"Local PCA (lPCA FO)\": \"PCA FO\",\n",
    "\n",
    "    # cosmetics\n",
    "    \"vmf_kappa\": \"vMF κ\",\n",
    "    \"iso\": \"IsoScore\",\n",
    "    \"sf\": \"Spectral flatness\",\n",
    "    \"erank\": \"Effective rank\",\n",
    "    \"pr\": \"Participation ratio\",\n",
    "    \"stable_rank\": \"Stable rank\",\n",
    "    \"twonn\": \"TwoNN\",\n",
    "    \"gride\": \"GRIDE\",\n",
    "    \"corrint\": \"CorrInt\",\n",
    "    \"fishers\": \"FisherS\",\n",
    "    \"mom\": \"MOM\",\n",
    "    \"tle\": \"TLE\",\n",
    "    \"mle\": \"MLE\",\n",
    "    \"ess\": \"ESS\",\n",
    "    \"mada\": \"MADA\",\n",
    "    \"knn\": \"KNN\",\n",
    "}\n",
    "\n",
    "points = points.rename(columns={c: RENAME_METRICS.get(c, c) for c in points.columns})\n",
    "\n",
    "# Keep only numeric columns that look like metrics (drop metadata columns if present)\n",
    "META_COLS = {\"n\", \"N\", \"seed\", \"layer\", \"layer_idx\", \"model\", \"subset\", \"class\"}\n",
    "metric_cols = [c for c in points.columns if c not in META_COLS and pd.api.types.is_numeric_dtype(points[c])]\n",
    "\n",
    "metrics = points[metric_cols].copy()\n",
    "\n",
    "# Drop all-NaN metrics\n",
    "all_nan = [c for c in metrics.columns if metrics[c].isna().all()]\n",
    "if all_nan:\n",
    "    print(\"Dropping all-NaN metrics:\", all_nan)\n",
    "    metrics = metrics.drop(columns=all_nan)\n",
    "\n",
    "print(\"Using metric columns:\", list(metrics.columns))\n",
    "metrics.describe().T[[\"count\",\"mean\",\"std\",\"min\",\"max\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cea2d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- metric ordering / families --------------------\n",
    "ISO_METRICS = [\"IsoScore\", \"Spectral flatness\", \"vMF κ\"]\n",
    "\n",
    "LINEAR_ID_METRICS = [\n",
    "    \"Effective rank\",\n",
    "    \"Participation ratio\",\n",
    "    \"Stable rank\",\n",
    "    \"PCA FO\",\n",
    "    \"PCA@95\",\n",
    "    \"PCA@99\",\n",
    "]\n",
    "\n",
    "NONLINEAR_ID_METRICS = [\n",
    "    \"TwoNN\",\n",
    "    \"GRIDE\",\n",
    "    \"CorrInt\",\n",
    "    \"FisherS\",\n",
    "    \"MLE\",\n",
    "    \"MOM\",\n",
    "    \"TLE\",\n",
    "    \"ESS\",\n",
    "    \"MADA\",\n",
    "    \"KNN\",\n",
    "]\n",
    "\n",
    "# Keep only those present (so the notebook doesn't break if you didn't compute some estimators)\n",
    "def _keep_present(order, cols):\n",
    "    return [m for m in order if m in cols]\n",
    "\n",
    "iso_order = _keep_present(ISO_METRICS, metrics.columns)\n",
    "lin_order = _keep_present(LINEAR_ID_METRICS, metrics.columns)\n",
    "nl_order  = _keep_present(NONLINEAR_ID_METRICS, metrics.columns)\n",
    "\n",
    "ORDER = iso_order + lin_order + nl_order + [c for c in metrics.columns if c not in (set(iso_order)|set(lin_order)|set(nl_order))]\n",
    "\n",
    "metrics = metrics[ORDER]\n",
    "\n",
    "print(\"Order used (len=%d):\" % len(ORDER))\n",
    "print(ORDER)\n",
    "\n",
    "# handy for drawing separators\n",
    "CUTS = {\n",
    "    \"iso_end\": len(iso_order),\n",
    "    \"lin_end\": len(iso_order) + len(lin_order),\n",
    "    \"nl_end\":  len(iso_order) + len(lin_order) + len(nl_order),\n",
    "}\n",
    "CUTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328d1713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Spearman correlation (pairwise with NaN handling) --------------------\n",
    "def spearman_pairwise(df: pd.DataFrame):\n",
    "    cols = list(df.columns)\n",
    "    k = len(cols)\n",
    "    corr = np.full((k, k), np.nan, dtype=float)\n",
    "    pval = np.full((k, k), np.nan, dtype=float)\n",
    "    nobs = np.zeros((k, k), dtype=int)\n",
    "\n",
    "    for i, a in enumerate(cols):\n",
    "        for j, b in enumerate(cols):\n",
    "            if j < i:\n",
    "                continue\n",
    "            x = df[a].to_numpy(dtype=float)\n",
    "            y = df[b].to_numpy(dtype=float)\n",
    "            m = np.isfinite(x) & np.isfinite(y)\n",
    "            n = int(m.sum())\n",
    "            nobs[i, j] = nobs[j, i] = n\n",
    "            if n < 3:\n",
    "                continue\n",
    "            r, p = spearmanr(x[m], y[m])\n",
    "            corr[i, j] = corr[j, i] = float(r)\n",
    "            pval[i, j] = pval[j, i] = float(p)\n",
    "\n",
    "    corr_df = pd.DataFrame(corr, index=cols, columns=cols)\n",
    "    pval_df = pd.DataFrame(pval, index=cols, columns=cols)\n",
    "    nobs_df = pd.DataFrame(nobs, index=cols, columns=cols)\n",
    "    return corr_df, pval_df, nobs_df\n",
    "\n",
    "corr, pval, nobs = spearman_pairwise(metrics)\n",
    "\n",
    "print(\"Computed correlations for\", corr.shape[0], \"metrics.\")\n",
    "corr.iloc[:5, :5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b97423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- significance stars + save tables --------------------\n",
    "def p_to_stars(p: float) -> str:\n",
    "    if not np.isfinite(p):\n",
    "        return \"\"\n",
    "    if p < 1e-3:\n",
    "        return \"***\"\n",
    "    if p < 1e-2:\n",
    "        return \"**\"\n",
    "    if p < 5e-2:\n",
    "        return \"*\"\n",
    "    return \"\"\n",
    "\n",
    "stars = pval.applymap(p_to_stars)\n",
    "\n",
    "# pretty table: \"0.87***\"\n",
    "corr_star = corr.copy()\n",
    "for r in corr_star.index:\n",
    "    for c in corr_star.columns:\n",
    "        if np.isfinite(corr_star.loc[r, c]):\n",
    "            corr_star.loc[r, c] = f\"{corr_star.loc[r, c]:.2f}{stars.loc[r, c]}\"\n",
    "        else:\n",
    "            corr_star.loc[r, c] = \"\"\n",
    "\n",
    "# save\n",
    "corr.to_csv(OUT_DIR / \"spearman_corr.csv\")\n",
    "pval.to_csv(OUT_DIR / \"spearman_pvals.csv\")\n",
    "nobs.to_csv(OUT_DIR / \"spearman_nobs.csv\")\n",
    "corr_star.to_csv(OUT_DIR / \"spearman_corr_with_stars.csv\")\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" \", OUT_DIR / \"spearman_corr.csv\")\n",
    "print(\" \", OUT_DIR / \"spearman_pvals.csv\")\n",
    "print(\" \", OUT_DIR / \"spearman_nobs.csv\")\n",
    "print(\" \", OUT_DIR / \"spearman_corr_with_stars.csv\")\n",
    "\n",
    "corr_star.iloc[:8, :8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d3235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- plot heatmap --------------------\n",
    "# Use seaborn if available (nicer labels); otherwise fallback to matplotlib.\n",
    "heat_df = corr.copy()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=HEATMAP_FIGSIZE)\n",
    "\n",
    "if _HAS_SNS:\n",
    "    sns.set_style(\"white\")\n",
    "    sns.heatmap(\n",
    "        heat_df,\n",
    "        vmin=HEATMAP_VMIN, vmax=HEATMAP_VMAX,\n",
    "        cmap=\"coolwarm\",\n",
    "        square=True,\n",
    "        linewidths=0.5,\n",
    "        cbar_kws={\"label\": \"Spearman $\\rho$\"},\n",
    "        ax=ax,\n",
    "    )\n",
    "else:\n",
    "    im = ax.imshow(\n",
    "        heat_df.to_numpy(),\n",
    "        vmin=HEATMAP_VMIN, vmax=HEATMAP_VMAX,\n",
    "        cmap=\"coolwarm\",\n",
    "        aspect=\"equal\",\n",
    "    )\n",
    "    fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04, label=\"Spearman $\\rho$\")\n",
    "    ax.set_xticks(np.arange(len(heat_df.columns)))\n",
    "    ax.set_yticks(np.arange(len(heat_df.index)))\n",
    "    ax.set_xticklabels(heat_df.columns)\n",
    "    ax.set_yticklabels(heat_df.index)\n",
    "\n",
    "ax.set_title(\"Metric correlations (Spearman)\", fontsize=TITLE_FONTSIZE)\n",
    "\n",
    "ax.tick_params(axis=\"x\", labelsize=TICK_FONTSIZE, rotation=45, ha=\"right\")\n",
    "ax.tick_params(axis=\"y\", labelsize=TICK_FONTSIZE)\n",
    "\n",
    "# family separators (if we have at least 2 families present)\n",
    "for cut in [CUTS[\"iso_end\"], CUTS[\"lin_end\"], CUTS[\"nl_end\"]]:\n",
    "    if 0 < cut < len(heat_df.columns):\n",
    "        ax.axhline(cut, color=\"black\", linewidth=1.2)\n",
    "        ax.axvline(cut, color=\"black\", linewidth=1.2)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(OUT_DIR / \"metric_correlation_heatmap.pdf\", bbox_inches=\"tight\")\n",
    "fig.savefig(OUT_DIR / \"metric_correlation_heatmap.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" \", OUT_DIR / \"metric_correlation_heatmap.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b6e616",
   "metadata": {},
   "source": [
    "### Optional: inspect strongest (absolute) correlations\n",
    "\n",
    "This is sometimes useful to sanity-check that metrics that are supposed to be related (e.g., different spectrum-based proxies) actually cluster together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b680e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the top |rho| off-diagonal pairs\n",
    "pairs = []\n",
    "cols = list(corr.columns)\n",
    "for i in range(len(cols)):\n",
    "    for j in range(i+1, len(cols)):\n",
    "        r = corr.iloc[i, j]\n",
    "        if np.isfinite(r):\n",
    "            pairs.append((abs(r), r, cols[i], cols[j], int(nobs.iloc[i, j])))\n",
    "\n",
    "pairs = sorted(pairs, reverse=True)\n",
    "pd.DataFrame(pairs[:25], columns=[\"abs_rho\", \"rho\", \"metric_a\", \"metric_b\", \"n_obs\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
