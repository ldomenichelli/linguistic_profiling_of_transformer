{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f4e07b0-805d-41d9-9b32-0fa7321f4f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: en_ewt-ud-train_sentences.csv\n",
      "Expanded to 194,916 token rows (POS present for 100.0% of tokens).\n",
      "\n",
      "Per‑POS summary (top values and percentages):\n",
      "      pos  n_tokens  n_types  top_index  top_index_pct  top_length  top_length_pct  top_head_dist  top_head_dist_pct top_relation_type  top_relation_type_pct  \\\n",
      "0    NOUN     33607     6903          6           5.54           4           18.33             -2              18.67               obj                  20.22   \n",
      "1   PUNCT     22123       94         10           4.48           1           96.14             -1              15.46             punct                 100.00   \n",
      "2    VERB     22095     3538          3           8.07           4           27.70              0              30.91              root                  30.91   \n",
      "3    PRON     18255      138          1          18.33           2           26.52              1              37.16             nsubj                  55.28   \n",
      "4     ADP     17557      116          6           6.01           2           64.49              2              34.57              case                  92.33   \n",
      "5     DET     16123       36          1           7.35           3           60.41              1              57.10               det                  96.52   \n",
      "6     ADJ     12648     2156          4           6.19           4           22.45              1              52.92              amod                  68.24   \n",
      "7     AUX     11526       90          2          14.86           2           31.25              1              46.55               aux                  51.22   \n",
      "8   PROPN     11203     3808          1           6.47           5           17.75              1              22.98          compound                  20.15   \n",
      "9     ADV      9913      716          1           8.59           4           36.17              1              39.39            advmod                  93.20   \n",
      "10  CCONJ      6627       21          7           5.93           3           86.27              1              43.40                cc                  98.25   \n",
      "11   PART      4241        7          4           8.32           2           76.85              1              81.66              mark                  76.42   \n",
      "12  SCONJ      3815       62          1          11.66           2           40.58              2              24.25              mark                  98.43   \n",
      "13    NUM      3675      728          1           8.49           3           22.67              1              29.33            nummod                  41.06   \n",
      "14    SYM       651       38          1           9.37           1           87.40              1              37.02                cc                  21.04   \n",
      "15   INTJ       556       66          1          50.54           6           45.14              1              39.57         discourse                  95.50   \n",
      "16      X       301      154          4           9.63           4           17.28             -1              27.57              flat                  48.17   \n",
      "\n",
      "    top_arity  top_arity_pct  \n",
      "0           2          27.81  \n",
      "1           0         100.00  \n",
      "2           3          27.54  \n",
      "3           0          89.92  \n",
      "4           0          99.09  \n",
      "5           0          98.18  \n",
      "6           0          65.24  \n",
      "7           0          98.13  \n",
      "8           0          46.26  \n",
      "9           0          85.62  \n",
      "10          0          99.26  \n",
      "11          0          99.15  \n",
      "12          0          98.56  \n",
      "13          0          56.35  \n",
      "14          0          49.92  \n",
      "15          0          94.78  \n",
      "16          0          85.71  \n",
      "\n",
      "✓ Saved summary to /home/ldomenichelli/geometric_profiling_of_a_neural_language_model/pos_summary.csv\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import ast\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# =========================== CONFIG ===========================\n",
    "# Point to your CSV. If you uploaded via notebook, /mnt/data is common.\n",
    "CSV_PATH = os.getenv(\"CSV_PATH\", \"en_ewt-ud-train_sentences.csv\")\n",
    "\n",
    "# Set True to drop sentence-initial tokens (word_id == 0) from all stats\n",
    "EXCLUDE_SENT_START = False\n",
    "\n",
    "# Where to save the summary table\n",
    "OUT_CSV = Path(\"pos_summary.csv\")\n",
    "\n",
    "\n",
    "# ======================== SMALL HELPERS =======================\n",
    "def _to_list(x):\n",
    "    \"\"\"Parse list-like strings to Python lists; leave lists as-is.\"\"\"\n",
    "    if isinstance(x, str) and x.startswith(\"[\"):\n",
    "        return ast.literal_eval(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def _pick_col(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:\n",
    "    \"\"\"Return the first column from candidates that exists in df, else None.\"\"\"\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "\n",
    "def _mode_and_pct(series: pd.Series, denom: int) -> Tuple[Optional[object], float, int]:\n",
    "    \"\"\"Return (most_frequent_value, pct_of_pos, count). If empty -> (None, 0.0, 0).\"\"\"\n",
    "    s = series.dropna()\n",
    "    if s.empty or denom == 0:\n",
    "        return None, 0.0, 0\n",
    "    vc = s.value_counts()\n",
    "    top_val = vc.index[0]\n",
    "    top_n = int(vc.iloc[0])\n",
    "    pct = 100.0 * top_n / float(denom)\n",
    "    return top_val, pct, top_n\n",
    "\n",
    "\n",
    "# ====================== LOADING & EXPANSION ====================\n",
    "def expand_to_tokens(\n",
    "    csv_path: str,\n",
    "    exclude_sent_start: bool = EXCLUDE_SENT_START,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read sentence-level rows and expand to token-level rows with columns:\n",
    "      sentence_id, word_id, word, pos, index, length, head_dist, relation_type, arity\n",
    "    Nonexistent columns are filled with NaN.\n",
    "    \"\"\"\n",
    "    df_all = pd.read_csv(csv_path)\n",
    "\n",
    "    sid_col   = _pick_col(df_all, [\"sentence_id\", \"sent_id\", \"sid\", \"SentenceID\"])\n",
    "    tok_col   = _pick_col(df_all, [\"tokens\", \"Tokens\", \"words\", \"Words\"])\n",
    "    pos_col   = _pick_col(df_all, [\"pos\", \"upos\", \"POS\", \"Pos\"])\n",
    "    idx_col   = _pick_col(df_all, [\"index\", \"token_index\", \"position\", \"positions\", \"idx\"])\n",
    "    hd_col    = _pick_col(df_all, [\"head_dist\", \"head_distance\", \"dep_head_dist\", \"gov_dist\"])\n",
    "    rel_col   = _pick_col(df_all, [\"relation_type\", \"deprel\", \"typed_dependency\", \"relation\", \"ud_rel\", \"rel\"])\n",
    "    arity_col = _pick_col(df_all, [\"arity\", \"ariety\", \"ARITY\"])\n",
    "\n",
    "    # Minimal required columns\n",
    "    missing = [name for name, col in dict(sentence_id=sid_col, tokens=tok_col, pos=pos_col).items() if col is None]\n",
    "    if missing:\n",
    "        raise ValueError(\n",
    "            f\"Missing required columns: {missing}. \"\n",
    "            f\"Found columns: {list(df_all.columns)[:20]}...\"\n",
    "        )\n",
    "\n",
    "    keep = [sid_col, tok_col, pos_col] + [c for c in [idx_col, hd_col, rel_col, arity_col] if c]\n",
    "    df = df_all[keep].copy()\n",
    "\n",
    "    # Normalize dtypes / parse lists\n",
    "    df[sid_col]   = df[sid_col].astype(str, copy=False)\n",
    "    df[tok_col]   = df[tok_col].apply(_to_list)\n",
    "    df[pos_col]   = df[pos_col].apply(_to_list)\n",
    "    if idx_col:   df[idx_col]   = df[idx_col].apply(_to_list)\n",
    "    if hd_col:    df[hd_col]    = df[hd_col].apply(_to_list)\n",
    "    if rel_col:   df[rel_col]   = df[rel_col].apply(_to_list)\n",
    "    if arity_col: df[arity_col] = df[arity_col].apply(_to_list)\n",
    "\n",
    "    rows = []\n",
    "    for row in df.itertuples(index=False):\n",
    "        sid  = getattr(row, sid_col)\n",
    "        toks = getattr(row, tok_col)\n",
    "        posl = getattr(row, pos_col)\n",
    "        idxl = getattr(row, idx_col) if idx_col else None\n",
    "        hdl  = getattr(row, hd_col)  if hd_col  else None\n",
    "        rell = getattr(row, rel_col) if rel_col else None\n",
    "        arl  = getattr(row, arity_col) if arity_col else None\n",
    "\n",
    "        # Align lengths conservatively\n",
    "        L = min(len(toks), len(posl))\n",
    "        if idxl is not None: L = min(L, len(idxl))\n",
    "        if hdl  is not None: L = min(L, len(hdl))\n",
    "        if rell is not None: L = min(L, len(rell))\n",
    "        if arl  is not None: L = min(L, len(arl))\n",
    "\n",
    "        for wid in range(L):\n",
    "            if exclude_sent_start and wid == 0:\n",
    "                continue\n",
    "\n",
    "            token = toks[wid]\n",
    "            pos   = str(posl[wid]).upper() if posl[wid] is not None else None\n",
    "            index = idxl[wid] if idxl is not None else np.nan\n",
    "            hd    = hdl[wid]  if hdl  is not None else np.nan\n",
    "            rel   = rell[wid] if rell is not None else np.nan\n",
    "            arity = arl[wid]  if arl  is not None else np.nan\n",
    "\n",
    "            # NEW: character length of the surface token\n",
    "            length = len(str(token))\n",
    "\n",
    "            rows.append((sid, wid, token, pos, index, length, hd, rel, arity))\n",
    "\n",
    "    tok_df = pd.DataFrame(\n",
    "        rows,\n",
    "        columns=[\n",
    "            \"sentence_id\", \"word_id\", \"word\", \"pos\",\n",
    "            \"index\", \"length\", \"head_dist\", \"relation_type\", \"arity\"\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Normalize token text for type counting\n",
    "    tok_df[\"word_norm\"] = tok_df[\"word\"].astype(str).str.casefold()\n",
    "    return tok_df\n",
    "\n",
    "\n",
    "# ====================== PER‑POS SUMMARY LOGIC ===================\n",
    "def build_pos_summary(tokens_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if \"pos\" not in tokens_df.columns:\n",
    "        raise ValueError(\"Expanded token frame has no 'pos' column; check inputs.\")\n",
    "\n",
    "    records = []\n",
    "    for pos, g in tokens_df.groupby(\"pos\", dropna=True):\n",
    "        n_tokens = len(g)\n",
    "        n_types  = g[\"word_norm\"].nunique()\n",
    "\n",
    "        top_index,  pct_index,  _ = _mode_and_pct(g[\"index\"],        denom=n_tokens) if \"index\"        in g else (None, 0.0, 0)\n",
    "        top_length, pct_length, _ = _mode_and_pct(g[\"length\"],       denom=n_tokens) if \"length\"       in g else (None, 0.0, 0)\n",
    "        top_hd,     pct_hd,     _ = _mode_and_pct(g[\"head_dist\"],    denom=n_tokens) if \"head_dist\"    in g else (None, 0.0, 0)\n",
    "        top_rel,    pct_rel,    _ = _mode_and_pct(g[\"relation_type\"],denom=n_tokens) if \"relation_type\" in g else (None, 0.0, 0)\n",
    "        top_arity,  pct_arity,  _ = _mode_and_pct(g[\"arity\"],        denom=n_tokens) if \"arity\"        in g else (None, 0.0, 0)\n",
    "\n",
    "        records.append({\n",
    "            \"pos\": pos,\n",
    "            \"n_tokens\": n_tokens,\n",
    "            \"n_types\": n_types,\n",
    "\n",
    "            \"top_index\": top_index,\n",
    "            \"top_index_pct\":  round(pct_index, 2),\n",
    "\n",
    "            \"top_length\": top_length,\n",
    "            \"top_length_pct\": round(pct_length, 2),\n",
    "\n",
    "            \"top_head_dist\": top_hd,\n",
    "            \"top_head_dist_pct\": round(pct_hd, 2),\n",
    "\n",
    "            \"top_relation_type\": top_rel,\n",
    "            \"top_relation_type_pct\": round(pct_rel, 2),\n",
    "\n",
    "            \"top_arity\": top_arity,\n",
    "            \"top_arity_pct\": round(pct_arity, 2),\n",
    "        })\n",
    "\n",
    "    summary = (\n",
    "        pd.DataFrame.from_records(records)\n",
    "        .sort_values([\"n_tokens\", \"pos\"], ascending=[False, True])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    return summary\n",
    "\n",
    "\n",
    "# =============================== MAIN ===============================\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"Reading: {CSV_PATH}\")\n",
    "    df_tokens = expand_to_tokens(CSV_PATH, exclude_sent_start=EXCLUDE_SENT_START)\n",
    "    print(\n",
    "        f\"Expanded to {len(df_tokens):,} token rows \"\n",
    "        f\"(POS present for {df_tokens['pos'].notna().mean()*100:.1f}% of tokens).\"\n",
    "    )\n",
    "\n",
    "    summary = build_pos_summary(df_tokens)\n",
    "    print(\"\\nPer‑POS summary (top values and percentages):\")\n",
    "    with pd.option_context(\"display.max_rows\", None,\n",
    "                           \"display.max_columns\", None,\n",
    "                           \"display.width\", 160):\n",
    "        print(summary)\n",
    "\n",
    "    OUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "    summary.to_csv(OUT_CSV, index=False)\n",
    "    print(f\"\\n✓ Saved summary to {OUT_CSV.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57c04a80-17f0-470b-89cf-6a55c868cf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_index_summary(tokens_df: pd.DataFrame, max_index: int = 10) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build a per-INDEX summary (index ≤ max_index).\n",
    "    \"\"\"\n",
    "    if \"index\" not in tokens_df.columns:\n",
    "        raise ValueError(\"Expanded token frame has no 'index' column; check inputs.\")\n",
    "\n",
    "    # Keep only index values up to max_index\n",
    "    df = tokens_df[tokens_df[\"index\"].notna() & (tokens_df[\"index\"] <= max_index)]\n",
    "\n",
    "    records = []\n",
    "    for idx_val, g in df.groupby(\"index\", dropna=True):\n",
    "        n_tokens = len(g)\n",
    "        n_types  = g[\"word_norm\"].nunique()\n",
    "\n",
    "        top_pos,    pct_pos,    _ = _mode_and_pct(g[\"pos\"], denom=n_tokens)\n",
    "        top_length, pct_length, _ = _mode_and_pct(g[\"length\"], denom=n_tokens)\n",
    "        top_hd,     pct_hd,     _ = _mode_and_pct(g[\"head_dist\"], denom=n_tokens)\n",
    "        top_rel,    pct_rel,    _ = _mode_and_pct(g[\"relation_type\"], denom=n_tokens)\n",
    "        top_arity,  pct_arity,  _ = _mode_and_pct(g[\"arity\"], denom=n_tokens)\n",
    "\n",
    "        records.append({\n",
    "            \"index\": idx_val,\n",
    "            \"n_tokens\": n_tokens,\n",
    "            \"n_types\": n_types,\n",
    "\n",
    "            \"top_pos\": top_pos,\n",
    "            \"top_pos_pct\": round(pct_pos, 2),\n",
    "\n",
    "            \"top_length\": top_length,\n",
    "            \"top_length_pct\": round(pct_length, 2),\n",
    "\n",
    "            \"top_head_dist\": top_hd,\n",
    "            \"top_head_dist_pct\": round(pct_hd, 2),\n",
    "\n",
    "            \"top_relation_type\": top_rel,\n",
    "            \"top_relation_type_pct\": round(pct_rel, 2),\n",
    "\n",
    "            \"top_arity\": top_arity,\n",
    "            \"top_arity_pct\": round(pct_arity, 2),\n",
    "        })\n",
    "\n",
    "    summary = (\n",
    "        pd.DataFrame.from_records(records)\n",
    "        .sort_values([\"index\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    return summary\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d77cb596-86cd-446b-b302-6981b83a150e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: en_ewt-ud-train_sentences.csv\n",
      "Expanded to 194,916 token rows (POS present for 100.0% of tokens).\n",
      "\n",
      "Per‑POS summary (top values and percentages):\n",
      "      pos  n_tokens  n_types  top_index  top_index_pct  top_length  top_length_pct  top_head_dist  top_head_dist_pct top_relation_type  top_relation_type_pct  \\\n",
      "0    NOUN     33607     6903          6           5.54           4           18.33             -2              18.67               obj                  20.22   \n",
      "1   PUNCT     22123       94         10           4.48           1           96.14             -1              15.46             punct                 100.00   \n",
      "2    VERB     22095     3538          3           8.07           4           27.70              0              30.91              root                  30.91   \n",
      "3    PRON     18255      138          1          18.33           2           26.52              1              37.16             nsubj                  55.28   \n",
      "4     ADP     17557      116          6           6.01           2           64.49              2              34.57              case                  92.33   \n",
      "5     DET     16123       36          1           7.35           3           60.41              1              57.10               det                  96.52   \n",
      "6     ADJ     12648     2156          4           6.19           4           22.45              1              52.92              amod                  68.24   \n",
      "7     AUX     11526       90          2          14.86           2           31.25              1              46.55               aux                  51.22   \n",
      "8   PROPN     11203     3808          1           6.47           5           17.75              1              22.98          compound                  20.15   \n",
      "9     ADV      9913      716          1           8.59           4           36.17              1              39.39            advmod                  93.20   \n",
      "10  CCONJ      6627       21          7           5.93           3           86.27              1              43.40                cc                  98.25   \n",
      "11   PART      4241        7          4           8.32           2           76.85              1              81.66              mark                  76.42   \n",
      "12  SCONJ      3815       62          1          11.66           2           40.58              2              24.25              mark                  98.43   \n",
      "13    NUM      3675      728          1           8.49           3           22.67              1              29.33            nummod                  41.06   \n",
      "14    SYM       651       38          1           9.37           1           87.40              1              37.02                cc                  21.04   \n",
      "15   INTJ       556       66          1          50.54           6           45.14              1              39.57         discourse                  95.50   \n",
      "16      X       301      154          4           9.63           4           17.28             -1              27.57              flat                  48.17   \n",
      "\n",
      "    top_arity  top_arity_pct  \n",
      "0           2          27.81  \n",
      "1           0         100.00  \n",
      "2           3          27.54  \n",
      "3           0          89.92  \n",
      "4           0          99.09  \n",
      "5           0          98.18  \n",
      "6           0          65.24  \n",
      "7           0          98.13  \n",
      "8           0          46.26  \n",
      "9           0          85.62  \n",
      "10          0          99.26  \n",
      "11          0          99.15  \n",
      "12          0          98.56  \n",
      "13          0          56.35  \n",
      "14          0          49.92  \n",
      "15          0          94.78  \n",
      "16          0          85.71  \n",
      "\n",
      "✓ Saved POS summary to /home/ldomenichelli/geometric_profiling_of_a_neural_language_model/pos_summary.csv\n",
      "\n",
      "Per‑INDEX summary (top values and percentages):\n",
      "   index  n_tokens  n_types top_pos  top_pos_pct  top_length  top_length_pct  top_head_dist  top_head_dist_pct top_relation_type  top_relation_type_pct  \\\n",
      "0      1     10067     1600    PRON        33.24           3           21.10              1              31.79             nsubj                  32.95   \n",
      "1      2      9647     2309     AUX        17.76           3           20.74              1              33.02              root                  18.01   \n",
      "2      3      9800     2483    VERB        18.20           4           20.05              1              32.01              root                  17.38   \n",
      "3      4      9932     2701    VERB        15.88           4           19.84              1              32.69              root                  14.03   \n",
      "4      5      9948     2876    NOUN        18.69           3           19.14              1              31.39              root                   9.63   \n",
      "5      6      9972     2891    NOUN        18.66           3           18.61              1              30.14              case                  10.00   \n",
      "6      7      9559     2820    NOUN        18.87           3           18.84              1              29.58             punct                   9.93   \n",
      "7      8      9142     2709    NOUN        18.22           3           18.99              1              29.74             punct                  10.75   \n",
      "8      9      8704     2699    NOUN        18.64           3           19.05              1              28.37             punct                  11.35   \n",
      "9     10      8252     2566    NOUN        18.82           3           18.90              1              29.50             punct                  12.02   \n",
      "\n",
      "   top_arity  top_arity_pct  \n",
      "0          0          83.68  \n",
      "1          0          65.37  \n",
      "2          0          62.15  \n",
      "3          0          62.90  \n",
      "4          0          62.78  \n",
      "5          0          64.37  \n",
      "6          0          64.16  \n",
      "7          0          65.38  \n",
      "8          0          64.84  \n",
      "9          0          66.02  \n",
      "✓ Saved INDEX summary to /home/ldomenichelli/geometric_profiling_of_a_neural_language_model/index_summary.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(f\"Reading: {CSV_PATH}\")\n",
    "    df_tokens = expand_to_tokens(CSV_PATH, exclude_sent_start=EXCLUDE_SENT_START)\n",
    "    print(\n",
    "        f\"Expanded to {len(df_tokens):,} token rows \"\n",
    "        f\"(POS present for {df_tokens['pos'].notna().mean()*100:.1f}% of tokens).\"\n",
    "    )\n",
    "    OUT_CSV_INDEX = Path(\"index_summary.csv\")\n",
    "\n",
    "    # --- POS summary ---\n",
    "    pos_summary = build_pos_summary(df_tokens)\n",
    "    print(\"\\nPer‑POS summary (top values and percentages):\")\n",
    "    with pd.option_context(\"display.max_rows\", None,\n",
    "                           \"display.max_columns\", None,\n",
    "                           \"display.width\", 160):\n",
    "        print(pos_summary)\n",
    "\n",
    "    OUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "    pos_summary.to_csv(OUT_CSV, index=False)\n",
    "    print(f\"\\n✓ Saved POS summary to {OUT_CSV.resolve()}\")\n",
    "\n",
    "    # --- INDEX summary ---\n",
    "    index_summary = build_index_summary(df_tokens)\n",
    "    print(\"\\nPer‑INDEX summary (top values and percentages):\")\n",
    "    with pd.option_context(\"display.max_rows\", None,\n",
    "                           \"display.max_columns\", None,\n",
    "                           \"display.width\", 160):\n",
    "        print(index_summary)\n",
    "\n",
    "    OUT_CSV_INDEX.parent.mkdir(parents=True, exist_ok=True)\n",
    "    index_summary.to_csv(OUT_CSV_INDEX, index=False)\n",
    "    print(f\"✓ Saved INDEX summary to {OUT_CSV_INDEX.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4a3270f-8fcc-46ce-bead-b02e4fed597e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_length_summary(tokens_df: pd.DataFrame, max_length: int = 10) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build a per-token-length summary (length ≤ max_length).\n",
    "    Mirrors build_pos_summary and build_index_summary.\n",
    "    \"\"\"\n",
    "\n",
    "    if \"length\" not in tokens_df.columns:\n",
    "        raise ValueError(\"Expanded token frame has no 'length' column; check inputs.\")\n",
    "\n",
    "    # Keep only tokens with length <= max_length\n",
    "    df = tokens_df[tokens_df[\"length\"].notna() & (tokens_df[\"length\"] <= max_length)]\n",
    "\n",
    "    records = []\n",
    "    for L, g in df.groupby(\"length\", dropna=True):\n",
    "        n_tokens = len(g)\n",
    "        n_types  = g[\"word_norm\"].nunique()\n",
    "\n",
    "        top_pos,    pct_pos,    _ = _mode_and_pct(g[\"pos\"], denom=n_tokens)\n",
    "        top_index,  pct_index,  _ = _mode_and_pct(g[\"index\"], denom=n_tokens)\n",
    "        top_hd,     pct_hd,     _ = _mode_and_pct(g[\"head_dist\"], denom=n_tokens)\n",
    "        top_rel,    pct_rel,    _ = _mode_and_pct(g[\"relation_type\"], denom=n_tokens)\n",
    "        top_arity,  pct_arity,  _ = _mode_and_pct(g[\"arity\"], denom=n_tokens)\n",
    "\n",
    "        records.append({\n",
    "            \"length\": L,\n",
    "            \"n_tokens\": n_tokens,\n",
    "            \"n_types\": n_types,\n",
    "\n",
    "            \"top_pos\": top_pos,\n",
    "            \"top_pos_pct\": round(pct_pos, 2),\n",
    "\n",
    "            \"top_index\": top_index,\n",
    "            \"top_index_pct\": round(pct_index, 2),\n",
    "\n",
    "            \"top_head_dist\": top_hd,\n",
    "            \"top_head_dist_pct\": round(pct_hd, 2),\n",
    "\n",
    "            \"top_relation_type\": top_rel,\n",
    "            \"top_relation_type_pct\": round(pct_rel, 2),\n",
    "\n",
    "            \"top_arity\": top_arity,\n",
    "            \"top_arity_pct\": round(pct_arity, 2),\n",
    "        })\n",
    "\n",
    "    summary = (\n",
    "        pd.DataFrame.from_records(records)\n",
    "        .sort_values([\"length\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ac66899-71e0-4858-b34d-368f5176c7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Per-LENGTH summary (length ≤ 10):\n",
      "   length  n_tokens  n_types top_pos  top_pos_pct  top_index  top_index_pct  top_head_dist  top_head_dist_pct top_relation_type  top_relation_type_pct  \\\n",
      "0       1     29626       74   PUNCT        71.80          1           5.98              1              21.08             punct                  71.80   \n",
      "1       2     29918      334     ADP        37.84          1           6.61              1              41.01              case                  35.28   \n",
      "2       3     36097      911     DET        26.98          1           5.88              1              41.34               det                  26.02   \n",
      "3       4     33008     1660    NOUN        18.66          2           6.03              1              26.63            advmod                  10.33   \n",
      "4       5     18892     2012    NOUN        30.75          2           5.92              1              26.32              amod                   9.01   \n",
      "5       6     14274     2373    NOUN        37.89          4           5.73              1              21.52              amod                   8.81   \n",
      "6       7     12188     2426    NOUN        36.82          4           5.29              1              19.49              amod                   9.56   \n",
      "7       8      7895     2044    NOUN        39.61          5           5.78              1              20.39              amod                  12.89   \n",
      "8       9      5526     1557    NOUN        39.32          4           5.52              1              21.08              amod                  12.76   \n",
      "9      10      3526     1150    NOUN        45.86          3           6.66              1              21.67              amod                  10.78   \n",
      "\n",
      "   top_arity  top_arity_pct  \n",
      "0          0          97.21  \n",
      "1          0          92.30  \n",
      "2          0          81.98  \n",
      "3          0          55.09  \n",
      "4          0          47.07  \n",
      "5          0          36.53  \n",
      "6          0          33.13  \n",
      "7          0          31.91  \n",
      "8          0          31.94  \n",
      "9          0          30.20  \n",
      "✓ Saved LENGTH summary to length_summary.csv\n"
     ]
    }
   ],
   "source": [
    "length_summary = build_length_summary(df_tokens, max_length=10)\n",
    "print(\"\\nPer-LENGTH summary (length ≤ 10):\")\n",
    "with pd.option_context(\"display.max_rows\", None,\n",
    "                       \"display.max_columns\", None,\n",
    "                       \"display.width\", 160):\n",
    "    print(length_summary)\n",
    "\n",
    "length_summary.to_csv(\"length_summary.csv\", index=False)\n",
    "print(\"✓ Saved LENGTH summary to length_summary.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7bba3f4-4caf-44d6-95ce-936ae16e9192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_head_dist_summary(tokens_df: pd.DataFrame,\n",
    "                            min_head_dist: int = -6,\n",
    "                            max_head_dist: int = 6) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build a per-head_dist summary for head_dist in [min_head_dist, max_head_dist].\n",
    "    Mirrors the structure of your POS / INDEX / LENGTH summaries.\n",
    "    \"\"\"\n",
    "\n",
    "    if \"head_dist\" not in tokens_df.columns:\n",
    "        raise ValueError(\"Expanded token frame has no 'head_dist' column; check inputs.\")\n",
    "\n",
    "    # Keep only tokens within the specified range\n",
    "    df = tokens_df[\n",
    "        tokens_df[\"head_dist\"].notna()\n",
    "        & (tokens_df[\"head_dist\"] >= min_head_dist)\n",
    "        & (tokens_df[\"head_dist\"] <= max_head_dist)\n",
    "    ]\n",
    "\n",
    "    records = []\n",
    "    for hd, g in df.groupby(\"head_dist\", dropna=True):\n",
    "        n_tokens = len(g)\n",
    "        n_types  = g[\"word_norm\"].nunique()\n",
    "\n",
    "        top_pos,    pct_pos,    _ = _mode_and_pct(g[\"pos\"], denom=n_tokens)\n",
    "        top_index,  pct_index,  _ = _mode_and_pct(g[\"index\"], denom=n_tokens)\n",
    "        top_length, pct_length, _ = _mode_and_pct(g[\"length\"], denom=n_tokens)\n",
    "        top_rel,    pct_rel,    _ = _mode_and_pct(g[\"relation_type\"], denom=n_tokens)\n",
    "        top_arity,  pct_arity,  _ = _mode_and_pct(g[\"arity\"], denom=n_tokens)\n",
    "\n",
    "        records.append({\n",
    "            \"head_dist\": hd,\n",
    "            \"n_tokens\": n_tokens,\n",
    "            \"n_types\": n_types,\n",
    "\n",
    "            \"top_pos\": top_pos,\n",
    "            \"top_pos_pct\": round(pct_pos, 2),\n",
    "\n",
    "            \"top_index\": top_index,\n",
    "            \"top_index_pct\": round(pct_index, 2),\n",
    "\n",
    "            \"top_length\": top_length,\n",
    "            \"top_length_pct\": round(pct_length, 2),\n",
    "\n",
    "            \"top_relation_type\": top_rel,\n",
    "            \"top_relation_type_pct\": round(pct_rel, 2),\n",
    "\n",
    "            \"top_arity\": top_arity,\n",
    "            \"top_arity_pct\": round(pct_arity, 2),\n",
    "        })\n",
    "\n",
    "    summary = (\n",
    "        pd.DataFrame.from_records(records)\n",
    "        .sort_values([\"head_dist\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80be8192-298e-46a2-b187-e261a8a2fb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Per-HEAD_DIST summary (−6 to 6):\n",
      "    head_dist  n_tokens  n_types top_pos  top_pos_pct  top_index  top_index_pct  top_length  top_length_pct top_relation_type  top_relation_type_pct  \\\n",
      "0          -6      3251     1701    NOUN        37.47          8          10.34           1           18.61             punct                  19.26   \n",
      "1          -5      4545     2268    NOUN        41.41          8           9.42           4           17.29               obl                  21.30   \n",
      "2          -4      6684     3050    NOUN        46.95          7           8.95           4           18.73               obl                  21.47   \n",
      "3          -3     10487     4117    NOUN        55.21          6           7.96           4           19.61              nmod                  20.32   \n",
      "4          -2     15690     5483    NOUN        39.99          5           7.39           4           21.22               obj                  22.54   \n",
      "5          -1     13038     2647   PUNCT        26.24          2           8.18           1           26.86             punct                  26.24   \n",
      "6           0     10046     3032    VERB        67.99          2          17.29           4           28.58              root                 100.00   \n",
      "7           1     57036     5218     DET        16.14          4           5.69           3           26.16               det                  16.06   \n",
      "8           2     28588     2747     ADP        21.23          1           8.36           3           26.21              case                  21.48   \n",
      "9           3     13592     1840     ADP        19.41          1          10.53           2           24.01              case                  19.81   \n",
      "10          4      6439     1171     ADP        14.35          1          11.18           3           22.43             nsubj                  16.40   \n",
      "11          5      3249      795   PUNCT        16.65          1          11.27           3           20.71             punct                  16.65   \n",
      "12          6      1673      575   PUNCT        16.92          1          12.43           4           19.43             punct                  16.92   \n",
      "\n",
      "    top_arity  top_arity_pct  \n",
      "0           3          23.81  \n",
      "1           3          23.06  \n",
      "2           3          31.57  \n",
      "3           2          46.96  \n",
      "4           1          49.94  \n",
      "5           0          85.46  \n",
      "6           3          25.46  \n",
      "7           0          95.13  \n",
      "8           0          92.87  \n",
      "9           0          85.98  \n",
      "10          0          83.20  \n",
      "11          0          75.96  \n",
      "12          0          68.98  \n"
     ]
    }
   ],
   "source": [
    "head_dist_summary = build_head_dist_summary(df_tokens,\n",
    "                                            min_head_dist=-6,\n",
    "                                            max_head_dist=6)\n",
    "\n",
    "print(\"\\nPer-HEAD_DIST summary (−6 to 6):\")\n",
    "with pd.option_context(\"display.max_rows\", None,\n",
    "                       \"display.max_columns\", None,\n",
    "                       \"display.width\", 160):\n",
    "    print(head_dist_summary)\n",
    "\n",
    "head_dist_summary.to_csv(\"head_dist_summary.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecc1041e-4925-4aa2-a407-bb7d54098bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_arity_summary(tokens_df: pd.DataFrame, max_arity: int = 4) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build a per-arity summary (arity ≤ max_arity).\n",
    "    Mirrors the structure of your POS / INDEX / LENGTH / HEAD_DIST summaries.\n",
    "    \"\"\"\n",
    "\n",
    "    if \"arity\" not in tokens_df.columns:\n",
    "        raise ValueError(\"Expanded token frame has no 'arity' column; check inputs.\")\n",
    "\n",
    "    # Keep only tokens with arity <= max_arity\n",
    "    df = tokens_df[\n",
    "        tokens_df[\"arity\"].notna()\n",
    "        & (tokens_df[\"arity\"] <= max_arity)\n",
    "    ]\n",
    "\n",
    "    records = []\n",
    "    for ar, g in df.groupby(\"arity\", dropna=True):\n",
    "        n_tokens = len(g)\n",
    "        n_types  = g[\"word_norm\"].nunique()\n",
    "\n",
    "        top_pos,    pct_pos,    _ = _mode_and_pct(g[\"pos\"], denom=n_tokens)\n",
    "        top_index,  pct_index,  _ = _mode_and_pct(g[\"index\"], denom=n_tokens)\n",
    "        top_length, pct_length, _ = _mode_and_pct(g[\"length\"], denom=n_tokens)\n",
    "        top_hd,     pct_hd,     _ = _mode_and_pct(g[\"head_dist\"], denom=n_tokens)\n",
    "        top_rel,    pct_rel,    _ = _mode_and_pct(g[\"relation_type\"], denom=n_tokens)\n",
    "\n",
    "        records.append({\n",
    "            \"arity\": ar,\n",
    "            \"n_tokens\": n_tokens,\n",
    "            \"n_types\": n_types,\n",
    "\n",
    "            \"top_pos\": top_pos,\n",
    "            \"top_pos_pct\": round(pct_pos, 2),\n",
    "\n",
    "            \"top_index\": top_index,\n",
    "            \"top_index_pct\": round(pct_index, 2),\n",
    "\n",
    "            \"top_length\": top_length,\n",
    "            \"top_length_pct\": round(pct_length, 2),\n",
    "\n",
    "            \"top_head_dist\": top_hd,\n",
    "            \"top_head_dist_pct\": round(pct_hd, 2),\n",
    "\n",
    "            \"top_relation_type\": top_rel,\n",
    "            \"top_relation_type_pct\": round(pct_rel, 2),\n",
    "        })\n",
    "\n",
    "    summary = (\n",
    "        pd.DataFrame.from_records(records)\n",
    "        .sort_values([\"arity\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "255b98d6-8223-43d4-a2c1-5965bec04ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Per-ARITY summary (≤ 4):\n",
      "   arity  n_tokens  n_types top_pos  top_pos_pct  top_index  top_index_pct  top_length  top_length_pct  top_head_dist  top_head_dist_pct top_relation_type  \\\n",
      "0      0    129064     7581   PUNCT        17.14          1           6.53           3           22.93              1              42.04             punct   \n",
      "1      1     20239     6441    NOUN        45.31          6           5.68           4           19.97             -2              38.72               obj   \n",
      "2      2     18037     5846    NOUN        51.82          2           6.32           4           22.05             -3              27.30               obl   \n",
      "3      3     13546     4621    VERB        44.92          3           8.25           4           23.67              0              18.88              root   \n",
      "4      4      7856     3169    VERB        54.88          4           8.95           4           26.03              0              31.73              root   \n",
      "\n",
      "   top_relation_type_pct  \n",
      "0                  17.14  \n",
      "1                  15.83  \n",
      "2                  16.97  \n",
      "3                  18.88  \n",
      "4                  31.73  \n",
      "✓ Saved ARITY summary to arity_summary.csv\n"
     ]
    }
   ],
   "source": [
    "arity_summary = build_arity_summary(df_tokens, max_arity=4)\n",
    "\n",
    "print(\"\\nPer-ARITY summary (≤ 4):\")\n",
    "with pd.option_context(\"display.max_rows\", None,\n",
    "                       \"display.max_columns\", None,\n",
    "                       \"display.width\", 160):\n",
    "    print(arity_summary)\n",
    "\n",
    "arity_summary.to_csv(\"arity_summary.csv\", index=False)\n",
    "print(\"✓ Saved ARITY summary to arity_summary.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "605a80d6-16e9-4a58-9a47-68bbe1cd9f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_relation_type_summary_top15(tokens_df: pd.DataFrame, top_k: int = 15) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build a per-relation_type summary for the top-K most frequent\n",
    "    dependency relations in the dataset.\n",
    "    Mirrors your other feature summary functions.\n",
    "    \"\"\"\n",
    "\n",
    "    if \"relation_type\" not in tokens_df.columns:\n",
    "        raise ValueError(\"Expanded token frame has no 'relation_type' column; check inputs.\")\n",
    "\n",
    "    # Count relations → pick top K\n",
    "    vc = tokens_df[\"relation_type\"].value_counts(dropna=True)\n",
    "    top_relations = set(vc.iloc[:top_k].index)\n",
    "\n",
    "    # Filter to only those\n",
    "    df = tokens_df[tokens_df[\"relation_type\"].isin(top_relations)]\n",
    "\n",
    "    records = []\n",
    "    for rel, g in df.groupby(\"relation_type\", dropna=True):\n",
    "        n_tokens = len(g)\n",
    "        n_types  = g[\"word_norm\"].nunique()\n",
    "\n",
    "        top_pos,    pct_pos,    _ = _mode_and_pct(g[\"pos\"], denom=n_tokens)\n",
    "        top_index,  pct_index,  _ = _mode_and_pct(g[\"index\"], denom=n_tokens)\n",
    "        top_length, pct_length, _ = _mode_and_pct(g[\"length\"], denom=n_tokens)\n",
    "        top_hd,     pct_hd,     _ = _mode_and_pct(g[\"head_dist\"], denom=n_tokens)\n",
    "        top_arity,  pct_arity,  _ = _mode_and_pct(g[\"arity\"], denom=n_tokens)\n",
    "\n",
    "        records.append({\n",
    "            \"relation_type\": rel,\n",
    "            \"n_tokens\": n_tokens,\n",
    "            \"n_types\": n_types,\n",
    "\n",
    "            \"top_pos\": top_pos,\n",
    "            \"top_pos_pct\": round(pct_pos, 2),\n",
    "\n",
    "            \"top_index\": top_index,\n",
    "            \"top_index_pct\": round(pct_index, 2),\n",
    "\n",
    "            \"top_length\": top_length,\n",
    "            \"top_length_pct\": round(pct_length, 2),\n",
    "\n",
    "            \"top_head_dist\": top_hd,\n",
    "            \"top_head_dist_pct\": round(pct_hd, 2),\n",
    "\n",
    "            \"top_arity\": top_arity,\n",
    "            \"top_arity_pct\": round(pct_arity, 2),\n",
    "        })\n",
    "\n",
    "    summary = (\n",
    "        pd.DataFrame.from_records(records)\n",
    "        .sort_values([\"n_tokens\"], ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eae519a2-fa75-46a2-9b1b-a380e943f0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-15 RELATION_TYPE summary:\n",
      "   relation_type  n_tokens  n_types top_pos  top_pos_pct  top_index  top_index_pct  top_length  top_length_pct  top_head_dist  top_head_dist_pct  top_arity  \\\n",
      "0          punct     22123       94   PUNCT       100.00         10           4.48           1           96.14             -1              15.46          0   \n",
      "1           case     16577      128     ADP        97.79          6           6.01           2           63.67              2              37.04          0   \n",
      "2          nsubj     15648     2562    PRON        64.49          1          21.20           4           19.67              1              35.85          0   \n",
      "3            det     15562       31     DET       100.00          1           7.36           3           60.36              1              58.85          0   \n",
      "4         advmod     10307      704     ADV        89.64          1           7.98           4           33.07              1              43.64          0   \n",
      "5           root     10046     3032    VERB        67.99          2          17.29           4           28.58              0             100.00          3   \n",
      "6            obj      9685     2978    NOUN        70.18          5           7.64           4           22.28             -2              36.52          1   \n",
      "7           amod      9312     1960     ADJ        92.69          5           5.52           4           18.98              1              75.83          0   \n",
      "8            obl      8743     3228    NOUN        68.20          7           5.94           4           21.22             -3              21.25          2   \n",
      "9           conj      7557     3810    VERB        39.31         11           5.27           4           21.19             -2              26.17          1   \n",
      "10          mark      7097       80   SCONJ        52.91          5           6.97           2           67.66              1              50.08          0   \n",
      "11      compound      7018     2758    NOUN        62.20          6           5.77           4           18.18              1              80.61          0   \n",
      "12          nmod      6794     2980    NOUN        66.50          9           5.78           4           17.28             -2              34.56          2   \n",
      "13            cc      6694       26   CCONJ        97.27          7           5.92           3           85.55              1              44.07          0   \n",
      "14           aux      5904       71     AUX       100.00          2          17.45           3           29.86              1              48.49          0   \n",
      "\n",
      "    top_arity_pct  \n",
      "0          100.00  \n",
      "1           98.68  \n",
      "2           71.04  \n",
      "3           99.92  \n",
      "4           90.67  \n",
      "5           25.46  \n",
      "6           33.07  \n",
      "7           89.68  \n",
      "8           35.01  \n",
      "9           28.04  \n",
      "10          98.72  \n",
      "11          79.91  \n",
      "12          36.78  \n",
      "13          98.98  \n",
      "14          99.88  \n",
      "✓ Saved to relation_type_top15_summary.csv\n"
     ]
    }
   ],
   "source": [
    "rel_summary = build_relation_type_summary_top15(df_tokens, top_k=15)\n",
    "\n",
    "print(\"\\nTop-15 RELATION_TYPE summary:\")\n",
    "with pd.option_context(\"display.max_rows\", None,\n",
    "                       \"display.max_columns\", None,\n",
    "                       \"display.width\", 160):\n",
    "    print(rel_summary)\n",
    "\n",
    "rel_summary.to_csv(\"relation_type_top15_summary.csv\", index=False)\n",
    "print(\"✓ Saved to relation_type_top15_summary.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad207a8e-a49d-4bc6-a3a2-4bdb487a05b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import pandas as pd\n",
    "def top_n_and_pct(series: pd.Series, denom: int, n: int = 5):\n",
    "    \"\"\"\n",
    "    Return the top n values in the series, their counts, and their percentages of denom.\n",
    "    Returns lists: values, counts, pct_of_denom.\n",
    "    \"\"\"\n",
    "    # Value counts (drop NaNs)\n",
    "    vc = series.dropna().value_counts()\n",
    "    topn = vc.head(n)\n",
    "    values = topn.index.tolist()\n",
    "    counts = topn.values.tolist()\n",
    "    pcts   = [(count / denom) * 100.0 for count in counts]\n",
    "    return values, counts, pcts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51cd8320-be15-433c-b585-146b72bb0dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_head_dist_summary(tokens_df: pd.DataFrame,\n",
    "                            min_head_dist: int = -6,\n",
    "                            max_head_dist: int = 6,\n",
    "                            top_n: int = 5) -> pd.DataFrame:\n",
    "    if \"head_dist\" not in tokens_df.columns:\n",
    "        raise ValueError(\"Expanded token frame has no 'head_dist' column; check inputs.\")\n",
    "\n",
    "    df = tokens_df[\n",
    "        tokens_df[\"head_dist\"].notna()\n",
    "        & (tokens_df[\"head_dist\"] >= min_head_dist)\n",
    "        & (tokens_df[\"head_dist\"] <= max_head_dist)\n",
    "    ]\n",
    "\n",
    "    records = []\n",
    "    for hd, g in df.groupby(\"head_dist\", dropna=True):\n",
    "        n_tokens = len(g)\n",
    "        n_types  = g[\"word_norm\"].nunique()\n",
    "\n",
    "        # get top_n for each feature\n",
    "        vals_pos, cnts_pos, pcts_pos = top_n_and_pct(g[\"pos\"], denom=n_tokens, n=top_n)\n",
    "        vals_rel, cnts_rel, pcts_rel = top_n_and_pct(g[\"relation_type\"], denom=n_tokens, n=top_n)\n",
    "        # likewise for index, length, arity …\n",
    "        vals_index, cnts_index, pcts_index = top_n_and_pct(g[\"index\"], denom=n_tokens, n=top_n)\n",
    "        vals_length, cnts_length, pcts_length = top_n_and_pct(g[\"length\"], denom=n_tokens, n=top_n)\n",
    "        vals_arity, cnts_arity, pcts_arity = top_n_and_pct(g[\"arity\"], denom=n_tokens, n=top_n)\n",
    "\n",
    "        records.append({\n",
    "            \"head_dist\": hd,\n",
    "            \"n_tokens\": n_tokens,\n",
    "            \"n_types\": n_types,\n",
    "\n",
    "            \"top_pos_vals\": vals_pos,\n",
    "            \"top_pos_counts\": cnts_pos,\n",
    "            \"top_pos_pct\": [round(p,2) for p in pcts_pos],\n",
    "\n",
    "            \"top_relation_type_vals\": vals_rel,\n",
    "            \"top_relation_type_counts\": cnts_rel,\n",
    "            \"top_relation_type_pct\": [round(p,2) for p in pcts_rel],\n",
    "\n",
    "            \"top_index_vals\": vals_index,\n",
    "            \"top_index_counts\": cnts_index,\n",
    "            \"top_index_pct\": [round(p,2) for p in pcts_index],\n",
    "\n",
    "            \"top_length_vals\": vals_length,\n",
    "            \"top_length_counts\": cnts_length,\n",
    "            \"top_length_pct\": [round(p,2) for p in pcts_length],\n",
    "\n",
    "            \"top_arity_vals\": vals_arity,\n",
    "            \"top_arity_counts\": cnts_arity,\n",
    "            \"top_arity_pct\": [round(p,2) for p in pcts_arity],\n",
    "        })\n",
    "\n",
    "    summary = (\n",
    "        pd.DataFrame.from_records(records)\n",
    "        .sort_values([\"head_dist\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f289ce4f-c46e-44e6-bf71-a2641dbe52b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Per-HEAD_DIST summary (−6 to 6):\n",
      "    head_dist  n_tokens  n_types                      top_pos_vals                  top_pos_counts                          top_pos_pct  \\\n",
      "0          -6      3251     1701   [NOUN, VERB, PUNCT, PROPN, ADJ]      [1218, 816, 626, 209, 163]     [37.47, 25.1, 19.26, 6.43, 5.01]   \n",
      "1          -5      4545     2268   [NOUN, VERB, PUNCT, PROPN, ADJ]     [1882, 1058, 694, 358, 191]     [41.41, 23.28, 15.27, 7.88, 4.2]   \n",
      "2          -4      6684     3050   [NOUN, VERB, PUNCT, PROPN, ADJ]     [3138, 1488, 670, 592, 262]    [46.95, 22.26, 10.02, 8.86, 3.92]   \n",
      "3          -3     10487     4117   [NOUN, VERB, PROPN, PUNCT, ADV]     [5790, 1839, 936, 685, 352]     [55.21, 17.54, 8.93, 6.53, 3.36]   \n",
      "4          -2     15690     5483    [NOUN, VERB, PROPN, PRON, NUM]    [6275, 3726, 2110, 842, 646]    [39.99, 23.75, 13.45, 5.37, 4.12]   \n",
      "5          -1     13038     2647   [PUNCT, PRON, ADV, PROPN, NOUN]  [3421, 2368, 1453, 1375, 1213]    [26.24, 18.16, 11.14, 10.55, 9.3]   \n",
      "6           0     10046     3032     [VERB, NOUN, ADJ, PROPN, NUM]    [6830, 1308, 1090, 263, 220]    [67.99, 13.02, 10.85, 2.62, 2.19]   \n",
      "7           1     57036     5218        [DET, PRON, ADJ, ADP, AUX]  [9206, 6784, 6693, 5975, 5365]   [16.14, 11.89, 11.73, 10.48, 9.41]   \n",
      "8           2     28588     2747       [ADP, DET, PRON, AUX, NOUN]  [6069, 4508, 4155, 3679, 1706]   [21.23, 15.77, 14.53, 12.87, 5.97]   \n",
      "9           3     13592     1840      [ADP, PRON, DET, AUX, PUNCT]  [2638, 2202, 1279, 1261, 1153]      [19.41, 16.2, 9.41, 9.28, 8.48]   \n",
      "10          4      6439     1171   [ADP, PUNCT, PRON, NOUN, CCONJ]       [924, 894, 746, 612, 585]     [14.35, 13.88, 11.59, 9.5, 9.09]   \n",
      "11          5      3249      795   [PUNCT, NOUN, ADP, PRON, SCONJ]       [541, 394, 366, 336, 333]  [16.65, 12.13, 11.27, 10.34, 10.25]   \n",
      "12          6      1673      575  [PUNCT, NOUN, SCONJ, CCONJ, ADP]       [283, 264, 167, 136, 133]     [16.92, 15.78, 9.98, 8.13, 7.95]   \n",
      "\n",
      "                      top_relation_type_vals        top_relation_type_counts               top_relation_type_pct     top_index_vals  \\\n",
      "0            [punct, obl, conj, advcl, nmod]       [626, 618, 534, 274, 264]   [19.26, 19.01, 16.43, 8.43, 8.12]  [8, 9, 10, 11, 7]   \n",
      "1            [obl, punct, conj, nmod, advcl]       [968, 694, 593, 484, 332]    [21.3, 15.27, 13.05, 10.65, 7.3]   [8, 7, 9, 10, 6]   \n",
      "2              [obl, nmod, conj, punct, obj]     [1435, 1014, 717, 670, 581]  [21.47, 15.17, 10.73, 10.02, 8.69]   [7, 6, 8, 9, 11]   \n",
      "3              [nmod, obl, obj, conj, punct]    [2131, 1858, 1691, 911, 685]   [20.32, 17.72, 16.12, 8.69, 6.53]    [6, 7, 5, 8, 9]   \n",
      "4              [obj, nmod, conj, xcomp, obl]  [3537, 2348, 1978, 1737, 1474]  [22.54, 14.96, 12.61, 11.07, 9.39]    [5, 6, 7, 4, 8]   \n",
      "5   [punct, obj, advmod, flat, compound:prt]   [3421, 3076, 1377, 1182, 581]   [26.24, 23.59, 10.56, 9.07, 4.46]    [2, 5, 4, 6, 3]   \n",
      "6                                     [root]                         [10046]                             [100.0]    [2, 3, 4, 1, 5]   \n",
      "7         [det, amod, case, compound, nsubj]  [9158, 7061, 6096, 5657, 5610]   [16.06, 12.38, 10.69, 9.92, 9.84]    [4, 1, 2, 3, 5]   \n",
      "8             [case, det, nsubj, aux, punct]  [6140, 4376, 4284, 2259, 1602]     [21.48, 15.31, 14.99, 7.9, 5.6]    [1, 2, 3, 4, 5]   \n",
      "9              [case, nsubj, det, punct, cc]   [2693, 2575, 1212, 1153, 944]    [19.81, 18.94, 8.92, 8.48, 6.95]    [1, 2, 3, 4, 8]   \n",
      "10            [nsubj, case, punct, cc, mark]      [1056, 951, 894, 599, 587]     [16.4, 14.77, 13.88, 9.3, 9.12]    [1, 2, 3, 6, 7]   \n",
      "11            [punct, nsubj, case, mark, cc]       [541, 539, 363, 360, 295]  [16.65, 16.59, 11.17, 11.08, 9.08]    [1, 3, 2, 4, 5]   \n",
      "12            [punct, nsubj, mark, case, cc]       [283, 281, 174, 136, 132]     [16.92, 16.8, 10.4, 8.13, 7.89]    [1, 2, 3, 4, 5]   \n",
      "\n",
      "                  top_index_counts                       top_index_pct  top_length_vals                 top_length_counts  \\\n",
      "0        [336, 324, 297, 247, 200]      [10.34, 9.97, 9.14, 7.6, 6.15]  [1, 4, 5, 6, 7]         [605, 561, 434, 362, 340]   \n",
      "1        [428, 400, 384, 316, 291]        [9.42, 8.8, 8.45, 6.95, 6.4]  [4, 1, 5, 6, 7]         [786, 694, 615, 550, 491]   \n",
      "2        [598, 518, 504, 440, 360]      [8.95, 7.75, 7.54, 6.58, 5.39]  [4, 5, 6, 7, 1]        [1252, 974, 929, 735, 689]   \n",
      "3        [835, 805, 705, 653, 559]      [7.96, 7.68, 6.72, 6.23, 5.33]  [4, 5, 6, 7, 3]     [2057, 1605, 1380, 1214, 963]   \n",
      "4      [1159, 1121, 979, 979, 825]      [7.39, 7.14, 6.24, 6.24, 5.26]  [4, 5, 6, 7, 3]    [3329, 2185, 1931, 1727, 1664]   \n",
      "5       [1066, 828, 815, 783, 743]       [8.18, 6.35, 6.25, 6.01, 5.7]  [1, 2, 4, 3, 5]    [3502, 2229, 1875, 1444, 1012]   \n",
      "6    [1737, 1703, 1393, 1131, 958]  [17.29, 16.95, 13.87, 11.26, 9.54]  [4, 5, 6, 3, 7]    [2871, 1462, 1208, 1146, 1110]   \n",
      "7   [3247, 3200, 3185, 3137, 3123]       [5.69, 5.61, 5.58, 5.5, 5.48]  [3, 2, 4, 1, 5]  [14921, 12269, 8790, 6246, 4972]   \n",
      "8   [2389, 1659, 1578, 1486, 1446]        [8.36, 5.8, 5.52, 5.2, 5.06]  [3, 2, 4, 1, 5]    [7493, 7191, 4350, 3769, 2227]   \n",
      "9       [1431, 852, 731, 680, 639]       [10.53, 6.27, 5.38, 5.0, 4.7]  [2, 3, 4, 1, 5]     [3263, 3257, 2261, 2042, 947]   \n",
      "10       [720, 385, 360, 314, 301]     [11.18, 5.98, 5.59, 4.88, 4.67]  [3, 2, 1, 4, 5]     [1444, 1393, 1125, 1083, 419]   \n",
      "11       [366, 218, 206, 167, 164]     [11.27, 6.71, 6.34, 5.14, 5.05]  [3, 1, 4, 2, 5]         [673, 634, 596, 578, 271]   \n",
      "12         [208, 124, 124, 94, 86]     [12.43, 7.41, 7.41, 5.62, 5.14]  [4, 3, 1, 2, 5]         [325, 321, 309, 257, 134]   \n",
      "\n",
      "                         top_length_pct   top_arity_vals               top_arity_counts                        top_arity_pct  \n",
      "0   [18.61, 17.26, 13.35, 11.14, 10.46]  [3, 0, 2, 4, 1]      [774, 763, 595, 479, 280]    [23.81, 23.47, 18.3, 14.73, 8.61]  \n",
      "1     [17.29, 15.27, 13.53, 12.1, 10.8]  [3, 2, 0, 4, 1]     [1048, 974, 890, 754, 473]  [23.06, 21.43, 19.58, 16.59, 10.41]  \n",
      "2     [18.73, 14.57, 13.9, 11.0, 10.31]  [3, 2, 0, 4, 1]   [2110, 1461, 1040, 926, 845]  [31.57, 21.86, 15.56, 13.85, 12.64]  \n",
      "3     [19.61, 15.3, 13.16, 11.58, 9.18]  [2, 3, 1, 0, 4]  [4925, 2342, 1333, 1213, 538]   [46.96, 22.33, 12.71, 11.57, 5.13]  \n",
      "4   [21.22, 13.93, 12.31, 11.01, 10.61]  [1, 2, 0, 3, 4]  [7836, 4039, 2049, 1350, 334]     [49.94, 25.74, 13.06, 8.6, 2.13]  \n",
      "5     [26.86, 17.1, 14.38, 11.08, 7.76]  [0, 1, 2, 3, 4]     [11142, 1501, 327, 51, 12]     [85.46, 11.51, 2.51, 0.39, 0.09]  \n",
      "6   [28.58, 14.55, 12.02, 11.41, 11.05]  [3, 4, 2, 5, 6]  [2558, 2493, 1722, 1644, 714]   [25.46, 24.82, 17.14, 16.36, 7.11]  \n",
      "7    [26.16, 21.51, 15.41, 10.95, 8.72]  [0, 1, 2, 3, 4]     [54259, 2343, 361, 51, 19]      [95.13, 4.11, 0.63, 0.09, 0.03]  \n",
      "8    [26.21, 25.15, 15.22, 13.18, 7.79]  [0, 1, 2, 3, 4]     [26550, 1552, 392, 76, 15]      [92.87, 5.43, 1.37, 0.27, 0.05]  \n",
      "9    [24.01, 23.96, 16.63, 15.02, 6.97]  [0, 1, 2, 3, 4]    [11687, 1352, 411, 110, 24]      [85.98, 9.95, 3.02, 0.81, 0.18]  \n",
      "10   [22.43, 21.63, 17.47, 16.82, 6.51]  [0, 1, 2, 3, 4]      [5357, 600, 320, 116, 35]        [83.2, 9.32, 4.97, 1.8, 0.54]  \n",
      "11   [20.71, 19.51, 18.34, 17.79, 8.34]  [0, 1, 2, 3, 4]      [2468, 325, 271, 129, 41]      [75.96, 10.0, 8.34, 3.97, 1.26]  \n",
      "12   [19.43, 19.19, 18.47, 15.36, 8.01]  [0, 2, 1, 3, 4]      [1154, 175, 165, 121, 41]     [68.98, 10.46, 9.86, 7.23, 2.45]  \n"
     ]
    }
   ],
   "source": [
    "head_dist_summary = build_head_dist_summary(df_tokens,\n",
    "                                            min_head_dist=-6,\n",
    "                                            max_head_dist=6)\n",
    "\n",
    "print(\"\\nPer-HEAD_DIST summary (−6 to 6):\")\n",
    "with pd.option_context(\"display.max_rows\", None,\n",
    "                       \"display.max_columns\", None,\n",
    "                       \"display.width\", 160):\n",
    "    print(head_dist_summary)\n",
    "\n",
    "head_dist_summary.to_csv(\"head_dist_summary.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e611f9c0-d406-4b05-989f-70abfc6c0848",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
