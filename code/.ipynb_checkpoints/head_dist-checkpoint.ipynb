{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fccdd2f-009b-403c-a55e-4cd573675633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-07 21:50:51.915113: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import os, ast, random, inspect\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np, pandas as pd, torch\n",
    "import torch.utils.data as torchdata\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "from transformers import AutoTokenizer, AutoModel, BertModel, AutoConfig\n",
    "\n",
    "from IsoScore import IsoScore\n",
    "from dadapy import Data\n",
    "from skdim.id import MLE, MOM, TLE, CorrInt, FisherS, lPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "344110d4-299c-477a-a37a-0015a03a3b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ corpus ready — 184,870 tokens across head-dist classes ['-6', '-5', '-4', '-3', '-2', '-1', '1', '2', '3', '4', '5', '6']\n",
      "Sample sizes per head distance (raw cap):\n",
      "{'-6': 19585, '-5': 4545, '-4': 6684, '-3': 10487, '-2': 15690, '-1': 13038, '1': 57036, '2': 28588, '3': 13592, '4': 6439, '5': 3249, '6': 5937}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bert-base-uncased (embed subset):   8%|▎   | 780/10067 [00:07<01:23, 110.96it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 550\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m✓ done (incremental outputs produced per metric).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 550\u001b[0m     \u001b[43mrun_headdist_from_col_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 507\u001b[0m, in \u001b[0;36mrun_headdist_from_col_pipeline\u001b[0;34m()\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m⚠ Some classes have < \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMIN_N_FOR_HEAVY_WARN\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tokens (heavy ID may be noisy): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtoo_small\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# 3) Embed once\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m reps, filled \u001b[38;5;241m=\u001b[39m embed_subset(df_sent, raw_df, BASELINE, WORD_REP_MODE, BATCH_SIZE)\n\u001b[1;32m    508\u001b[0m raw_df \u001b[38;5;241m=\u001b[39m raw_df\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mloc[filled]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    509\u001b[0m cls_arr \u001b[38;5;241m=\u001b[39m raw_df\u001b[38;5;241m.\u001b[39mhead_dist_class\u001b[38;5;241m.\u001b[39mvalues\n",
      "Cell \u001b[0;32mIn[2], line 338\u001b[0m, in \u001b[0;36membed_subset\u001b[0;34m(df_sent, subset_df, baseline, word_rep_mode, batch_size)\u001b[0m\n\u001b[1;32m    336\u001b[0m enc_be \u001b[38;5;241m=\u001b[39m tokzr(batch_tokens, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39menc_kwargs)\n\u001b[1;32m    337\u001b[0m enc_t  \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m enc_be\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m--> 338\u001b[0m out \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39menc_t)\n\u001b[1;32m    339\u001b[0m h \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(out\u001b[38;5;241m.\u001b[39mhidden_states)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)  \u001b[38;5;66;03m# (L,B,T,D)\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b, sid \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch_ids):\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1000\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m    997\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m    998\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1000\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1013\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1014\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:650\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    646\u001b[0m     all_hidden_states \u001b[38;5;241m=\u001b[39m all_hidden_states \u001b[38;5;241m+\u001b[39m (hidden_states,)\n\u001b[1;32m    648\u001b[0m layer_head_mask \u001b[38;5;241m=\u001b[39m head_mask[i] \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 650\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[1;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    661\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    662\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/modeling_layers.py:60\u001b[0m, in \u001b[0;36mGradientCheckpointingLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Base class for layers with gradient checkpointing.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03mThis class enables gradient checkpointing functionality for a layer. By default, gradient checkpointing is disabled\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m        ```\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     58\u001b[0m gradient_checkpointing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_checkpointing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m     62\u001b[0m         do_warn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import os, gc, ast, random, inspect\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Callable\n",
    "from __future__ import annotations\n",
    "import os, ast, random, inspect\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np, pandas as pd, torch\n",
    "import torch.utils.data as torchdata\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "from transformers import AutoTokenizer, AutoModel, BertModel, AutoConfig\n",
    "\n",
    "from IsoScore import IsoScore\n",
    "from dadapy import Data\n",
    "from skdim.id import MLE, MOM, TLE, CorrInt, FisherS, lPCA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# ===== Optional deps (gracefully skipped if not installed) =====\n",
    "HAS_DADAPY = False\n",
    "try:\n",
    "    from dadapy import Data  # DADApy ID estimators (TwoNN, GRIDE)\n",
    "    HAS_DADAPY = True\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "HAS_SKDIM = False\n",
    "try:\n",
    "    from skdim.id import (\n",
    "        MOM, TLE, CorrInt, FisherS, lPCA,\n",
    "        MLE, DANCo, ESS, MiND_ML, MADA, KNN\n",
    "    )\n",
    "    HAS_SKDIM = True\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# IsoScore: use library if available, else a simple monotone fallback\n",
    "try:\n",
    "    from isoscore import IsoScore\n",
    "    _HAS_ISOSCORE = True\n",
    "except Exception:\n",
    "    _HAS_ISOSCORE = False\n",
    "    class _IsoScoreFallback:\n",
    "        @staticmethod\n",
    "        def IsoScore(X: np.ndarray) -> float:\n",
    "            C = np.cov(X.T, ddof=0)\n",
    "            ev = np.linalg.eigvalsh(C)\n",
    "            if ev.mean() <= 0 or ev[-1] <= 0:\n",
    "                return 0.0\n",
    "            # mean / max eigenvalue in [0,1]; higher ≈ more isotropic\n",
    "            return float(np.clip(ev.mean() / (ev[-1] + 1e-9), 0.0, 1.0))\n",
    "    IsoScore = _IsoScoreFallback()\n",
    "\n",
    "# =============================== CONFIG ===============================\n",
    "CSV_PATH      = \"en_ewt-ud-train_sentences.csv\"\n",
    "HEAD_DIST_COL = \"head_dist\"             # <-- your existing column with per-token distances\n",
    "BASELINE      = \"bert-base-uncased\"     # set to \"gpt2\" for GPT-2 family\n",
    "WORD_REP_MODE = \"first\"                 # BERT: {\"first\",\"last\",\"mean\"}; GPT-2: {\"last\",\"mean\"}\n",
    "\n",
    "# Sampling / bootstrap\n",
    "RAW_MAX_PER_CLASS              = int(1e12)  # no cap for fast metrics\n",
    "N_BOOTSTRAP_FAST               = 50\n",
    "N_BOOTSTRAP_HEAVY              = 200\n",
    "FAST_BS_MAX_SAMP_PER_CLASS     = int(1e12)  # M = N (classic bootstrap)\n",
    "HEAVY_BS_MAX_SAMP_PER_CLASS    = 5000       # practical for TwoNN/GRIDE/skdim\n",
    "MIN_N_FOR_HEAVY_WARN           = 1000       # warn if a class has fewer than this\n",
    "\n",
    "# Head-distance classes\n",
    "HEAD_DIST_CLAMP       = 6                  # keep classes within [-6,6]\n",
    "INCLUDE_ZERO_CLASS    = False              # set True if you also want \"0\" class\n",
    "\n",
    "# Misc\n",
    "RAND_SEED = 42\n",
    "PLOT_DIR  = Path(\"results_HEADDIST\"); PLOT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "CSV_DIR   = Path(\"tables_HEADDIST\") / \"headdist_bootstrap\"; CSV_DIR.mkdir(exist_ok=True, parents=True)\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# Repro & device\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "random.seed(RAND_SEED); np.random.seed(RAND_SEED); torch.manual_seed(RAND_SEED)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"cuda\": torch.backends.cudnn.benchmark = True\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "EPS = 1e-12\n",
    "\n",
    "# =============================== HELPERS ===============================\n",
    "def _to_list(x):\n",
    "    return ast.literal_eval(x) if isinstance(x, str) and x.startswith(\"[\") else x\n",
    "\n",
    "def _center(X: np.ndarray) -> np.ndarray:\n",
    "    return X - X.mean(0, keepdims=True)\n",
    "\n",
    "def _eigvals_from_X(X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Eigenvalues of covariance up to a constant via SVD of centered X (descending).\"\"\"\n",
    "    Xc = _center(X.astype(np.float32, copy=False))\n",
    "    try:\n",
    "        _, S, _ = np.linalg.svd(Xc, full_matrices=False)\n",
    "        lam = (S**2).astype(np.float64)\n",
    "        lam.sort()\n",
    "        return lam[::-1]\n",
    "    except Exception:\n",
    "        return np.array([], dtype=np.float64)\n",
    "\n",
    "def _jitter_unique(X: np.ndarray, eps: float = 1e-6) -> np.ndarray:\n",
    "    \"\"\"Add tiny noise if there are duplicate rows (helps NN-based estimators).\"\"\"\n",
    "    try:\n",
    "        if np.unique(X, axis=0).shape[0] < X.shape[0]:\n",
    "            X = X + np.random.normal(scale=eps, size=X.shape).astype(X.dtype)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return X\n",
    "\n",
    "def _num_hidden_layers(model) -> int:\n",
    "    n = getattr(model.config, \"num_hidden_layers\", None)\n",
    "    if n is None: n = getattr(model.config, \"n_layer\", None)  # GPT-2\n",
    "    if n is None: raise ValueError(\"Cannot determine number of hidden layers from model.config\")\n",
    "    return int(n)\n",
    "\n",
    "def _hidden_size(model) -> int:\n",
    "    d = getattr(model.config, \"hidden_size\", None)\n",
    "    if d is None: d = getattr(model.config, \"n_embd\", None)  # GPT-2\n",
    "    if d is None: raise ValueError(\"Cannot determine hidden size from model.config\")\n",
    "    return int(d)\n",
    "\n",
    "# ========= Metric single-call functions =========\n",
    "# --- Isotropy (fast) ---\n",
    "def _iso_once(X: np.ndarray) -> float:\n",
    "    return float(IsoScore.IsoScore(X))\n",
    "\n",
    "def _sf_once(X: np.ndarray) -> float:\n",
    "    lam = _eigvals_from_X(X)\n",
    "    if lam.size == 0: return np.nan\n",
    "    gm = np.exp(np.mean(np.log(lam + EPS)))\n",
    "    am = float(lam.mean() + EPS)\n",
    "    return float(gm / am)  # higher => flatter spectrum => more isotropic\n",
    "\n",
    "def _vmf_kappa_once(X: np.ndarray) -> float:\n",
    "    if X.shape[0] < 2: return np.nan\n",
    "    Xn = X / (np.linalg.norm(X, axis=1, keepdims=True) + 1e-9)\n",
    "    R = np.linalg.norm(Xn.mean(axis=0))\n",
    "    d = Xn.shape[1]\n",
    "    if R < 1e-9: return 0.0\n",
    "    return float(max(R * (d - R**2) / (1.0 - R**2 + 1e-9), 0.0))  # higher => more anisotropic\n",
    "\n",
    "def _spect_once(X: np.ndarray) -> float:\n",
    "    # spectral ratio: lambda_max / mean(lambda) (higher => more anisotropic)\n",
    "    ev = np.linalg.eigvalsh(np.cov(X.T, ddof=0))\n",
    "    if ev.size == 0: return np.nan\n",
    "    return float(ev[-1] / (ev.mean() + 1e-9))\n",
    "\n",
    "def _rand_once(X: np.ndarray, K: int = 2000) -> float:\n",
    "    # mean absolute random-pair cosine (higher => more anisotropic)\n",
    "    n = X.shape[0]\n",
    "    if n < 2: return np.nan\n",
    "    rng = np.random.default_rng(RAND_SEED)\n",
    "    K_eff = min(K, (n*(n-1))//2)\n",
    "    i = rng.integers(0, n, size=K_eff); j = rng.integers(0, n, size=K_eff)\n",
    "    same = (i == j)\n",
    "    if same.any(): j[same] = rng.integers(0, n, size=same.sum())\n",
    "    A, B = X[i], X[j]\n",
    "    num = np.einsum(\"ij,ij->i\", A, B)\n",
    "    den = (np.linalg.norm(A, axis=1)*np.linalg.norm(B, axis=1) + 1e-9)\n",
    "    return float(np.mean(np.abs(num/den)))\n",
    "\n",
    "# --- Linear ID (fast) ---\n",
    "def _pcaXX_once(X: np.ndarray, var_ratio: float) -> float:\n",
    "    lam = _eigvals_from_X(X)\n",
    "    if lam.size == 0: return np.nan\n",
    "    c = np.cumsum(lam); thr = c[-1] * var_ratio\n",
    "    return float(np.searchsorted(c, thr) + 1)\n",
    "\n",
    "def _pca95_once(X: np.ndarray) -> float:\n",
    "    return _pcaXX_once(X, 0.95)\n",
    "\n",
    "def _pca99_once(X: np.ndarray) -> float:\n",
    "    return _pcaXX_once(X, 0.99)\n",
    "\n",
    "def _erank_once(X: np.ndarray) -> float:\n",
    "    lam = _eigvals_from_X(X)\n",
    "    if lam.size == 0: return np.nan\n",
    "    p = lam / (lam.sum() + EPS)\n",
    "    H = -(p * np.log(p + EPS)).sum()\n",
    "    return float(np.exp(H))\n",
    "\n",
    "def _pr_once(X: np.ndarray) -> float:\n",
    "    lam = _eigvals_from_X(X)\n",
    "    if lam.size == 0: return np.nan\n",
    "    s1 = lam.sum(); s2 = (lam**2).sum()\n",
    "    return float((s1**2) / (s2 + EPS))\n",
    "\n",
    "def _stable_rank_once(X: np.ndarray) -> float:\n",
    "    lam = _eigvals_from_X(X)\n",
    "    if lam.size == 0: return np.nan\n",
    "    return float(lam.sum() / (lam.max() + EPS))\n",
    "\n",
    "# --- Non-linear (heavy) ---\n",
    "def _dadapy_twonn_once(X: np.ndarray) -> float:\n",
    "    if not HAS_DADAPY: return np.nan\n",
    "    d = Data(coordinates=_jitter_unique(X))\n",
    "    id_est, _, _ = d.compute_id_2NN()\n",
    "    return float(id_est)\n",
    "\n",
    "def _dadapy_gride_once(X: np.ndarray) -> float:\n",
    "    if not HAS_DADAPY: return np.nan\n",
    "    d = Data(coordinates=_jitter_unique(X))\n",
    "    d.compute_distances(maxk=64)\n",
    "    ids, _, _ = d.return_id_scaling_gride(range_max=64)\n",
    "    return float(ids[-1])\n",
    "\n",
    "def _skdim_factory(name: str):\n",
    "    if not HAS_SKDIM: return None\n",
    "    mapping = {\n",
    "        \"mom\": MOM, \"tle\": TLE, \"corrint\": CorrInt, \"fishers\": FisherS,\n",
    "        \"lpca\": lPCA, \"lpca99\": lPCA, \"lpca95\": lPCA,\n",
    "        \"mle\": MLE, \"danco\": DANCo, \"ess\": ESS, \"mind_ml\": MiND_ML,\n",
    "        \"mada\": MADA, \"knn\": KNN,\n",
    "    }\n",
    "    cls = mapping.get(name)\n",
    "    if cls is None: return None\n",
    "    def _builder():\n",
    "        if name == \"lpca\":      return cls(ver=\"FO\")\n",
    "        if name == \"lpca99\":    return cls(ver=\"ratio\", alphaRatio=0.99)\n",
    "        if name == \"lpca95\":    return cls(ver=\"ratio\", alphaRatio=0.95)\n",
    "        return cls()\n",
    "    return _builder\n",
    "\n",
    "def _skdim_once_builder(name: str) -> Callable[[np.ndarray], float] | None:\n",
    "    build = _skdim_factory(name)\n",
    "    if build is None: return None\n",
    "    def _once(X: np.ndarray) -> float:\n",
    "        est = build(); est.fit(_jitter_unique(X))\n",
    "        return float(getattr(est, \"dimension_\", np.nan))\n",
    "    return _once\n",
    "\n",
    "# =============================== DATA: use existing head_dist column ===============================\n",
    "def load_head_dist_from_column(csv_path: str,\n",
    "                               head_dist_col: str = HEAD_DIST_COL,\n",
    "                               clamp: int = HEAD_DIST_CLAMP,\n",
    "                               include_zero: bool = INCLUDE_ZERO_CLASS):\n",
    "    \"\"\"\n",
    "    Expects CSV columns:\n",
    "      - sentence_id (str)\n",
    "      - tokens      (list[str]) — one row per sentence\n",
    "      - head_dist   (list[int]) — signed distances per token\n",
    "    Produces token-level rows with 'head_dist_class' in {-clamp..-1, [0], 1..clamp}.\n",
    "    \"\"\"\n",
    "    need = [\"sentence_id\", \"tokens\", head_dist_col]\n",
    "    df = pd.read_csv(csv_path, usecols=need, dtype={\"sentence_id\": str})\n",
    "    df.tokens = df.tokens.apply(_to_list)\n",
    "    df[head_dist_col] = df[head_dist_col].apply(_to_list)\n",
    "\n",
    "    rows = []\n",
    "    for sid, toks, dists in df[[\"sentence_id\",\"tokens\", head_dist_col]].itertuples(index=False):\n",
    "        L = min(len(toks), len(dists))\n",
    "        for wid in range(L):\n",
    "            try:\n",
    "                dist = int(dists[wid])\n",
    "            except Exception:\n",
    "                continue\n",
    "            if dist == 0 and not include_zero:\n",
    "                continue\n",
    "            if dist < -clamp: dist = -clamp\n",
    "            if dist >  clamp: dist =  clamp\n",
    "            rows.append((sid, wid, str(dist), toks[wid]))\n",
    "    df_tok  = pd.DataFrame(rows, columns=[\"sentence_id\",\"word_id\",\"head_dist_class\",\"word\"])\n",
    "    df_sent = df[[\"sentence_id\",\"tokens\"]].drop_duplicates(\"sentence_id\")\n",
    "    return df_sent, df_tok\n",
    "\n",
    "def sample_raw(df_tok: pd.DataFrame, per_class_cap: int = RAW_MAX_PER_CLASS) -> pd.DataFrame:\n",
    "    picks = []\n",
    "    for c, sub in df_tok.groupby(\"head_dist_class\", sort=False):\n",
    "        n = min(len(sub), per_class_cap)\n",
    "        picks.append(sub.sample(n, random_state=RAND_SEED, replace=False))\n",
    "    return pd.concat(picks, ignore_index=True)\n",
    "\n",
    "def make_dist_palette(classes: List[str]) -> Dict[str, Tuple[float, float, float]]:\n",
    "    vals = sorted([int(c) for c in classes])\n",
    "    cmap = sns.color_palette(\"coolwarm\", len(vals))\n",
    "    return {str(v): cmap[i] for i, v in enumerate(vals)}\n",
    "\n",
    "# =============================== EMBEDDING (BERT & GPT‑2) ===============================\n",
    "def embed_subset(df_sent: pd.DataFrame,\n",
    "                 subset_df: pd.DataFrame,\n",
    "                 baseline: str = BASELINE,\n",
    "                 word_rep_mode: str = WORD_REP_MODE,\n",
    "                 batch_size: int = BATCH_SIZE) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    df_sent[\"sentence_id\"]   = df_sent[\"sentence_id\"].astype(str)\n",
    "    subset_df[\"sentence_id\"] = subset_df[\"sentence_id\"].astype(str)\n",
    "\n",
    "    # sid -> list[(global_idx, word_id)]\n",
    "    by_sid: Dict[str, List[Tuple[int,int]]] = {}\n",
    "    for gidx, (sid, wid) in enumerate(subset_df[[\"sentence_id\",\"word_id\"]].itertuples(index=False)):\n",
    "        by_sid.setdefault(str(sid), []).append((gidx, int(wid)))\n",
    "\n",
    "    sids = list(by_sid.keys())\n",
    "    df_sel = (df_sent[df_sent.sentence_id.isin(sids)]\n",
    "              .drop_duplicates(\"sentence_id\")\n",
    "              .set_index(\"sentence_id\")\n",
    "              .loc[sids])\n",
    "\n",
    "    tokzr = AutoTokenizer.from_pretrained(baseline, use_fast=True)\n",
    "    enc_kwargs = dict(is_split_into_words=True, return_tensors=\"pt\", padding=True)\n",
    "    if \"add_prefix_space\" in inspect.signature(tokzr.__call__).parameters:\n",
    "        enc_kwargs[\"add_prefix_space\"] = True\n",
    "    if tokzr.pad_token is None and getattr(tokzr, \"eos_token\", None) is not None:\n",
    "        tokzr.pad_token = tokzr.eos_token\n",
    "\n",
    "    model = AutoModel.from_pretrained(baseline, output_hidden_states=True).eval().to(device)\n",
    "    if getattr(model.config, \"pad_token_id\", None) is None and tokzr.pad_token_id is not None:\n",
    "        model.config.pad_token_id = tokzr.pad_token_id\n",
    "    if device == \"cuda\": model.half()\n",
    "\n",
    "    L = _num_hidden_layers(model) + 1   # include embeddings\n",
    "    D = _hidden_size(model)\n",
    "    N = len(subset_df)\n",
    "\n",
    "    reps   = np.zeros((L, N, D), np.float16)\n",
    "    filled = np.zeros(N, dtype=bool)\n",
    "\n",
    "    with torch.no_grad(), torch.cuda.amp.autocast(device == \"cuda\"):\n",
    "        for start in tqdm(range(0, len(sids), batch_size), desc=f\"{baseline} (embed subset)\"):\n",
    "            batch_ids    = sids[start : start + batch_size]\n",
    "            batch_tokens = df_sel.loc[batch_ids, \"tokens\"].tolist()\n",
    "\n",
    "            enc_be = tokzr(batch_tokens, **enc_kwargs)\n",
    "            enc_t  = {k: v.to(device) for k, v in enc_be.items()}\n",
    "            out = model(**enc_t)\n",
    "            h = torch.stack(out.hidden_states).detach().cpu().numpy().astype(np.float32)  # (L,B,T,D)\n",
    "\n",
    "            for b, sid in enumerate(batch_ids):\n",
    "                mp = {}\n",
    "                for tidx, wid in enumerate(enc_be.word_ids(b)):\n",
    "                    if wid is not None:\n",
    "                        mp.setdefault(int(wid), []).append(int(tidx))\n",
    "\n",
    "                for gidx, wid in by_sid.get(sid, []):\n",
    "                    toks = mp.get(wid)\n",
    "                    if not toks: continue\n",
    "                    if word_rep_mode == \"first\":\n",
    "                        vec = h[:, b, toks[0], :]\n",
    "                    elif word_rep_mode == \"last\":\n",
    "                        vec = h[:, b, toks[-1], :]\n",
    "                    elif word_rep_mode == \"mean\":\n",
    "                        vec = h[:, b, toks, :].mean(axis=1)\n",
    "                    else:\n",
    "                        raise ValueError(\"WORD_REP_MODE must be one of {'first','last','mean'} (for GPT-2 use 'last' or 'mean').\")\n",
    "                    reps[:, gidx, :] = vec.astype(np.float16, copy=False)\n",
    "                    filled[gidx] = True\n",
    "\n",
    "            del enc_be, enc_t, out, h\n",
    "            if device == \"cuda\": torch.cuda.empty_cache()\n",
    "\n",
    "    missing = int((~filled).sum())\n",
    "    if missing: print(f\"⚠ Missing vectors for {missing} of {N} tokens\")\n",
    "    del model; gc.collect()\n",
    "    if device == \"cuda\": torch.cuda.empty_cache()\n",
    "    return reps, filled\n",
    "\n",
    "# =============================== BOOTSTRAP CORE ===============================\n",
    "def _bs_layer_loop(rep_sub: np.ndarray, M: int, n_reps: int, compute_once: Callable[[np.ndarray], float]):\n",
    "    L, N, D = rep_sub.shape\n",
    "    rng = np.random.default_rng(RAND_SEED)\n",
    "    A = np.full((n_reps, L), np.nan, np.float32)\n",
    "    for r in range(n_reps):\n",
    "        idx = rng.integers(0, N, size=M)\n",
    "        for l in range(L):\n",
    "            X = rep_sub[l, idx].astype(np.float32, copy=False)\n",
    "            try:\n",
    "                A[r, l] = float(compute_once(X))\n",
    "            except Exception:\n",
    "                A[r, l] = np.nan\n",
    "    mu = np.nanmean(A, axis=0).astype(np.float32)\n",
    "    lo = np.nanpercentile(A, 2.5, axis=0).astype(np.float32)\n",
    "    hi = np.nanpercentile(A, 97.5, axis=0).astype(np.float32)\n",
    "    return mu, lo, hi\n",
    "\n",
    "# ---- Metric registries ----\n",
    "FAST_ONCE: Dict[str, Callable[[np.ndarray], float]] = {\n",
    "    # Isotropy\n",
    "    \"iso\": _iso_once,\n",
    "    \"sf\": _sf_once,\n",
    "    \"vmf_kappa\": _vmf_kappa_once,   # anisotropy↑\n",
    "    \"spect\": _spect_once,           # anisotropy↑\n",
    "    \"rand\": _rand_once,             # anisotropy↑\n",
    "\n",
    "    # Linear ID (spectral)\n",
    "    \"pca95\": _pca95_once,\n",
    "    \"pca99\": _pca99_once,\n",
    "    \"erank\": _erank_once,\n",
    "    \"pr\": _pr_once,\n",
    "    \"stable_rank\": _stable_rank_once,\n",
    "}\n",
    "\n",
    "HEAVY_ONCE: Dict[str, Callable[[np.ndarray], float] | None] = {\n",
    "    # DADApy\n",
    "    \"twonn\": _dadapy_twonn_once,\n",
    "    \"gride\": _dadapy_gride_once,\n",
    "    # scikit-dimension\n",
    "    \"mom\":   _skdim_once_builder(\"mom\"),\n",
    "    \"tle\":   _skdim_once_builder(\"tle\"),\n",
    "    \"corrint\": _skdim_once_builder(\"corrint\"),\n",
    "    \"fishers\": _skdim_once_builder(\"fishers\"),\n",
    "    \"lpca\":  _skdim_once_builder(\"lpca\"),\n",
    "    \"lpca95\": _skdim_once_builder(\"lpca95\"),\n",
    "    \"lpca99\": _skdim_once_builder(\"lpca99\"),\n",
    "    \"mle\":   _skdim_once_builder(\"mle\"),\n",
    "    \"danco\": _skdim_once_builder(\"danco\"),\n",
    "    \"ess\":   _skdim_once_builder(\"ess\"),\n",
    "    \"mind_ml\": _skdim_once_builder(\"mind_ml\"),\n",
    "    \"mada\":  _skdim_once_builder(\"mada\"),\n",
    "    \"knn\":   _skdim_once_builder(\"knn\"),\n",
    "}\n",
    "\n",
    "LABELS = {\n",
    "    # Isotropy\n",
    "    \"iso\":\"IsoScore\", \"sf\":\"Spectral Flatness\",\n",
    "    \"vmf_kappa\":\"vMF κ (anisotropy↑)\", \"spect\":\"Spectral Ratio (λ_max/μ, anisotropy↑)\",\n",
    "    \"rand\":\"RandCos |μ| (anisotropy↑)\",\n",
    "    # Linear ID\n",
    "    \"pca95\":\"lPCA 0.95\", \"pca99\":\"lPCA 0.99\",\n",
    "    \"erank\":\"Effective Rank\",\"pr\":\"Participation Ratio\",\"stable_rank\":\"Stable Rank\",\n",
    "    # Non-linear\n",
    "    \"twonn\":\"TwoNN ID\",\"gride\":\"GRIDE\",\n",
    "    \"mom\":\"MOM\",\"tle\":\"TLE\",\"corrint\":\"CorrInt\",\"fishers\":\"FisherS\",\n",
    "    \"lpca\":\"lPCA FO\",\"lpca95\":\"lPCA 0.95 (skdim)\",\"lpca99\":\"lPCA 0.99 (skdim)\",\n",
    "    \"mle\":\"MLE\",\"danco\":\"DANCo\",\"ess\":\"ESS\",\"mind_ml\":\"MiND_ML\",\"mada\":\"MADA\",\"knn\":\"KNN\",\n",
    "}\n",
    "\n",
    "# Compute them all by default\n",
    "#ALL_METRICS = list(LABELS.keys())\n",
    "ALL_METRICS = [\"gride\", \"iso\", \"lpca99\"]\n",
    "\n",
    "# =============================== SAVE / PLOT ===============================\n",
    "def save_metric_csv_all_classes(metric: str,\n",
    "                                class_to_stats: Dict[str, Dict[str, np.ndarray]],\n",
    "                                layers: np.ndarray,\n",
    "                                baseline: str,\n",
    "                                subset_name: str = \"raw\"):\n",
    "    rows = []\n",
    "    for c, stats in class_to_stats.items():\n",
    "        mu, lo, hi = stats[\"mean\"], stats.get(\"lo\"), stats.get(\"hi\")\n",
    "        for l, val in enumerate(mu):\n",
    "            rows.append({\n",
    "                \"subset\": subset_name, \"model\": baseline, \"feature\": \"head_dist\",\n",
    "                \"class\": c, \"metric\": metric, \"layer\": int(layers[l]),\n",
    "                \"mean\": float(val) if np.isfinite(val) else np.nan,\n",
    "                \"ci_low\": float(lo[l]) if isinstance(lo, np.ndarray) and np.isfinite(lo[l]) else np.nan,\n",
    "                \"ci_high\": float(hi[l]) if isinstance(hi, np.ndarray) and np.isfinite(hi[l]) else np.nan,\n",
    "                \"n_tokens\": int(stats.get(\"n\", 0)),\n",
    "                \"word_rep_mode\": WORD_REP_MODE,\n",
    "                \"source_csv\": Path(CSV_PATH).name,\n",
    "            })\n",
    "    df = pd.DataFrame(rows)\n",
    "    out = CSV_DIR / f\"headdist_{subset_name}_{metric}_{baseline}.csv\"\n",
    "    df.to_csv(out, index=False)\n",
    "\n",
    "def plot_metric_with_ci(class_to_stats: Dict[str, Dict[str, np.ndarray]],\n",
    "                        layers: np.ndarray, metric: str, title: str, out_path: Path,\n",
    "                        palette: Dict[str, Tuple[float, float, float]] | None = None):\n",
    "    plt.figure(figsize=(9, 5))\n",
    "    for c in sorted(class_to_stats.keys(), key=lambda s: int(s)):\n",
    "        stats = class_to_stats[c]\n",
    "        mu, lo, hi = stats[\"mean\"], stats.get(\"lo\"), stats.get(\"hi\")\n",
    "        if mu is None or np.all(np.isnan(mu)): continue\n",
    "        color = palette.get(c) if isinstance(palette, dict) else None\n",
    "        plt.plot(layers, mu, label=c, lw=1.8, color=color)\n",
    "        if isinstance(lo, np.ndarray) and isinstance(hi, np.ndarray) and not np.all(np.isnan(lo)):\n",
    "            plt.fill_between(layers, lo, hi, alpha=0.15, color=color)\n",
    "    plt.xlabel(\"Layer\"); plt.ylabel(LABELS.get(metric, metric.upper())); plt.title(title)\n",
    "    plt.legend(ncol=4, fontsize=\"small\", title=\"Head distance (−6 … 6)\", frameon=False)\n",
    "    plt.tight_layout(); plt.savefig(out_path, dpi=220); plt.close()\n",
    "\n",
    "# =============================== DRIVER ===============================\n",
    "def run_headdist_from_col_pipeline():\n",
    "    # 1) Load token lists + distance classes from existing column\n",
    "    df_sent, hd_df = load_head_dist_from_column(\n",
    "        CSV_PATH, head_dist_col=HEAD_DIST_COL,\n",
    "        clamp=HEAD_DIST_CLAMP, include_zero=INCLUDE_ZERO_CLASS\n",
    "    )\n",
    "    classes = sorted(hd_df.head_dist_class.unique(), key=lambda s: int(s))\n",
    "    palette = make_dist_palette(classes)\n",
    "    print(f\"✓ corpus ready — {len(hd_df):,} tokens across head-dist classes {classes}\")\n",
    "\n",
    "    # 2) Optional per-class cap (currently unlimited for fast metrics)\n",
    "    raw_df = sample_raw(hd_df, RAW_MAX_PER_CLASS)\n",
    "    print(\"Sample sizes per head distance (raw cap):\")\n",
    "    counts = raw_df.head_dist_class.value_counts()\n",
    "    counts = counts.reindex(sorted(counts.index, key=lambda x: int(x)))\n",
    "    print(counts.to_dict())\n",
    "    # Warn if heavy estimators may be unreliable for small classes\n",
    "    too_small = {c:int(n) for c,n in counts.items() if n < MIN_N_FOR_HEAVY_WARN}\n",
    "    if too_small:\n",
    "        print(f\"⚠ Some classes have < {MIN_N_FOR_HEAVY_WARN} tokens (heavy ID may be noisy): {too_small}\")\n",
    "\n",
    "    # 3) Embed once\n",
    "    reps, filled = embed_subset(df_sent, raw_df, BASELINE, WORD_REP_MODE, BATCH_SIZE)\n",
    "    raw_df = raw_df.reset_index(drop=True).loc[filled].reset_index(drop=True)\n",
    "    cls_arr = raw_df.head_dist_class.values\n",
    "    L = reps.shape[0]; layers = np.arange(L)\n",
    "    print(f\"✓ embedded {len(raw_df):,} tokens  • layers={L}\")\n",
    "\n",
    "    # 4) Metric loop\n",
    "    for metric in ALL_METRICS:\n",
    "        print(f\"\\n→ Computing metric: {metric} …\")\n",
    "        compute_once = FAST_ONCE.get(metric) or HEAVY_ONCE.get(metric)\n",
    "        if compute_once is None:\n",
    "            print(f\"  (skipping {metric}: estimator unavailable)\")\n",
    "            continue\n",
    "        n_bs = N_BOOTSTRAP_FAST if metric in FAST_ONCE else N_BOOTSTRAP_HEAVY\n",
    "        Mcap = FAST_BS_MAX_SAMP_PER_CLASS if metric in FAST_ONCE else HEAVY_BS_MAX_SAMP_PER_CLASS\n",
    "\n",
    "        class_results: Dict[str, Dict[str, np.ndarray]] = {}\n",
    "        for c in classes:\n",
    "            idx = np.where(cls_arr == c)[0]\n",
    "            if idx.size < 3:\n",
    "                continue\n",
    "            sub = reps[:, idx]  # (L, n_c, D)\n",
    "            Nc = sub.shape[1]\n",
    "            M = min(Mcap, Nc)\n",
    "            mu, lo, hi = _bs_layer_loop(sub, M, n_bs, compute_once)\n",
    "            class_results[c] = {\"mean\": mu, \"lo\": lo, \"hi\": hi, \"n\": int(Nc)}\n",
    "\n",
    "        save_metric_csv_all_classes(metric, class_results, layers, BASELINE, subset_name=\"raw\")\n",
    "        plot_metric_with_ci(class_results, layers, metric,\n",
    "                            title=f\"{LABELS.get(metric, metric.upper())} • {BASELINE}\",\n",
    "                            out_path=PLOT_DIR / f\"headdist_raw_{metric}_{BASELINE}.png\",\n",
    "                            palette=palette)\n",
    "        print(f\"  ✓ saved: CSV= {CSV_DIR}/headdist_raw_{metric}_{BASELINE}.csv  \"\n",
    "              f\"plot= {PLOT_DIR}/headdist_raw_{metric}_{BASELINE}.png\")\n",
    "\n",
    "        del class_results; gc.collect()\n",
    "        if device == \"cuda\": torch.cuda.empty_cache()\n",
    "\n",
    "    del reps; gc.collect()\n",
    "    if device == \"cuda\": torch.cuda.empty_cache()\n",
    "    print(\"\\n✓ done (incremental outputs produced per metric).\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_headdist_from_col_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70a63d61-1087-4113-ba46-bb94c0b0fa16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ plotting subset — 194,916 tokens across head-dist classes ['-6', '-5', '-4', '-3', '-2', '-1', '0', '1', '2', '3', '4', '5', '6']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-07 21:46:51.438609: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/tmp/ipykernel_2156630/1057072974.py:176: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast(device == \"cuda\"):\n",
      "openai-community/gpt2 (embed subset): 100%|█| 5034/5034 [01:03<00:00, 78.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA plotting on 194,916 tokens across 13 layers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f6ccf186380>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ldomenichelli/venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 365\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 365\u001b[0m     \u001b[43mrun_pca3d_head_dist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 351\u001b[0m, in \u001b[0;36mrun_pca3d_head_dist\u001b[0;34m()\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;66;03m# 4) PCA→3D per layer + Plotly (HTML path built AFTER model id is resolved)\u001b[39;00m\n\u001b[1;32m    350\u001b[0m html_out \u001b[38;5;241m=\u001b[39m OUT_DIR \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolved_id\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_head_dist_pca3d_layers.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 351\u001b[0m \u001b[43mpca3d_by_head_dist_and_plot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcls_arr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_tag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolved_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhtml_out\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhtml_out\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;66;03m# Cleanup\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m reps; gc\u001b[38;5;241m.\u001b[39mcollect()\n",
      "Cell \u001b[0;32mIn[1], line 259\u001b[0m, in \u001b[0;36mpca3d_by_head_dist_and_plot\u001b[0;34m(reps, words, classes_arr, all_classes, model_tag, html_out)\u001b[0m\n\u001b[1;32m    257\u001b[0m Y_layers: List[np\u001b[38;5;241m.\u001b[39mndarray] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(L):\n\u001b[0;32m--> 259\u001b[0m     Y_layers\u001b[38;5;241m.\u001b[39mappend(\u001b[43m_pca3d_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreps\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# (N,3)\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# Distinct colors for each class\u001b[39;00m\n\u001b[1;32m    262\u001b[0m cmap \u001b[38;5;241m=\u001b[39m distinct_hsl_palette(all_classes)\n",
      "Cell \u001b[0;32mIn[1], line 221\u001b[0m, in \u001b[0;36m_pca3d_layer\u001b[0;34m(X, n_components)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Lightweight PCA to 3D without external deps. Returns Y in R^{n x 3}.\"\"\"\u001b[39;00m\n\u001b[1;32m    220\u001b[0m X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 221\u001b[0m Xc \u001b[38;5;241m=\u001b[39m X \u001b[38;5;241m-\u001b[39m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;66;03m# economy SVD: Xc = U S V^T → take first 3 comps\u001b[39;00m\n\u001b[1;32m    223\u001b[0m U, S, _ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39msvd(Xc, full_matrices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/numpy/core/_methods.py:118\u001b[0m, in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    115\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m mu\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    116\u001b[0m         is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, mu\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _no_nep50_warning():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import os, gc, ast, random, inspect\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Plotly (interactive)\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# =============================== CONFIG ===============================\n",
    "CSV_PATH      = \"en_ewt-ud-train_sentences.csv\"  # needs: sentence_id, tokens (list[str]), head_dist (list[int])\n",
    "BASELINE      = \"gpt2\"              # or \"gpt2\"\n",
    "WORD_REP_MODE = \"last\"                          # BERT: {\"first\",\"last\",\"mean\"}; GPT-2: {\"last\",\"mean\"}\n",
    "\n",
    "HEAD_DIST_COL       = \"head_dist\"  # list[int], token-aligned per sentence\n",
    "HEAD_DIST_CLAMP     = 6            # bucket distances to [-6,6]\n",
    "INCLUDE_ZERO_CLASS  = True        # include the \"0\" class or not\n",
    "\n",
    "# Plot subsampling per class (for browser smoothness)\n",
    "PCA_MAX_PER_CLASS   = None   # set None for \"all\"; 2k-5k per class keeps things fast\n",
    "\n",
    "# Output\n",
    "OUT_DIR = Path(\"pca3d_head_dist\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Throughput / device\n",
    "BATCH_SIZE = 2\n",
    "RAND_SEED  = 42\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "random.seed(RAND_SEED); np.random.seed(RAND_SEED); torch.manual_seed(RAND_SEED)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"cuda\":\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# =============================== HELPERS ===============================\n",
    "def _to_list(x):\n",
    "    return ast.literal_eval(x) if isinstance(x, str) and x.startswith(\"[\") else x\n",
    "\n",
    "def _num_hidden_layers(model) -> int:\n",
    "    n = getattr(model.config, \"num_hidden_layers\", None)\n",
    "    if n is None: n = getattr(model.config, \"n_layer\", None)  # GPT-2\n",
    "    if n is None: raise ValueError(\"Cannot determine num_hidden_layers\")\n",
    "    return int(n)\n",
    "\n",
    "def _hidden_size(model) -> int:\n",
    "    d = getattr(model.config, \"hidden_size\", None)\n",
    "    if d is None: d = getattr(model.config, \"n_embd\", None)  # GPT-2\n",
    "    if d is None: raise ValueError(\"Cannot determine hidden size\")\n",
    "    return int(d)\n",
    "\n",
    "def _require_csv(path_like) -> Path:\n",
    "    \"\"\"Fail early with a clear message if CSV_PATH is None or missing.\"\"\"\n",
    "    if path_like is None:\n",
    "        raise TypeError(\"CSV_PATH is None — please set CSV_PATH to your dataset CSV filename.\")\n",
    "    p = Path(path_like)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"CSV_PATH does not exist: {p.resolve()}\")\n",
    "    return p\n",
    "\n",
    "def load_head_dist_from_column(csv_path: str,\n",
    "                               head_dist_col: str = HEAD_DIST_COL,\n",
    "                               clamp: int = HEAD_DIST_CLAMP,\n",
    "                               include_zero: bool = INCLUDE_ZERO_CLASS):\n",
    "    \"\"\"\n",
    "    Load sentence-level rows with 'tokens' (list[str]) and 'head_dist' (list[int]),\n",
    "    emit token-level rows with 'head_dist_class' in {-clamp..-1, [0], 1..clamp}.\n",
    "    \"\"\"\n",
    "    csv_file = _require_csv(csv_path)\n",
    "    need = [\"sentence_id\", \"tokens\", head_dist_col]\n",
    "    df = pd.read_csv(csv_file, usecols=need, dtype={\"sentence_id\": str})\n",
    "    df.tokens = df.tokens.apply(_to_list)\n",
    "    df[head_dist_col] = df[head_dist_col].apply(_to_list)\n",
    "\n",
    "    rows = []\n",
    "    for sid, toks, dists in df[[\"sentence_id\",\"tokens\", head_dist_col]].itertuples(index=False):\n",
    "        L = min(len(toks), len(dists))\n",
    "        for wid in range(L):\n",
    "            try:\n",
    "                dist = int(dists[wid])\n",
    "            except Exception:\n",
    "                continue\n",
    "            if dist == 0 and not include_zero:\n",
    "                continue\n",
    "            if dist < -clamp: dist = -clamp\n",
    "            if dist >  clamp: dist =  clamp\n",
    "            rows.append((sid, wid, str(dist), toks[wid]))\n",
    "    df_tok  = pd.DataFrame(rows, columns=[\"sentence_id\",\"word_id\",\"head_dist_class\",\"word\"])\n",
    "    df_sent = df[[\"sentence_id\",\"tokens\"]].drop_duplicates(\"sentence_id\")\n",
    "    if df_tok.empty:\n",
    "        raise ValueError(\"No token rows constructed—check your head_dist column.\")\n",
    "    return df_sent, df_tok\n",
    "\n",
    "def sample_per_class(df_tok: pd.DataFrame, per_class_cap: int | None) -> pd.DataFrame:\n",
    "    \"\"\"Optional per-class subsample for plotting.\"\"\"\n",
    "    if per_class_cap is None:\n",
    "        return df_tok.reset_index(drop=True)\n",
    "    picks = []\n",
    "    for c, sub in df_tok.groupby(\"head_dist_class\", sort=False):\n",
    "        n = min(len(sub), per_class_cap)\n",
    "        picks.append(sub.sample(n, random_state=RAND_SEED, replace=False))\n",
    "    return pd.concat(picks, ignore_index=True)\n",
    "\n",
    "def _load_tok_and_model(model_id: str):\n",
    "    \"\"\"\n",
    "    Robust loader for both encoder and decoder families.\n",
    "    Ensures right-padding and PAD token for GPT-2-like tokenizers.\n",
    "    Returns (tokenizer, model, resolved_model_id:str).\n",
    "    \"\"\"\n",
    "    tried = []\n",
    "    candidates = [model_id]\n",
    "    # Robust GPT-2 fallback aliases\n",
    "    if model_id.lower() in {\"gpt2\", \"gpt-2\"}:\n",
    "        candidates += [\"openai-community/gpt2\", \"gpt2\"]\n",
    "\n",
    "    for mid in candidates:\n",
    "        try:\n",
    "            tok = AutoTokenizer.from_pretrained(mid, use_fast=True, add_prefix_space=True)\n",
    "            if getattr(tok, \"padding_side\", None) != \"right\":\n",
    "                tok.padding_side = \"right\"\n",
    "            if tok.pad_token is None and getattr(tok, \"eos_token\", None) is not None:\n",
    "                tok.pad_token = tok.eos_token\n",
    "\n",
    "            mdl = AutoModel.from_pretrained(mid, output_hidden_states=True)\n",
    "            if getattr(mdl.config, \"pad_token_id\", None) is None and tok.pad_token_id is not None:\n",
    "                mdl.config.pad_token_id = tok.pad_token_id\n",
    "\n",
    "            mdl = mdl.eval().to(device)\n",
    "            if device == \"cuda\":\n",
    "                mdl.half()\n",
    "            return tok, mdl, mid  # <- resolved id (string) for filenames\n",
    "        except Exception as e:\n",
    "            tried.append((mid, repr(e)))\n",
    "            continue\n",
    "    raise RuntimeError(\n",
    "        \"Could not load tokenizer/model. Attempts:\\n\" +\n",
    "        \"\\n\".join(f\" - {m}: {err}\" for m, err in tried)\n",
    "    )\n",
    "\n",
    "def embed_subset(df_sent: pd.DataFrame,\n",
    "                 subset_df: pd.DataFrame,\n",
    "                 baseline: str = BASELINE,\n",
    "                 word_rep_mode: str = WORD_REP_MODE,\n",
    "                 batch_size: int = BATCH_SIZE) -> Tuple[np.ndarray, np.ndarray, str]:\n",
    "    \"\"\"\n",
    "    Return (reps (L,N,D), filled mask (N,), resolved_model_id:str).\n",
    "    \"\"\"\n",
    "    df_sent[\"sentence_id\"]   = df_sent[\"sentence_id\"].astype(str)\n",
    "    subset_df[\"sentence_id\"] = subset_df[\"sentence_id\"].astype(str)\n",
    "\n",
    "    by_sid: Dict[str, List[Tuple[int,int]]] = {}\n",
    "    for gidx, (sid, wid) in enumerate(subset_df[[\"sentence_id\",\"word_id\"]].itertuples(index=False)):\n",
    "        by_sid.setdefault(str(sid), []).append((gidx, int(wid)))\n",
    "\n",
    "    sids = list(by_sid.keys())\n",
    "    df_sel = (df_sent[df_sent.sentence_id.isin(sids)]\n",
    "              .drop_duplicates(\"sentence_id\")\n",
    "              .set_index(\"sentence_id\")\n",
    "              .loc[sids])\n",
    "\n",
    "    tokzr, model, resolved_id = _load_tok_and_model(baseline)\n",
    "    enc_kwargs = dict(is_split_into_words=True, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    if \"add_prefix_space\" in inspect.signature(tokzr.__call__).parameters:\n",
    "        enc_kwargs[\"add_prefix_space\"] = True\n",
    "\n",
    "    L = _num_hidden_layers(model) + 1   # include embeddings\n",
    "    D = _hidden_size(model)\n",
    "    N = len(subset_df)\n",
    "\n",
    "    reps   = np.zeros((L, N, D), np.float16)\n",
    "    filled = np.zeros(N, dtype=bool)\n",
    "\n",
    "    with torch.no_grad(), torch.cuda.amp.autocast(device == \"cuda\"):\n",
    "        for start in tqdm(range(0, len(sids), batch_size), desc=f\"{resolved_id} (embed subset)\"):\n",
    "            batch_ids    = sids[start : start + batch_size]\n",
    "            batch_tokens = df_sel.loc[batch_ids, \"tokens\"].tolist()\n",
    "\n",
    "            enc_be = tokzr(batch_tokens, **enc_kwargs)\n",
    "            enc_t  = {k: v.to(device) for k, v in enc_be.items()}\n",
    "            out = model(**enc_t)\n",
    "            h = torch.stack(out.hidden_states).detach().cpu().numpy().astype(np.float32)  # (L,B,T,D)\n",
    "\n",
    "            for b, sid in enumerate(batch_ids):\n",
    "                mp = {}\n",
    "                wids = enc_be.word_ids(b)\n",
    "                if wids is None:\n",
    "                    raise RuntimeError(\"Fast tokenizer required (word_ids unavailable).\")\n",
    "                for tidx, wid in enumerate(wids):\n",
    "                    if wid is not None:\n",
    "                        mp.setdefault(int(wid), []).append(int(tidx))\n",
    "\n",
    "                for gidx, wid in by_sid.get(sid, []):\n",
    "                    toks = mp.get(wid)\n",
    "                    if not toks: continue\n",
    "                    if word_rep_mode == \"first\":\n",
    "                        vec = h[:, b, toks[0], :]\n",
    "                    elif word_rep_mode == \"last\":\n",
    "                        vec = h[:, b, toks[-1], :]\n",
    "                    elif word_rep_mode == \"mean\":\n",
    "                        vec = h[:, b, toks, :].mean(axis=1)\n",
    "                    else:\n",
    "                        raise ValueError(\"WORD_REP_MODE must be in {'first','last','mean'}.\")\n",
    "                    reps[:, gidx, :] = vec.astype(np.float16, copy=False)\n",
    "                    filled[gidx] = True\n",
    "\n",
    "            del enc_be, enc_t, out, h\n",
    "            if device == \"cuda\":\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "    if device == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "    return reps, filled, resolved_id\n",
    "\n",
    "# =============================== PCA 3D PER LAYER (Plotly) ===============================\n",
    "def _pca3d_layer(X: np.ndarray, n_components: int = 3) -> np.ndarray:\n",
    "    \"\"\"Lightweight PCA to 3D without external deps. Returns Y in R^{n x 3}.\"\"\"\n",
    "    X = X.astype(np.float32, copy=False)\n",
    "    Xc = X - X.mean(0, keepdims=True)\n",
    "    # economy SVD: Xc = U S V^T → take first 3 comps\n",
    "    U, S, _ = np.linalg.svd(Xc, full_matrices=False)\n",
    "    return (U[:, :n_components] * S[:n_components]).astype(np.float32, copy=False)\n",
    "\n",
    "def distinct_hsl_palette(classes: List[str]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Return a distinct color for each class using evenly spaced HSL hues.\n",
    "    Plotly accepts CSS color strings like 'hsl(210, 65%, 50%)'.\n",
    "    \"\"\"\n",
    "    ordered = sorted(classes, key=lambda s: int(s))\n",
    "    n = len(ordered) if len(ordered) > 0 else 1\n",
    "    cmap = {}\n",
    "    for i, c in enumerate(ordered):\n",
    "        hue = int(round(360.0 * i / n)) % 360\n",
    "        cmap[c] = f\"hsl({hue}, 65%, 50%)\"\n",
    "    return cmap\n",
    "\n",
    "def pca3d_by_head_dist_and_plot(reps: np.ndarray,\n",
    "                                words: List[str],\n",
    "                                classes_arr: np.ndarray,\n",
    "                                all_classes: List[str],\n",
    "                                model_tag: str,\n",
    "                                html_out: Path):\n",
    "    \"\"\"\n",
    "    reps: (L, N, D), words: list[str] length N\n",
    "    classes_arr: array of class labels (str) per token\n",
    "    Build one 3D scatter trace per class per layer; a slider toggles layers.\n",
    "    \"\"\"\n",
    "    if html_out is None:\n",
    "        raise TypeError(\"html_out is None — provide a valid Path for the HTML file.\")\n",
    "\n",
    "    L, N, D = reps.shape\n",
    "    print(f\"PCA plotting on {N:,} tokens across {L} layers...\")\n",
    "\n",
    "    # PCA→3D per layer on ALL selected points (keeps axes consistent within the layer)\n",
    "    Y_layers: List[np.ndarray] = []\n",
    "    for l in range(L):\n",
    "        Y_layers.append(_pca3d_layer(reps[l]))  # (N,3)\n",
    "\n",
    "    # Distinct colors for each class\n",
    "    cmap = distinct_hsl_palette(all_classes)\n",
    "\n",
    "    # Build traces: (layer, class) pairs\n",
    "    traces = []\n",
    "    for l in range(L):\n",
    "        Y = Y_layers[l]\n",
    "        for c in all_classes:\n",
    "            mask = (classes_arr == c)\n",
    "            if not np.any(mask):\n",
    "                x = y = z = []\n",
    "                hover = []\n",
    "            else:\n",
    "                idx = np.where(mask)[0]\n",
    "                x, y, z = Y[idx, 0], Y[idx, 1], Y[idx, 2]\n",
    "                hover = [f\"{words[i]} | hd={c}\" for i in idx]\n",
    "            traces.append(\n",
    "                go.Scatter3d(\n",
    "                    x=x, y=y, z=z,\n",
    "                    mode=\"markers\",\n",
    "                    marker=dict(size=2, opacity=0.75, color=cmap[c]),\n",
    "                    name=str(c),\n",
    "                    hovertext=hover,\n",
    "                    hovertemplate=\"<b>%{hovertext}</b><br>\"\n",
    "                                  \"x=%{x:.3f}<br>y=%{y:.3f}<br>z=%{z:.3f}\"\n",
    "                                  \"<extra></extra>\",\n",
    "                    visible=(l == 0),\n",
    "                    showlegend=(l == 0),\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # Slider steps (one per layer)\n",
    "    traces_per_layer = len(all_classes)\n",
    "    steps = []\n",
    "    for l in range(L):\n",
    "        vis = [False] * (L * traces_per_layer)\n",
    "        s = slice(l * traces_per_layer, (l + 1) * traces_per_layer)\n",
    "        for k in range(*s.indices(len(vis))):\n",
    "            vis[k] = True\n",
    "        steps.append(dict(\n",
    "            method=\"update\",\n",
    "            args=[{\"visible\": vis},\n",
    "                  {\"title\": f\"{model_tag} • PCA 3D by head_dist • Layer {l} (drag to rotate)\"}],\n",
    "            label=str(l),\n",
    "        ))\n",
    "\n",
    "    sliders = [dict(\n",
    "        active=0,\n",
    "        steps=steps,\n",
    "        currentvalue={\"prefix\": \"Layer: \"},\n",
    "        pad={\"t\": 10}\n",
    "    )]\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title=f\"{model_tag} • PCA 3D by head_dist • Layer 0 (drag to rotate)\",\n",
    "        scene=dict(xaxis_title=\"PC1\", yaxis_title=\"PC2\", zaxis_title=\"PC3\", aspectmode=\"data\"),\n",
    "        margin=dict(l=0, r=0, b=0, t=40),\n",
    "        sliders=sliders,\n",
    "        showlegend=True,\n",
    "        legend=dict(title=\"head_dist class\")\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=traces, layout=layout)\n",
    "    fig.show()\n",
    "    # Convert Path → str explicitly to avoid any pathlike/None confusion\n",
    "    fig.write_html(str(html_out), include_plotlyjs=\"cdn\")\n",
    "    print(\"✓ Saved interactive HTML to:\", html_out)\n",
    "\n",
    "# =============================== DRIVER ===============================\n",
    "def run_pca3d_head_dist():\n",
    "    # 1) Load token lists + head_dist classes\n",
    "    df_sent, hd_df = load_head_dist_from_column(\n",
    "        CSV_PATH, head_dist_col=HEAD_DIST_COL,\n",
    "        clamp=HEAD_DIST_CLAMP, include_zero=INCLUDE_ZERO_CLASS\n",
    "    )\n",
    "    # 2) (Optional) subsample per class for plotting\n",
    "    raw_df = sample_per_class(hd_df, PCA_MAX_PER_CLASS)\n",
    "    classes = sorted(raw_df.head_dist_class.unique(), key=lambda s: int(s))\n",
    "    print(f\"✓ plotting subset — {len(raw_df):,} tokens across head-dist classes {classes}\")\n",
    "\n",
    "    # 3) Embed once\n",
    "    reps, filled, resolved_id = embed_subset(df_sent, raw_df, BASELINE, WORD_REP_MODE, BATCH_SIZE)\n",
    "    raw_df = raw_df.reset_index(drop=True).loc[filled].reset_index(drop=True)\n",
    "\n",
    "    # Prepare labels and words\n",
    "    cls_arr = raw_df.head_dist_class.values.astype(str)\n",
    "    words   = raw_df.word.astype(str).tolist()\n",
    "\n",
    "    # 4) PCA→3D per layer + Plotly (HTML path built AFTER model id is resolved)\n",
    "    html_out = OUT_DIR / f\"{resolved_id.replace('/', '_')}_head_dist_pca3d_layers.html\"\n",
    "    pca3d_by_head_dist_and_plot(\n",
    "        reps.astype(np.float32, copy=False),\n",
    "        words,\n",
    "        cls_arr,\n",
    "        classes,\n",
    "        model_tag=resolved_id,\n",
    "        html_out=html_out\n",
    "    )\n",
    "\n",
    "    # Cleanup\n",
    "    del reps; gc.collect()\n",
    "    if device == \"cuda\": torch.cuda.empty_cache()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_pca3d_head_dist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a150898b-d6eb-416d-9830-c9d2cd5334fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ corpus ready — 175,934 tokens across head-dist classes ['-6', '-5', '-4', '-3', '-2', '-1', '1', '2', '3', '4', '5', '6']\n",
      "Sample sizes per head distance (raw cap):\n",
      "{'-6': 19585, '-5': 4545, '-4': 6684, '-3': 10487, '-2': 15690, '-1': 13038, '1': 53836, '2': 26199, '3': 12161, '4': 5719, '5': 2883, '6': 5107}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "openai-community/gpt2 (embed subset): 100%|█| 10067/10067 [01:31<00:00, 110.37it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ embedded 175,934 tokens  • layers=13\n",
      "\n",
      "→ Computing metric: pca99 …\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 523\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m✓ done (incremental outputs produced per metric).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 523\u001b[0m     \u001b[43mrun_headdist_from_col_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 504\u001b[0m, in \u001b[0;36mrun_headdist_from_col_pipeline\u001b[0;34m()\u001b[0m\n\u001b[1;32m    502\u001b[0m     Nc \u001b[38;5;241m=\u001b[39m sub\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    503\u001b[0m     M \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(Mcap, Nc)\n\u001b[0;32m--> 504\u001b[0m     mu, lo, hi \u001b[38;5;241m=\u001b[39m \u001b[43m_bs_layer_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_bs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_once\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m     class_results[c] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m: mu, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlo\u001b[39m\u001b[38;5;124m\"\u001b[39m: lo, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhi\u001b[39m\u001b[38;5;124m\"\u001b[39m: hi, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mint\u001b[39m(Nc)}\n\u001b[1;32m    507\u001b[0m save_metric_csv_all_classes(metric, class_results, layers, BASELINE, subset_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 289\u001b[0m, in \u001b[0;36m_bs_layer_loop\u001b[0;34m(rep_sub, M, n_reps, compute_once)\u001b[0m\n\u001b[1;32m    287\u001b[0m X \u001b[38;5;241m=\u001b[39m rep_sub[l, idx]\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 289\u001b[0m     A[r, l] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[43mcompute_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    291\u001b[0m     A[r, l] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan\n",
      "Cell \u001b[0;32mIn[2], line 350\u001b[0m, in \u001b[0;36m_pca99_once\u001b[0;34m(X)\u001b[0m\n\u001b[0;32m--> 350\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pca99_once\u001b[39m(X: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_pcaXX_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.99\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 344\u001b[0m, in \u001b[0;36m_pcaXX_once\u001b[0;34m(X, var_ratio)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pcaXX_once\u001b[39m(X: np\u001b[38;5;241m.\u001b[39mndarray, var_ratio: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m--> 344\u001b[0m     lam \u001b[38;5;241m=\u001b[39m \u001b[43m_eigvals_from_X\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lam\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan\n\u001b[1;32m    346\u001b[0m     c \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcumsum(lam); thr \u001b[38;5;241m=\u001b[39m c[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m var_ratio\n",
      "Cell \u001b[0;32mIn[2], line 62\u001b[0m, in \u001b[0;36m_eigvals_from_X\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     60\u001b[0m Xc \u001b[38;5;241m=\u001b[39m _center(X\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 62\u001b[0m     _, S, _ \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_matrices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     lam \u001b[38;5;241m=\u001b[39m (S\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m     64\u001b[0m     lam\u001b[38;5;241m.\u001b[39msort()\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/numpy/linalg/linalg.py:1681\u001b[0m, in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, hermitian)\u001b[0m\n\u001b[1;32m   1678\u001b[0m         gufunc \u001b[38;5;241m=\u001b[39m _umath_linalg\u001b[38;5;241m.\u001b[39msvd_n_s\n\u001b[1;32m   1680\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->DdD\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->ddd\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1681\u001b[0m u, s, vh \u001b[38;5;241m=\u001b[39m \u001b[43mgufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1682\u001b[0m u \u001b[38;5;241m=\u001b[39m u\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1683\u001b[0m s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mastype(_realType(result_t), copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import os, gc, ast, random, inspect\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Callable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import AutoTokenizer, AutoModel, GPT2TokenizerFast\n",
    "\n",
    "# =============================== CONFIG ===============================\n",
    "CSV_PATH      = \"en_ewt-ud-train_sentences.csv\"  # <--- set to your actual file path\n",
    "HEAD_DIST_COL = \"head_dist\"                      # list[int] column with signed head distances\n",
    "BASELINE      = \"gpt2\"                           # \"gpt2\" or \"openai-community/gpt2\" or any HF id\n",
    "WORD_REP_MODE = \"last\"                           # GPT-2: {\"last\",\"mean\"}; BERT: {\"first\",\"last\",\"mean\"}\n",
    "\n",
    "# Remove the **first** token in every sentence (0-based index == 0)\n",
    "EXCLUDE_FIRST_TOKEN = True\n",
    "\n",
    "# Sampling / bootstrap\n",
    "RAW_MAX_PER_CLASS           = int(1e12)  # no cap for fast metrics\n",
    "N_BOOTSTRAP_FAST            = 50\n",
    "N_BOOTSTRAP_HEAVY           = 20\n",
    "FAST_BS_MAX_SAMP_PER_CLASS  = int(1e12)  # M = N (classic bootstrap)\n",
    "HEAVY_BS_MAX_SAMP_PER_CLASS = 5000       # practical for TwoNN/GRIDE/skdim\n",
    "MIN_N_FOR_HEAVY_WARN        = 1000\n",
    "\n",
    "# Head-distance classes config\n",
    "HEAD_DIST_CLAMP    = 6       # clamp to [-6, 6]\n",
    "INCLUDE_ZERO_CLASS = False   # include \"0\" class or not\n",
    "\n",
    "# Output\n",
    "RAND_SEED = 42\n",
    "PLOT_DIR  = Path(\"results_HEADDIST_no_index\"); PLOT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "CSV_DIR   = Path(\"tables_HEADDIST_no_index\") / \"headdist_bootstrap\"; CSV_DIR.mkdir(exist_ok=True, parents=True)\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# Repro & device\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "random.seed(RAND_SEED); np.random.seed(RAND_SEED); torch.manual_seed(RAND_SEED)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"cuda\": torch.backends.cudnn.benchmark = True\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "EPS = 1e-12\n",
    "\n",
    "# =============================== HELPERS ===============================\n",
    "def _to_list(x):\n",
    "    return ast.literal_eval(x) if isinstance(x, str) and x.startswith(\"[\") else x\n",
    "\n",
    "def _center(X: np.ndarray) -> np.ndarray:\n",
    "    return X - X.mean(0, keepdims=True)\n",
    "\n",
    "def _eigvals_from_X(X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Eigenvalues of covariance up to a constant via SVD of centered X (descending).\"\"\"\n",
    "    Xc = _center(X.astype(np.float32, copy=False))\n",
    "    try:\n",
    "        _, S, _ = np.linalg.svd(Xc, full_matrices=False)\n",
    "        lam = (S**2).astype(np.float64)\n",
    "        lam.sort()\n",
    "        return lam[::-1]\n",
    "    except Exception:\n",
    "        return np.array([], dtype=np.float64)\n",
    "\n",
    "def _jitter_unique(X: np.ndarray, eps: float = 1e-6) -> np.ndarray:\n",
    "    \"\"\"Add tiny noise if there are duplicate rows (helps NN-based estimators).\"\"\"\n",
    "    try:\n",
    "        if np.unique(X, axis=0).shape[0] < X.shape[0]:\n",
    "            X = X + np.random.normal(scale=eps, size=X.shape).astype(X.dtype)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return X\n",
    "\n",
    "def _num_hidden_layers(model) -> int:\n",
    "    n = getattr(model.config, \"num_hidden_layers\", None)\n",
    "    if n is None: n = getattr(model.config, \"n_layer\", None)  # GPT-2\n",
    "    if n is None: raise ValueError(\"Cannot determine number of hidden layers from model.config\")\n",
    "    return int(n)\n",
    "\n",
    "def _hidden_size(model) -> int:\n",
    "    d = getattr(model.config, \"hidden_size\", None)\n",
    "    if d is None: d = getattr(model.config, \"n_embd\", None)  # GPT-2\n",
    "    if d is None: raise ValueError(\"Cannot determine hidden size from model.config\")\n",
    "    return int(d)\n",
    "\n",
    "# =============================== ROBUST LOADER (fixes NoneType path errors) ===============================\n",
    "def _load_tok_and_model(baseline: str):\n",
    "    \"\"\"\n",
    "    Robustly load tokenizer + model.\n",
    "\n",
    "    For GPT-2 we prefer GPT2TokenizerFast and try both IDs:\n",
    "      - the user-provided `baseline`\n",
    "      - \"openai-community/gpt2\"\n",
    "      - \"gpt2\"\n",
    "\n",
    "    We also set:\n",
    "      - right padding\n",
    "      - pad_token = eos_token when missing (decoder-only models)\n",
    "    \"\"\"\n",
    "    cands: List[str] = []\n",
    "    seen = set()\n",
    "    for mid in [baseline, \"openai-community/gpt2\", \"gpt2\"]:\n",
    "        if \"gpt2\" in baseline.lower():\n",
    "            if mid not in seen:\n",
    "                cands.append(mid); seen.add(mid)\n",
    "    if not cands:\n",
    "        cands = [baseline]\n",
    "\n",
    "    last_err = None\n",
    "    for mid in cands:\n",
    "        try:\n",
    "            if \"gpt2\" in mid.lower():\n",
    "                tokzr = GPT2TokenizerFast.from_pretrained(mid, add_prefix_space=True)\n",
    "            else:\n",
    "                tokzr = AutoTokenizer.from_pretrained(mid, use_fast=True)\n",
    "            # right padding\n",
    "            if getattr(tokzr, \"padding_side\", None) != \"right\":\n",
    "                tokzr.padding_side = \"right\"\n",
    "            # pad token for GPT-like models\n",
    "            if tokzr.pad_token is None and getattr(tokzr, \"eos_token\", None) is not None:\n",
    "                tokzr.pad_token = tokzr.eos_token\n",
    "\n",
    "            model = AutoModel.from_pretrained(mid, output_hidden_states=True)\n",
    "            if getattr(model.config, \"pad_token_id\", None) is None and tokzr.pad_token_id is not None:\n",
    "                model.config.pad_token_id = tokzr.pad_token_id\n",
    "\n",
    "            return tokzr, model, mid\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            continue\n",
    "    raise RuntimeError(f\"Failed to load tokenizer/model for '{baseline}'. Tried {cands}. Last error: {last_err}\")\n",
    "\n",
    "# =============================== DATA: use existing head_dist column ===============================\n",
    "def load_head_dist_from_column(csv_path: str,\n",
    "                               head_dist_col: str = HEAD_DIST_COL,\n",
    "                               clamp: int = HEAD_DIST_CLAMP,\n",
    "                               include_zero: bool = INCLUDE_ZERO_CLASS):\n",
    "    \"\"\"\n",
    "    Expects CSV columns:\n",
    "      - sentence_id (str)\n",
    "      - tokens      (list[str]) — one row per sentence\n",
    "      - head_dist   (list[int]) — signed distances per token\n",
    "    Produces token-level rows with:\n",
    "      - 'head_dist_class' in {-clamp..-1, [0], 1..clamp}\n",
    "      - *drops the first token in each sentence* if EXCLUDE_FIRST_TOKEN is True\n",
    "    \"\"\"\n",
    "    need = [\"sentence_id\", \"tokens\", head_dist_col]\n",
    "    df = pd.read_csv(csv_path, usecols=need, dtype={\"sentence_id\": str})\n",
    "    df.tokens = df.tokens.apply(_to_list)\n",
    "    df[head_dist_col] = df[head_dist_col].apply(_to_list)\n",
    "\n",
    "    rows = []\n",
    "    for sid, toks, dists in df[[\"sentence_id\",\"tokens\", head_dist_col]].itertuples(index=False):\n",
    "        L = min(len(toks), len(dists))\n",
    "        for wid in range(L):\n",
    "            # --- Drop the FIRST token in each sentence (0-based index == 0) ---\n",
    "            if EXCLUDE_FIRST_TOKEN and wid == 0:\n",
    "                continue\n",
    "            try:\n",
    "                dist = int(dists[wid])\n",
    "            except Exception:\n",
    "                continue\n",
    "            if dist == 0 and not include_zero:\n",
    "                continue\n",
    "            if dist < -clamp: dist = -clamp\n",
    "            if dist >  clamp: dist =  clamp\n",
    "            rows.append((sid, wid, str(dist), toks[wid]))\n",
    "\n",
    "    df_tok  = pd.DataFrame(rows, columns=[\"sentence_id\",\"word_id\",\"head_dist_class\",\"word\"])\n",
    "\n",
    "    # Safety: enforce the filter even if the loop above changes in the future\n",
    "    if EXCLUDE_FIRST_TOKEN and not df_tok.empty:\n",
    "        df_tok = df_tok[df_tok.word_id != 0].reset_index(drop=True)\n",
    "\n",
    "    df_sent = df[[\"sentence_id\",\"tokens\"]].drop_duplicates(\"sentence_id\")\n",
    "    if df_tok.empty:\n",
    "        raise ValueError(\"No token rows constructed—recheck your CSV columns and EXCLUDE_FIRST_TOKEN setting.\")\n",
    "    return df_sent, df_tok\n",
    "\n",
    "def sample_raw(df_tok: pd.DataFrame, per_class_cap: int = RAW_MAX_PER_CLASS) -> pd.DataFrame:\n",
    "    picks = []\n",
    "    for c, sub in df_tok.groupby(\"head_dist_class\", sort=False):\n",
    "        n = min(len(sub), per_class_cap)\n",
    "        picks.append(sub.sample(n, random_state=RAND_SEED, replace=False))\n",
    "    return pd.concat(picks, ignore_index=True)\n",
    "\n",
    "def make_dist_palette(classes: List[str]) -> Dict[str, Tuple[float, float, float]]:\n",
    "    # KEEPING YOUR PALETTE EXACTLY: seaborn \"coolwarm\" spaced across classes\n",
    "    vals = sorted([int(c) for c in classes])\n",
    "    cmap = sns.color_palette(\"coolwarm\", len(vals))\n",
    "    return {str(v): cmap[i] for i, v in enumerate(vals)}\n",
    "\n",
    "# =============================== EMBEDDING (GPT‑2 & others) ===============================\n",
    "def embed_subset(df_sent: pd.DataFrame,\n",
    "                 subset_df: pd.DataFrame,\n",
    "                 baseline: str = BASELINE,\n",
    "                 word_rep_mode: str = WORD_REP_MODE,\n",
    "                 batch_size: int = BATCH_SIZE) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    df_sent[\"sentence_id\"]   = df_sent[\"sentence_id\"].astype(str)\n",
    "    subset_df[\"sentence_id\"] = subset_df[\"sentence_id\"].astype(str)\n",
    "\n",
    "    # sid -> list[(global_idx, word_id)]\n",
    "    by_sid: Dict[str, List[Tuple[int,int]]] = {}\n",
    "    for gidx, (sid, wid) in enumerate(subset_df[[\"sentence_id\",\"word_id\"]].itertuples(index=False)):\n",
    "        by_sid.setdefault(str(sid), []).append((gidx, int(wid)))\n",
    "\n",
    "    sids = list(by_sid.keys())\n",
    "    df_sel = (df_sent[df_sent.sentence_id.isin(sids)]\n",
    "              .drop_duplicates(\"sentence_id\")\n",
    "              .set_index(\"sentence_id\")\n",
    "              .loc[sids])\n",
    "\n",
    "    tokzr, model, model_id = _load_tok_and_model(baseline)\n",
    "    model = model.eval().to(device)\n",
    "    if device == \"cuda\":\n",
    "        model.half()\n",
    "\n",
    "    enc_kwargs = dict(is_split_into_words=True, return_tensors=\"pt\", padding=True)\n",
    "    # Use add_prefix_space when supported (GPT‑2-friendly)\n",
    "    if \"add_prefix_space\" in inspect.signature(tokzr.__call__).parameters:\n",
    "        enc_kwargs[\"add_prefix_space\"] = True\n",
    "\n",
    "    L = _num_hidden_layers(model) + 1   # include embedding layer\n",
    "    D = _hidden_size(model)\n",
    "    N = len(subset_df)\n",
    "\n",
    "    reps   = np.zeros((L, N, D), np.float16)\n",
    "    filled = np.zeros(N, dtype=bool)\n",
    "\n",
    "    with torch.no_grad(), torch.cuda.amp.autocast(device == \"cuda\"):\n",
    "        for start in tqdm(range(0, len(sids), batch_size), desc=f\"{model_id} (embed subset)\"):\n",
    "            batch_ids    = sids[start : start + batch_size]\n",
    "            batch_tokens = df_sel.loc[batch_ids, \"tokens\"].tolist()\n",
    "\n",
    "            enc_be = tokzr(batch_tokens, **enc_kwargs)\n",
    "            enc_t  = {k: v.to(device) for k, v in enc_be.items()}\n",
    "            out = model(**enc_t)\n",
    "            h = torch.stack(out.hidden_states).detach().cpu().numpy().astype(np.float32)  # (L,B,T,D)\n",
    "\n",
    "            for b, sid in enumerate(batch_ids):\n",
    "                # word_id -> token positions for this item\n",
    "                mp: Dict[int, List[int]] = {}\n",
    "                wids = enc_be.word_ids(b)  # requires a *fast* tokenizer\n",
    "                if wids is None:\n",
    "                    raise RuntimeError(\"Fast tokenizer required (word_ids unavailable).\")\n",
    "                for tidx, wid in enumerate(wids):\n",
    "                    if wid is not None:\n",
    "                        mp.setdefault(int(wid), []).append(int(tidx))\n",
    "\n",
    "                for gidx, wid in by_sid.get(sid, []):\n",
    "                    toks = mp.get(wid)\n",
    "                    if not toks:\n",
    "                        continue\n",
    "                    if word_rep_mode == \"first\":\n",
    "                        vec = h[:, b, toks[0], :]\n",
    "                    elif word_rep_mode == \"last\":\n",
    "                        vec = h[:, b, toks[-1], :]\n",
    "                    elif word_rep_mode == \"mean\":\n",
    "                        vec = h[:, b, toks, :].mean(axis=1)\n",
    "                    else:\n",
    "                        raise ValueError(\"WORD_REP_MODE must be one of {'first','last','mean'} (for GPT‑2 use 'last' or 'mean').\")\n",
    "                    reps[:, gidx, :] = vec.astype(np.float16, copy=False)\n",
    "                    filled[gidx] = True\n",
    "\n",
    "            del enc_be, enc_t, out, h\n",
    "            if device == \"cuda\": torch.cuda.empty_cache()\n",
    "\n",
    "    missing = int((~filled).sum())\n",
    "    if missing:\n",
    "        print(f\"⚠ Missing vectors for {missing} of {N} tokens\")\n",
    "    del model; gc.collect()\n",
    "    if device == \"cuda\": torch.cuda.empty_cache()\n",
    "    return reps, filled\n",
    "\n",
    "# =============================== BOOTSTRAP CORE ===============================\n",
    "def _bs_layer_loop(rep_sub: np.ndarray, M: int, n_reps: int, compute_once: Callable[[np.ndarray], float]):\n",
    "    L, N, D = rep_sub.shape\n",
    "    rng = np.random.default_rng(RAND_SEED)\n",
    "    A = np.full((n_reps, L), np.nan, np.float32)\n",
    "    for r in range(n_reps):\n",
    "        idx = rng.integers(0, N, size=M)\n",
    "        for l in range(L):\n",
    "            X = rep_sub[l, idx].astype(np.float32, copy=False)\n",
    "            try:\n",
    "                A[r, l] = float(compute_once(X))\n",
    "            except Exception:\n",
    "                A[r, l] = np.nan\n",
    "    mu = np.nanmean(A, axis=0).astype(np.float32)\n",
    "    lo = np.nanpercentile(A, 2.5, axis=0).astype(np.float32)\n",
    "    hi = np.nanpercentile(A, 97.5, axis=0).astype(np.float32)\n",
    "    return mu, lo, hi\n",
    "\n",
    "# =============================== METRICS ===============================\n",
    "# --- Isotropy (fast) ---\n",
    "def _iso_once(X: np.ndarray) -> float:\n",
    "    # If 'isoscore' package is not installed, use a safe monotone proxy\n",
    "    try:\n",
    "        from isoscore import IsoScore\n",
    "        return float(IsoScore.IsoScore(X))\n",
    "    except Exception:\n",
    "        lam = _eigvals_from_X(X)\n",
    "        if lam.size == 0: return np.nan\n",
    "        return float(np.clip(lam.mean() / (lam.max() + 1e-9), 0.0, 1.0))\n",
    "\n",
    "def _sf_once(X: np.ndarray) -> float:\n",
    "    lam = _eigvals_from_X(X)\n",
    "    if lam.size == 0: return np.nan\n",
    "    gm = np.exp(np.mean(np.log(lam + EPS)))\n",
    "    am = float(lam.mean() + EPS)\n",
    "    return float(gm / am)  # higher => flatter => more isotropic\n",
    "\n",
    "def _vmf_kappa_once(X: np.ndarray) -> float:\n",
    "    if X.shape[0] < 2: return np.nan\n",
    "    Xn = X / (np.linalg.norm(X, axis=1, keepdims=True) + 1e-9)\n",
    "    R = np.linalg.norm(Xn.mean(axis=0))\n",
    "    d = Xn.shape[1]\n",
    "    if R < 1e-9: return 0.0\n",
    "    return float(max(R * (d - R**2) / (1.0 - R**2 + 1e-9), 0.0))  # higher => more anisotropic\n",
    "\n",
    "def _spect_once(X: np.ndarray) -> float:\n",
    "    ev = np.linalg.eigvalsh(np.cov(X.T, ddof=0))\n",
    "    if ev.size == 0: return np.nan\n",
    "    return float(ev[-1] / (ev.mean() + 1e-9))\n",
    "\n",
    "def _rand_once(X: np.ndarray, K: int = 2000) -> float:\n",
    "    n = X.shape[0]\n",
    "    if n < 2: return np.nan\n",
    "    rng = np.random.default_rng(RAND_SEED)\n",
    "    K_eff = min(K, (n*(n-1))//2)\n",
    "    i = rng.integers(0, n, size=K_eff); j = rng.integers(0, n, size=K_eff)\n",
    "    same = (i == j)\n",
    "    if same.any(): j[same] = rng.integers(0, n, size=same.sum())\n",
    "    A, B = X[i], X[j]\n",
    "    num = np.einsum(\"ij,ij->i\", A, B)\n",
    "    den = (np.linalg.norm(A, axis=1)*np.linalg.norm(B, axis=1) + 1e-9)\n",
    "    return float(np.mean(np.abs(num/den)))\n",
    "\n",
    "# --- Linear ID (fast) ---\n",
    "def _pcaXX_once(X: np.ndarray, var_ratio: float) -> float:\n",
    "    lam = _eigvals_from_X(X)\n",
    "    if lam.size == 0: return np.nan\n",
    "    c = np.cumsum(lam); thr = c[-1] * var_ratio\n",
    "    return float(np.searchsorted(c, thr) + 1)\n",
    "\n",
    "def _pca95_once(X: np.ndarray) -> float: return _pcaXX_once(X, 0.95)\n",
    "def _pca99_once(X: np.ndarray) -> float: return _pcaXX_once(X, 0.99)\n",
    "\n",
    "def _erank_once(X: np.ndarray) -> float:\n",
    "    lam = _eigvals_from_X(X)\n",
    "    if lam.size == 0: return np.nan\n",
    "    p = lam / (lam.sum() + EPS)\n",
    "    H = -(p * np.log(p + EPS)).sum()\n",
    "    return float(np.exp(H))\n",
    "\n",
    "def _pr_once(X: np.ndarray) -> float:\n",
    "    lam = _eigvals_from_X(X)\n",
    "    if lam.size == 0: return np.nan\n",
    "    s1 = lam.sum(); s2 = (lam**2).sum()\n",
    "    return float((s1**2) / (s2 + EPS))\n",
    "\n",
    "def _stable_rank_once(X: np.ndarray) -> float:\n",
    "    lam = _eigvals_from_X(X)\n",
    "    if lam.size == 0: return np.nan\n",
    "    return float(lam.sum() / (lam.max() + EPS))\n",
    "\n",
    "# --- Non-linear (heavy) ---\n",
    "HAS_DADAPY = False\n",
    "try:\n",
    "    from dadapy import Data  # DADApy ID estimators (TwoNN, GRIDE)\n",
    "    HAS_DADAPY = True\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "def _dadapy_twonn_once(X: np.ndarray) -> float:\n",
    "    if not HAS_DADAPY: return np.nan\n",
    "    d = Data(coordinates=_jitter_unique(X))\n",
    "    id_est, _, _ = d.compute_id_2NN()\n",
    "    return float(id_est)\n",
    "\n",
    "def _dadapy_gride_once(X: np.ndarray) -> float:\n",
    "    if not HAS_DADAPY: return np.nan\n",
    "    d = Data(coordinates=_jitter_unique(X))\n",
    "    d.compute_distances(maxk=64)\n",
    "    ids, _, _ = d.return_id_scaling_gride(range_max=64)\n",
    "    return float(ids[-1])\n",
    "\n",
    "FAST_ONCE: Dict[str, Callable[[np.ndarray], float]] = {\n",
    "    # Isotropy\n",
    "    \"iso\": _iso_once, \"sf\": _sf_once, \"vmf_kappa\": _vmf_kappa_once,\n",
    "    \"spect\": _spect_once, \"rand\": _rand_once,\n",
    "    # Linear ID\n",
    "    \"pca95\": _pca95_once, \"pca99\": _pca99_once,\n",
    "    \"erank\": _erank_once, \"pr\": _pr_once, \"stable_rank\": _stable_rank_once,\n",
    "}\n",
    "HEAVY_ONCE: Dict[str, Callable[[np.ndarray], float] | None] = {\n",
    "    \"twonn\": _dadapy_twonn_once, \"gride\": _dadapy_gride_once,\n",
    "}\n",
    "\n",
    "LABELS = {\n",
    "    # Isotropy\n",
    "    \"iso\":\"IsoScore\", \"sf\":\"Spectral Flatness\",\n",
    "    \"vmf_kappa\":\"vMF κ (anisotropy↑)\", \"spect\":\"Spectral Ratio (λ_max/μ, anisotropy↑)\",\n",
    "    \"rand\":\"RandCos |μ| (anisotropy↑)\",\n",
    "    # Linear ID\n",
    "    \"pca95\":\"lPCA 0.95\", \"pca99\":\"lPCA 0.99\",\n",
    "    \"erank\":\"Effective Rank\",\"pr\":\"Participation Ratio\",\"stable_rank\":\"Stable Rank\",\n",
    "    # Non-linear\n",
    "    \"twonn\":\"TwoNN ID\",\"gride\":\"GRIDE\",\n",
    "}\n",
    "\n",
    "# Compute a compact set by default (tweak as needed)\n",
    "ALL_METRICS = [\"pca99\"]\n",
    "\n",
    "# =============================== SAVE / PLOT ===============================\n",
    "def save_metric_csv_all_classes(metric: str,\n",
    "                                class_to_stats: Dict[str, Dict[str, np.ndarray]],\n",
    "                                layers: np.ndarray,\n",
    "                                baseline: str,\n",
    "                                subset_name: str = \"raw\"):\n",
    "    rows = []\n",
    "    for c, stats in class_to_stats.items():\n",
    "        mu, lo, hi = stats[\"mean\"], stats.get(\"lo\"), stats.get(\"hi\")\n",
    "        for l, val in enumerate(mu):\n",
    "            rows.append({\n",
    "                \"subset\": subset_name, \"model\": baseline, \"feature\": \"head_dist\",\n",
    "                \"class\": c, \"metric\": metric, \"layer\": int(layers[l]),\n",
    "                \"mean\": float(val) if np.isfinite(val) else np.nan,\n",
    "                \"ci_low\": float(lo[l]) if isinstance(lo, np.ndarray) and np.isfinite(lo[l]) else np.nan,\n",
    "                \"ci_high\": float(hi[l]) if isinstance(hi, np.ndarray) and np.isfinite(hi[l]) else np.nan,\n",
    "                \"n_tokens\": int(stats.get(\"n\", 0)),\n",
    "                \"word_rep_mode\": WORD_REP_MODE,\n",
    "                \"source_csv\": Path(CSV_PATH).name,\n",
    "            })\n",
    "    df = pd.DataFrame(rows)\n",
    "    out = CSV_DIR / f\"headdist_{subset_name}_{metric}_{baseline}.csv\"\n",
    "    df.to_csv(out, index=False)\n",
    "\n",
    "def plot_metric_with_ci(class_to_stats: Dict[str, Dict[str, np.ndarray]],\n",
    "                        layers: np.ndarray, metric: str, title: str, out_path: Path,\n",
    "                        palette: Dict[str, Tuple[float, float, float]] | None = None):\n",
    "    plt.figure(figsize=(9, 5))\n",
    "    for c in sorted(class_to_stats.keys(), key=lambda s: int(s)):\n",
    "        stats = class_to_stats[c]\n",
    "        mu, lo, hi = stats[\"mean\"], stats.get(\"lo\"), stats.get(\"hi\")\n",
    "        if mu is None or np.all(np.isnan(mu)): continue\n",
    "        color = palette.get(c) if isinstance(palette, dict) else None\n",
    "        plt.plot(layers, mu, label=c, lw=1.8, color=color)\n",
    "        if isinstance(lo, np.ndarray) and isinstance(hi, np.ndarray) and not np.all(np.isnan(lo)):\n",
    "            plt.fill_between(layers, lo, hi, alpha=0.15, color=color)\n",
    "    plt.xlabel(\"Layer\"); plt.ylabel(LABELS.get(metric, metric.upper())); plt.title(title)\n",
    "    plt.legend(ncol=4, fontsize=\"small\", title=\"Head distance (−6 … 6)\", frameon=False)\n",
    "    plt.tight_layout(); plt.savefig(out_path, dpi=220); plt.close()\n",
    "\n",
    "# =============================== DRIVER ===============================\n",
    "def run_headdist_from_col_pipeline():\n",
    "    # 1) Load token lists + distance classes from existing column\n",
    "    df_sent, hd_df = load_head_dist_from_column(\n",
    "        CSV_PATH, head_dist_col=HEAD_DIST_COL,\n",
    "        clamp=HEAD_DIST_CLAMP, include_zero=INCLUDE_ZERO_CLASS\n",
    "    )\n",
    "    classes = sorted(hd_df.head_dist_class.unique(), key=lambda s: int(s))\n",
    "    palette = make_dist_palette(classes)\n",
    "    print(f\"✓ corpus ready — {len(hd_df):,} tokens across head-dist classes {classes}\")\n",
    "\n",
    "    # 2) Optional per-class cap (currently unlimited for fast metrics)\n",
    "    raw_df = sample_raw(hd_df, RAW_MAX_PER_CLASS)\n",
    "    print(\"Sample sizes per head distance (raw cap):\")\n",
    "    counts = raw_df.head_dist_class.value_counts()\n",
    "    counts = counts.reindex(sorted(counts.index, key=lambda x: int(x)))\n",
    "    print(counts.to_dict())\n",
    "    too_small = {c:int(n) for c,n in counts.items() if n < MIN_N_FOR_HEAVY_WARN}\n",
    "    if too_small:\n",
    "        print(f\"⚠ Some classes have < {MIN_N_FOR_HEAVY_WARN} tokens (heavy ID may be noisy): {too_small}\")\n",
    "\n",
    "    # 3) Embed once\n",
    "    reps, filled = embed_subset(df_sent, raw_df, BASELINE, WORD_REP_MODE, BATCH_SIZE)\n",
    "    raw_df = raw_df.reset_index(drop=True).loc[filled].reset_index(drop=True)\n",
    "    cls_arr = raw_df.head_dist_class.values\n",
    "    L = reps.shape[0]; layers = np.arange(L)\n",
    "    print(f\"✓ embedded {len(raw_df):,} tokens  • layers={L}\")\n",
    "\n",
    "    # 4) Metric loop\n",
    "    for metric in ALL_METRICS:\n",
    "        print(f\"\\n→ Computing metric: {metric} …\")\n",
    "        compute_once = FAST_ONCE.get(metric) or HEAVY_ONCE.get(metric)\n",
    "        if compute_once is None:\n",
    "            print(f\"  (skipping {metric}: estimator unavailable)\")\n",
    "            continue\n",
    "        n_bs = N_BOOTSTRAP_FAST if metric in FAST_ONCE else N_BOOTSTRAP_HEAVY\n",
    "        Mcap = FAST_BS_MAX_SAMP_PER_CLASS if metric in FAST_ONCE else HEAVY_BS_MAX_SAMP_PER_CLASS\n",
    "\n",
    "        class_results: Dict[str, Dict[str, np.ndarray]] = {}\n",
    "        for c in classes:\n",
    "            idx = np.where(cls_arr == c)[0]\n",
    "            if idx.size < 3:\n",
    "                continue\n",
    "            sub = reps[:, idx]  # (L, n_c, D)\n",
    "            Nc = sub.shape[1]\n",
    "            M = min(Mcap, Nc)\n",
    "            mu, lo, hi = _bs_layer_loop(sub, M, n_bs, compute_once)\n",
    "            class_results[c] = {\"mean\": mu, \"lo\": lo, \"hi\": hi, \"n\": int(Nc)}\n",
    "\n",
    "        save_metric_csv_all_classes(metric, class_results, layers, BASELINE, subset_name=\"raw\")\n",
    "        plot_metric_with_ci(class_results, layers, metric,\n",
    "                            title=f\"{LABELS.get(metric, metric.upper())} • {BASELINE}\",\n",
    "                            out_path=PLOT_DIR / f\"headdist_raw_{metric}_{BASELINE}.png\",\n",
    "                            palette=palette)\n",
    "        print(f\"  ✓ saved: CSV= {CSV_DIR}/headdist_raw_{metric}_{BASELINE}.csv  \"\n",
    "              f\"plot= {PLOT_DIR}/headdist_raw_{metric}_{BASELINE}.png\")\n",
    "\n",
    "        del class_results; gc.collect()\n",
    "        if device == \"cuda\": torch.cuda.empty_cache()\n",
    "\n",
    "    del reps; gc.collect()\n",
    "    if device == \"cuda\": torch.cuda.empty_cache()\n",
    "    print(\"\\n✓ done (incremental outputs produced per metric).\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_headdist_from_col_pipeline()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8fdabc-783a-4b44-9c49-c0c455ed5281",
   "metadata": {},
   "source": [
    "## Finegrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba2b5eb2-c828-4c16-a590-fb89de63f12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH      = \"en_ewt-ud-train_sentences.csv\"\n",
    "HEAD_DIST_COL = \"head_dist\"             # <-- your existing column with per-token distances\n",
    "BASELINE      = \"bert-base-uncased\"     # set to \"gpt2\" for GPT-2 family\n",
    "WORD_REP_MODE = \"first\"                 # BERT: {\"first\",\"last\",\"mean\"}; GPT-2: {\"last\",\"mean\"}\n",
    "\n",
    "POS_COL      = \"pos\"                    # column name in en_ewt-ud-train_sentences.csv\n",
    "KEEP_POS_TAG = \"NOUN\"                   # only keep tokens whose POS == \"NOUN\"\n",
    "\n",
    "# Sampling / bootstrap\n",
    "RAW_MAX_PER_CLASS              = int(1e12)  # no cap for fast metrics\n",
    "N_BOOTSTRAP_FAST               = 50\n",
    "N_BOOTSTRAP_HEAVY              = 200\n",
    "FAST_BS_MAX_SAMP_PER_CLASS     = int(1e12)  # M = N (classic bootstrap)\n",
    "HEAVY_BS_MAX_SAMP_PER_CLASS    = 5000       # practical for TwoNN/GRIDE/skdim\n",
    "MIN_N_FOR_HEAVY_WARN           = 1000       # warn if a class has fewer than this\n",
    "\n",
    "# Head-distance classes\n",
    "HEAD_DIST_CLAMP       = 6                  # keep classes within [-6,6]\n",
    "INCLUDE_ZERO_CLASS    = False              # set True if you also want \"0\" class\n",
    "\n",
    "# Misc\n",
    "RAND_SEED = 42\n",
    "PLOT_DIR  = Path(\"results_HEADDIST\"); PLOT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "CSV_DIR   = Path(\"tables_HEADDIST\") / \"headdist_bootstrap\"; CSV_DIR.mkdir(exist_ok=True, parents=True)\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# Repro & device\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "random.seed(RAND_SEED); np.random.seed(RAND_SEED); torch.manual_seed(RAND_SEED)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"cuda\": torch.backends.cudnn.benchmark = True\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "EPS = 1e-12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f08e5331-e623-4b30-8aaa-1907ce6a0852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================== HELPERS ===============================\n",
    "def _to_list(x):\n",
    "    # Turn a string like \"['a', 'b']\" into a real Python list\n",
    "    return ast.literal_eval(x) if isinstance(x, str) and x.startswith(\"[\") else x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e6b7bf5-c2a7-405d-be6f-1da96e10328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================== DATA: use existing head_dist column ===============================\n",
    "def load_head_dist_from_column(csv_path: str,\n",
    "                               head_dist_col: str = HEAD_DIST_COL,\n",
    "                               clamp: int = HEAD_DIST_CLAMP,\n",
    "                               include_zero: bool = INCLUDE_ZERO_CLASS,\n",
    "                               pos_col: str = POS_COL,\n",
    "                               keep_pos_tag: str = KEEP_POS_TAG):\n",
    "    \"\"\"\n",
    "    Expects CSV columns:\n",
    "      - sentence_id (str)\n",
    "      - tokens      (list[str]) — one row per sentence\n",
    "      - head_dist   (list[int]) — signed distances per token\n",
    "      - pos         (list[str]) — POS tags per token\n",
    "\n",
    "    Produces token-level rows with 'head_dist_class' in {-clamp..-1, [0], 1..clamp},\n",
    "    **restricted to tokens with POS == keep_pos_tag** (default: \"NOUN\").\n",
    "    \"\"\"\n",
    "    # We now also read the POS column\n",
    "    need = [\"sentence_id\", \"tokens\", head_dist_col, pos_col]\n",
    "    df = pd.read_csv(csv_path, usecols=need, dtype={\"sentence_id\": str})\n",
    "\n",
    "    # Convert stringified lists to actual Python lists\n",
    "    df.tokens         = df.tokens.apply(_to_list)\n",
    "    df[head_dist_col] = df[head_dist_col].apply(_to_list)\n",
    "    df[pos_col]       = df[pos_col].apply(_to_list)\n",
    "\n",
    "    rows = []\n",
    "    for sid, toks, dists, poss in df[[\"sentence_id\", \"tokens\", head_dist_col, pos_col]].itertuples(index=False):\n",
    "        # be safe if lengths differ\n",
    "        L = min(len(toks), len(dists), len(poss))\n",
    "        for wid in range(L):\n",
    "            pos_tag = poss[wid]\n",
    "\n",
    "            # *** POS FILTER: keep only NOUNs ***\n",
    "            if pos_tag != keep_pos_tag:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                dist = int(dists[wid])\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            if dist == 0 and not include_zero:\n",
    "                continue\n",
    "            if dist < -clamp:\n",
    "                dist = -clamp\n",
    "            if dist >  clamp:\n",
    "                dist =  clamp\n",
    "\n",
    "            rows.append((sid, wid, str(dist), toks[wid]))\n",
    "\n",
    "    df_tok  = pd.DataFrame(\n",
    "        rows,\n",
    "        columns=[\"sentence_id\",\"word_id\",\"head_dist_class\",\"word\"]\n",
    "    )\n",
    "    df_sent = df[[\"sentence_id\",\"tokens\"]].drop_duplicates(\"sentence_id\")\n",
    "\n",
    "    print(f\"✓ kept {len(df_tok):,} tokens with POS == {keep_pos_tag!r}\")\n",
    "    return df_sent, df_tok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e242f84-10f4-4f62-827b-68c18f96d554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_raw(df_tok: pd.DataFrame, per_class_cap: int = RAW_MAX_PER_CLASS) -> pd.DataFrame:\n",
    "    picks = []\n",
    "    for c, sub in df_tok.groupby(\"head_dist_class\", sort=False):\n",
    "        n = min(len(sub), per_class_cap)\n",
    "        picks.append(sub.sample(n, random_state=RAND_SEED, replace=False))\n",
    "    return pd.concat(picks, ignore_index=True)\n",
    "\n",
    "def make_dist_palette(classes: List[str]) -> Dict[str, Tuple[float, float, float]]:\n",
    "    vals = sorted([int(c) for c in classes])\n",
    "    cmap = sns.color_palette(\"coolwarm\", len(vals))\n",
    "    return {str(v): cmap[i] for i, v in enumerate(vals)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "403de4f6-38a7-44b4-9b86-7e1ccf9b830b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_METRICS=[   \"lpca99\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d80db17c-c688-4a98-8c76-9eaadf1d48cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ kept 32,299 tokens with POS == 'NOUN'\n",
      "✓ corpus ready — 32,299 tokens across head-dist classes ['-6', '-5', '-4', '-3', '-2', '-1', '1', '2', '3', '4', '5', '6']\n",
      "Sample sizes per head distance (raw cap):\n",
      "{'-6': 4000, '-5': 1882, '-4': 3138, '-3': 5790, '-2': 6275, '-1': 1213, '1': 4959, '2': 1706, '3': 1115, '4': 612, '5': 394, '6': 1215}\n",
      "⚠ Some classes have < 1000 tokens (heavy ID may be noisy): {'4': 612, '5': 394}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bert-base-uncased (embed subset):   5%|▎    | 465/9078 [00:03<01:08, 126.01it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 66\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m✓ done (incremental outputs produced per metric).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m     \u001b[43mrun_headdist_from_col_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 23\u001b[0m, in \u001b[0;36mrun_headdist_from_col_pipeline\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m⚠ Some classes have < \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMIN_N_FOR_HEAVY_WARN\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tokens (heavy ID may be noisy): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtoo_small\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# 3) Embed once\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m reps, filled \u001b[38;5;241m=\u001b[39m \u001b[43membed_subset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_sent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBASELINE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWORD_REP_MODE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m raw_df \u001b[38;5;241m=\u001b[39m raw_df\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mloc[filled]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     25\u001b[0m cls_arr \u001b[38;5;241m=\u001b[39m raw_df\u001b[38;5;241m.\u001b[39mhead_dist_class\u001b[38;5;241m.\u001b[39mvalues\n",
      "Cell \u001b[0;32mIn[4], line 183\u001b[0m, in \u001b[0;36membed_subset\u001b[0;34m(df_sent, subset_df, baseline, word_rep_mode, batch_size)\u001b[0m\n\u001b[1;32m    181\u001b[0m enc_be \u001b[38;5;241m=\u001b[39m tokzr(batch_tokens, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39menc_kwargs)\n\u001b[1;32m    182\u001b[0m enc_t  \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m enc_be\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m--> 183\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43menc_t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m h \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(out\u001b[38;5;241m.\u001b[39mhidden_states)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)  \u001b[38;5;66;03m# (L,B,T,D)\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b, sid \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch_ids):\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1000\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m    997\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m    998\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1000\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1013\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1014\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:650\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    646\u001b[0m     all_hidden_states \u001b[38;5;241m=\u001b[39m all_hidden_states \u001b[38;5;241m+\u001b[39m (hidden_states,)\n\u001b[1;32m    648\u001b[0m layer_head_mask \u001b[38;5;241m=\u001b[39m head_mask[i] \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 650\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[1;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    661\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    662\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/modeling_layers.py:94\u001b[0m, in \u001b[0;36mGradientCheckpointingLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning_once(message)\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:588\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, output_attentions, cache_position)\u001b[0m\n\u001b[1;32m    585\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    586\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m outputs \u001b[38;5;241m+\u001b[39m cross_attention_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add cross attentions if we output attention weights\u001b[39;00m\n\u001b[0;32m--> 588\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/pytorch_utils.py:257\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:597\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[1;32m    596\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[0;32m--> 597\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    598\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1769\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1766\u001b[0m             tracing_state\u001b[38;5;241m.\u001b[39mpop_scope()\n\u001b[1;32m   1767\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m-> 1769\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapped_call_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1770\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1771\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def run_headdist_from_col_pipeline():\n",
    "    # 1) Load token lists + distance classes from existing column\n",
    "    df_sent, hd_df = load_head_dist_from_column(\n",
    "        CSV_PATH, head_dist_col=HEAD_DIST_COL,\n",
    "        clamp=HEAD_DIST_CLAMP, include_zero=INCLUDE_ZERO_CLASS\n",
    "    )\n",
    "    classes = sorted(hd_df.head_dist_class.unique(), key=lambda s: int(s))\n",
    "    palette = make_dist_palette(classes)\n",
    "    print(f\"✓ corpus ready — {len(hd_df):,} tokens across head-dist classes {classes}\")\n",
    "\n",
    "    # 2) Optional per-class cap (currently unlimited for fast metrics)\n",
    "    raw_df = sample_raw(hd_df, RAW_MAX_PER_CLASS)\n",
    "    print(\"Sample sizes per head distance (raw cap):\")\n",
    "    counts = raw_df.head_dist_class.value_counts()\n",
    "    counts = counts.reindex(sorted(counts.index, key=lambda x: int(x)))\n",
    "    print(counts.to_dict())\n",
    "    # Warn if heavy estimators may be unreliable for small classes\n",
    "    too_small = {c:int(n) for c,n in counts.items() if n < MIN_N_FOR_HEAVY_WARN}\n",
    "    if too_small:\n",
    "        print(f\"⚠ Some classes have < {MIN_N_FOR_HEAVY_WARN} tokens (heavy ID may be noisy): {too_small}\")\n",
    "\n",
    "    # 3) Embed once\n",
    "    reps, filled = embed_subset(df_sent, raw_df, BASELINE, WORD_REP_MODE, BATCH_SIZE)\n",
    "    raw_df = raw_df.reset_index(drop=True).loc[filled].reset_index(drop=True)\n",
    "    cls_arr = raw_df.head_dist_class.values\n",
    "    L = reps.shape[0]; layers = np.arange(L)\n",
    "    print(f\"✓ embedded {len(raw_df):,} tokens  • layers={L}\")\n",
    "\n",
    "    # 4) Metric loop\n",
    "    for metric in ALL_METRICS:\n",
    "        print(f\"\\n→ Computing metric: {metric} …\")\n",
    "        compute_once = FAST_ONCE.get(metric) or HEAVY_ONCE.get(metric)\n",
    "        if compute_once is None:\n",
    "            print(f\"  (skipping {metric}: estimator unavailable)\")\n",
    "            continue\n",
    "        n_bs = N_BOOTSTRAP_FAST if metric in FAST_ONCE else N_BOOTSTRAP_HEAVY\n",
    "        Mcap = FAST_BS_MAX_SAMP_PER_CLASS if metric in FAST_ONCE else HEAVY_BS_MAX_SAMP_PER_CLASS\n",
    "\n",
    "        class_results: Dict[str, Dict[str, np.ndarray]] = {}\n",
    "        for c in classes:\n",
    "            idx = np.where(cls_arr == c)[0]\n",
    "            if idx.size < 3:\n",
    "                continue\n",
    "            sub = reps[:, idx]  # (L, n_c, D)\n",
    "            Nc = sub.shape[1]\n",
    "            M = min(Mcap, Nc)\n",
    "            mu, lo, hi = _bs_layer_loop(sub, M, n_bs, compute_once)\n",
    "            class_results[c] = {\"mean\": mu, \"lo\": lo, \"hi\": hi, \"n\": int(Nc)}\n",
    "\n",
    "        save_metric_csv_all_classes(metric, class_results, layers, BASELINE, subset_name=\"raw\")\n",
    "        plot_metric_with_ci(class_results, layers, metric,\n",
    "                            title=f\"{LABELS.get(metric, metric.upper())} • {BASELINE}\",\n",
    "                            out_path=PLOT_DIR / f\"headdist_raw_{metric}_{BASELINE}.png\",\n",
    "                            palette=palette)\n",
    "        print(f\"  ✓ saved: CSV= {CSV_DIR}/headdist_raw_{metric}_{BASELINE}.csv  \"\n",
    "              f\"plot= {PLOT_DIR}/headdist_raw_{metric}_{BASELINE}.png\")\n",
    "\n",
    "        del class_results; gc.collect()\n",
    "        if device == \"cuda\": torch.cuda.empty_cache()\n",
    "\n",
    "    del reps; gc.collect()\n",
    "    if device == \"cuda\": torch.cuda.empty_cache()\n",
    "    print(\"\\n✓ done (incremental outputs produced per metric).\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_headdist_from_col_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd58303b-2914-49b1-911a-568e9a8af4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ kept 32,299 tokens with POS == 'NOUN'\n",
      "✓ corpus ready — 32,299 tokens across head-dist classes ['-6', '-5', '-4', '-3', '-2', '-1', '1', '2', '3', '4', '5', '6']\n",
      "Sample sizes per head distance (raw cap):\n",
      "{'-6': 4000, '-5': 1882, '-4': 3138, '-3': 5790, '-2': 6275, '-1': 1213, '1': 4959, '2': 1706, '3': 1115, '4': 612, '5': 394, '6': 1215}\n",
      "⚠ Some classes have < 1000 tokens (heavy ID may be noisy): {'4': 612, '5': 394}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "openai-community/gpt2 (embed subset): 100%|█| 9078/9078 [01:16<00:00, 118.75it/s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 189\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m✓ done (incremental outputs produced per metric).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 189\u001b[0m     \u001b[43mrun_headdist_from_col_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 146\u001b[0m, in \u001b[0;36mrun_headdist_from_col_pipeline\u001b[0;34m()\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m⚠ Some classes have < \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMIN_N_FOR_HEAVY_WARN\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tokens (heavy ID may be noisy): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtoo_small\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# 3) Embed once\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m reps, filled \u001b[38;5;241m=\u001b[39m embed_subset(df_sent, raw_df, BASELINE, WORD_REP_MODE, BATCH_SIZE)\n\u001b[1;32m    147\u001b[0m raw_df \u001b[38;5;241m=\u001b[39m raw_df\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mloc[filled]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    148\u001b[0m cls_arr \u001b[38;5;241m=\u001b[39m raw_df\u001b[38;5;241m.\u001b[39mhead_dist_class\u001b[38;5;241m.\u001b[39mvalues\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "CSV_PATH      = \"en_ewt-ud-train_sentences.csv\"\n",
    "HEAD_DIST_COL = \"head_dist\"             # <-- your existing column with per-token distances\n",
    "BASELINE      = \"gpt2\"     # set to \"gpt2\" for GPT-2 family\n",
    "WORD_REP_MODE = \"last\"                 # BERT: {\"first\",\"last\",\"mean\"}; GPT-2: {\"last\",\"mean\"}\n",
    "\n",
    "POS_COL      = \"pos\"                    # column name in en_ewt-ud-train_sentences.csv\n",
    "KEEP_POS_TAG = \"NOUN\"                   # only keep tokens whose POS == \"NOUN\"\n",
    "\n",
    "# Sampling / bootstrap\n",
    "RAW_MAX_PER_CLASS              = int(1e12)  # no cap for fast metrics\n",
    "N_BOOTSTRAP_FAST               = 50\n",
    "N_BOOTSTRAP_HEAVY              = 200\n",
    "FAST_BS_MAX_SAMP_PER_CLASS     = int(1e12)  # M = N (classic bootstrap)\n",
    "HEAVY_BS_MAX_SAMP_PER_CLASS    = 5000       # practical for TwoNN/GRIDE/skdim\n",
    "MIN_N_FOR_HEAVY_WARN           = 1000       # warn if a class has fewer than this\n",
    "\n",
    "# Head-distance classes\n",
    "HEAD_DIST_CLAMP       = 6                  # keep classes within [-6,6]\n",
    "INCLUDE_ZERO_CLASS    = False              # set True if you also want \"0\" class\n",
    "\n",
    "# Misc\n",
    "RAND_SEED = 42\n",
    "PLOT_DIR  = Path(\"results_HEADDIST\"); PLOT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "CSV_DIR   = Path(\"tables_HEADDIST\") / \"headdist_bootstrap\"; CSV_DIR.mkdir(exist_ok=True, parents=True)\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# Repro & device\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "random.seed(RAND_SEED); np.random.seed(RAND_SEED); torch.manual_seed(RAND_SEED)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"cuda\": torch.backends.cudnn.benchmark = True\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "EPS = 1e-12\n",
    "\n",
    "\n",
    "\n",
    "# =============================== HELPERS ===============================\n",
    "def _to_list(x):\n",
    "    # Turn a string like \"['a', 'b']\" into a real Python list\n",
    "    return ast.literal_eval(x) if isinstance(x, str) and x.startswith(\"[\") else x\n",
    "\n",
    "\n",
    "\n",
    "# =============================== DATA: use existing head_dist column ===============================\n",
    "\n",
    "\n",
    "def load_head_dist_from_column(csv_path: str,\n",
    "                               head_dist_col: str = HEAD_DIST_COL,\n",
    "                               clamp: int = HEAD_DIST_CLAMP,\n",
    "                               include_zero: bool = INCLUDE_ZERO_CLASS,\n",
    "                               pos_col: str = POS_COL,\n",
    "                               keep_pos_tag: str = KEEP_POS_TAG):\n",
    "    \"\"\"\n",
    "    Expects CSV columns:\n",
    "      - sentence_id (str)\n",
    "      - tokens      (list[str]) — one row per sentence\n",
    "      - head_dist   (list[int]) — signed distances per token\n",
    "      - pos         (list[str]) — POS tags per token\n",
    "\n",
    "    Produces token-level rows with 'head_dist_class' in {-clamp..-1, [0], 1..clamp},\n",
    "    **restricted to tokens with POS == keep_pos_tag** (default: \"NOUN\").\n",
    "    \"\"\"\n",
    "    # We now also read the POS column\n",
    "    need = [\"sentence_id\", \"tokens\", head_dist_col, pos_col]\n",
    "    df = pd.read_csv(csv_path, usecols=need, dtype={\"sentence_id\": str})\n",
    "\n",
    "    # Convert stringified lists to actual Python lists\n",
    "    df.tokens         = df.tokens.apply(_to_list)\n",
    "    df[head_dist_col] = df[head_dist_col].apply(_to_list)\n",
    "    df[pos_col]       = df[pos_col].apply(_to_list)\n",
    "\n",
    "    rows = []\n",
    "    for sid, toks, dists, poss in df[[\"sentence_id\", \"tokens\", head_dist_col, pos_col]].itertuples(index=False):\n",
    "        # be safe if lengths differ\n",
    "        L = min(len(toks), len(dists), len(poss))\n",
    "        for wid in range(L):\n",
    "            pos_tag = poss[wid]\n",
    "\n",
    "            # *** POS FILTER: keep only NOUNs ***\n",
    "            if pos_tag != keep_pos_tag:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                dist = int(dists[wid])\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            if dist == 0 and not include_zero:\n",
    "                continue\n",
    "            if dist < -clamp:\n",
    "                dist = -clamp\n",
    "            if dist >  clamp:\n",
    "                dist =  clamp\n",
    "\n",
    "            rows.append((sid, wid, str(dist), toks[wid]))\n",
    "\n",
    "    df_tok  = pd.DataFrame(\n",
    "        rows,\n",
    "        columns=[\"sentence_id\",\"word_id\",\"head_dist_class\",\"word\"]\n",
    "    )\n",
    "    df_sent = df[[\"sentence_id\",\"tokens\"]].drop_duplicates(\"sentence_id\")\n",
    "\n",
    "    print(f\"✓ kept {len(df_tok):,} tokens with POS == {keep_pos_tag!r}\")\n",
    "    return df_sent, df_tok\n",
    "\n",
    "\n",
    "\n",
    "def sample_raw(df_tok: pd.DataFrame, per_class_cap: int = RAW_MAX_PER_CLASS) -> pd.DataFrame:\n",
    "    picks = []\n",
    "    for c, sub in df_tok.groupby(\"head_dist_class\", sort=False):\n",
    "        n = min(len(sub), per_class_cap)\n",
    "        picks.append(sub.sample(n, random_state=RAND_SEED, replace=False))\n",
    "    return pd.concat(picks, ignore_index=True)\n",
    "\n",
    "def make_dist_palette(classes: List[str]) -> Dict[str, Tuple[float, float, float]]:\n",
    "    vals = sorted([int(c) for c in classes])\n",
    "    cmap = sns.color_palette(\"coolwarm\", len(vals))\n",
    "    return {str(v): cmap[i] for i, v in enumerate(vals)}\n",
    "\n",
    "\n",
    "ALL_METRICS=[ \"pca99\"]\n",
    "def run_headdist_from_col_pipeline():\n",
    "    # 1) Load token lists + distance classes from existing column\n",
    "    df_sent, hd_df = load_head_dist_from_column(\n",
    "        CSV_PATH, head_dist_col=HEAD_DIST_COL,\n",
    "        clamp=HEAD_DIST_CLAMP, include_zero=INCLUDE_ZERO_CLASS\n",
    "    )\n",
    "    classes = sorted(hd_df.head_dist_class.unique(), key=lambda s: int(s))\n",
    "    palette = make_dist_palette(classes)\n",
    "    print(f\"✓ corpus ready — {len(hd_df):,} tokens across head-dist classes {classes}\")\n",
    "\n",
    "    # 2) Optional per-class cap (currently unlimited for fast metrics)\n",
    "    raw_df = sample_raw(hd_df, RAW_MAX_PER_CLASS)\n",
    "    print(\"Sample sizes per head distance (raw cap):\")\n",
    "    counts = raw_df.head_dist_class.value_counts()\n",
    "    counts = counts.reindex(sorted(counts.index, key=lambda x: int(x)))\n",
    "    print(counts.to_dict())\n",
    "    # Warn if heavy estimators may be unreliable for small classes\n",
    "    too_small = {c:int(n) for c,n in counts.items() if n < MIN_N_FOR_HEAVY_WARN}\n",
    "    if too_small:\n",
    "        print(f\"⚠ Some classes have < {MIN_N_FOR_HEAVY_WARN} tokens (heavy ID may be noisy): {too_small}\")\n",
    "\n",
    "    # 3) Embed once\n",
    "    reps, filled = embed_subset(df_sent, raw_df, BASELINE, WORD_REP_MODE, BATCH_SIZE)\n",
    "    raw_df = raw_df.reset_index(drop=True).loc[filled].reset_index(drop=True)\n",
    "    cls_arr = raw_df.head_dist_class.values\n",
    "    L = reps.shape[0]; layers = np.arange(L)\n",
    "    print(f\"✓ embedded {len(raw_df):,} tokens  • layers={L}\")\n",
    "\n",
    "    # 4) Metric loop\n",
    "    for metric in ALL_METRICS:\n",
    "        print(f\"\\n→ Computing metric: {metric} …\")\n",
    "        compute_once = FAST_ONCE.get(metric) or HEAVY_ONCE.get(metric)\n",
    "        if compute_once is None:\n",
    "            print(f\"  (skipping {metric}: estimator unavailable)\")\n",
    "            continue\n",
    "        n_bs = N_BOOTSTRAP_FAST if metric in FAST_ONCE else N_BOOTSTRAP_HEAVY\n",
    "        Mcap = FAST_BS_MAX_SAMP_PER_CLASS if metric in FAST_ONCE else HEAVY_BS_MAX_SAMP_PER_CLASS\n",
    "\n",
    "        class_results: Dict[str, Dict[str, np.ndarray]] = {}\n",
    "        for c in classes:\n",
    "            idx = np.where(cls_arr == c)[0]\n",
    "            if idx.size < 3:\n",
    "                continue\n",
    "            sub = reps[:, idx]  # (L, n_c, D)\n",
    "            Nc = sub.shape[1]\n",
    "            M = min(Mcap, Nc)\n",
    "            mu, lo, hi = _bs_layer_loop(sub, M, n_bs, compute_once)\n",
    "            class_results[c] = {\"mean\": mu, \"lo\": lo, \"hi\": hi, \"n\": int(Nc)}\n",
    "\n",
    "        save_metric_csv_all_classes(metric, class_results, layers, BASELINE, subset_name=\"raw\")\n",
    "        plot_metric_with_ci(class_results, layers, metric,\n",
    "                            title=f\"{LABELS.get(metric, metric.upper())} • {BASELINE}\",\n",
    "                            out_path=PLOT_DIR / f\"headdist_raw_{metric}_{BASELINE}.png\",\n",
    "                            palette=palette)\n",
    "        print(f\"  ✓ saved: CSV= {CSV_DIR}/headdist_raw_{metric}_{BASELINE}.csv  \"\n",
    "              f\"plot= {PLOT_DIR}/headdist_raw_{metric}_{BASELINE}.png\")\n",
    "\n",
    "        del class_results; gc.collect()\n",
    "        if device == \"cuda\": torch.cuda.empty_cache()\n",
    "\n",
    "    del reps; gc.collect()\n",
    "    if device == \"cuda\": torch.cuda.empty_cache()\n",
    "    print(\"\\n✓ done (incremental outputs produced per metric).\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_headdist_from_col_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcca4af3-f10e-4818-8ca6-26e05fccb7f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7613dfad-afc2-49ec-82e1-1c26a0a7b1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ kept 31,997 tokens with POS == 'NOUN' and word_id > 0\n",
      "✓ corpus ready — 31,997 tokens across head-dist classes ['-6', '-5', '-4', '-3', '-2', '-1', '1', '2', '3', '4', '5', '6']\n",
      "Sample sizes per head distance (raw cap):\n",
      "{'-6': 4000, '-5': 1882, '-4': 3138, '-3': 5790, '-2': 6275, '-1': 1213, '1': 4846, '2': 1650, '3': 1073, '4': 585, '5': 378, '6': 1167}\n",
      "⚠ Some classes have < 1000 tokens (heavy ID may be noisy): {'4': 585, '5': 378}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "openai-community/gpt2 (embed subset): 100%|█| 9052/9052 [01:15<00:00, 120.59it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ embedded 31,997 tokens  • layers=13\n",
      "\n",
      "→ Computing metric: pca99 …\n",
      "  ✓ saved: CSV= tables_HEADDIST/headdist_bootstrap/headdist_raw_pca99_gpt2.csv  plot= results_HEADDIST/headdist_raw_pca99_gpt2.png\n",
      "\n",
      "✓ done (incremental outputs produced per metric).\n"
     ]
    }
   ],
   "source": [
    "CSV_PATH      = \"en_ewt-ud-train_sentences.csv\"\n",
    "HEAD_DIST_COL = \"head_dist\"             # <-- your existing column with per-token distances\n",
    "BASELINE      = \"gpt2\"                  # set to \"gpt2\" for GPT-2 family\n",
    "WORD_REP_MODE = \"last\"                  # BERT: {\"first\",\"last\",\"mean\"}; GPT-2: {\"last\",\"mean\"}\n",
    "\n",
    "POS_COL      = \"pos\"                    # column name in en_ewt-ud-train_sentences.csv\n",
    "KEEP_POS_TAG = \"NOUN\"                   # only keep tokens whose POS == \"NOUN\"\n",
    "\n",
    "# Sampling / bootstrap\n",
    "RAW_MAX_PER_CLASS              = int(1e12)  # no cap for fast metrics\n",
    "N_BOOTSTRAP_FAST               = 50\n",
    "N_BOOTSTRAP_HEAVY              = 200\n",
    "FAST_BS_MAX_SAMP_PER_CLASS     = int(1e12)  # M = N (classic bootstrap)\n",
    "HEAVY_BS_MAX_SAMP_PER_CLASS    = 5000       # practical for TwoNN/GRIDE/skdim\n",
    "MIN_N_FOR_HEAVY_WARN           = 1000       # warn if a class has fewer than this\n",
    "\n",
    "# Head-distance classes\n",
    "HEAD_DIST_CLAMP       = 6                  # keep classes within [-6,6]\n",
    "INCLUDE_ZERO_CLASS    = False              # set True if you also want \"0\" class\n",
    "\n",
    "# Misc\n",
    "RAND_SEED = 42\n",
    "PLOT_DIR  = Path(\"results_HEADDIST\"); PLOT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "CSV_DIR   = Path(\"tables_HEADDIST\") / \"headdist_bootstrap\"; CSV_DIR.mkdir(exist_ok=True, parents=True)\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# Repro & device\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "random.seed(RAND_SEED); np.random.seed(RAND_SEED); torch.manual_seed(RAND_SEED)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"cuda\": torch.backends.cudnn.benchmark = True\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "EPS = 1e-12\n",
    "\n",
    "# =============================== HELPERS ===============================\n",
    "def _to_list(x):\n",
    "    # Turn a string like \"['a', 'b']\" into a real Python list\n",
    "    return ast.literal_eval(x) if isinstance(x, str) and x.startswith(\"[\") else x\n",
    "\n",
    "# =============================== DATA: use existing head_dist column ===============================\n",
    "def load_head_dist_from_column(csv_path: str,\n",
    "                               head_dist_col: str = HEAD_DIST_COL,\n",
    "                               clamp: int = HEAD_DIST_CLAMP,\n",
    "                               include_zero: bool = INCLUDE_ZERO_CLASS,\n",
    "                               pos_col: str = POS_COL,\n",
    "                               keep_pos_tag: str = KEEP_POS_TAG):\n",
    "    \"\"\"\n",
    "    Expects CSV columns:\n",
    "      - sentence_id (str)\n",
    "      - tokens      (list[str]) — one row per sentence\n",
    "      - head_dist   (list[int]) — signed distances per token\n",
    "      - pos         (list[str]) — POS tags per token\n",
    "\n",
    "    Produces token-level rows with 'head_dist_class' in {-clamp..-1, [0], 1..clamp},\n",
    "    restricted to tokens with POS == keep_pos_tag (default: \"NOUN\"),\n",
    "    and **excluding tokens at sentence position 0**.\n",
    "    \"\"\"\n",
    "    # We now also read the POS column\n",
    "    need = [\"sentence_id\", \"tokens\", head_dist_col, pos_col]\n",
    "    df = pd.read_csv(csv_path, usecols=need, dtype={\"sentence_id\": str})\n",
    "\n",
    "    # Convert stringified lists to actual Python lists\n",
    "    df.tokens         = df.tokens.apply(_to_list)\n",
    "    df[head_dist_col] = df[head_dist_col].apply(_to_list)\n",
    "    df[pos_col]       = df[pos_col].apply(_to_list)\n",
    "\n",
    "    rows = []\n",
    "    for sid, toks, dists, poss in df[[\"sentence_id\", \"tokens\", head_dist_col, pos_col]].itertuples(index=False):\n",
    "        # be safe if lengths differ\n",
    "        L = min(len(toks), len(dists), len(poss))\n",
    "        for wid in range(L):\n",
    "            # --- NEW FILTER: ignore first token in each sentence ---\n",
    "            if wid == 0:                      # <<< NEW: skip first token\n",
    "                continue\n",
    "\n",
    "            pos_tag = poss[wid]\n",
    "\n",
    "            # POS FILTER: keep only NOUNs\n",
    "            if pos_tag != keep_pos_tag:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                dist = int(dists[wid])\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            if dist == 0 and not include_zero:\n",
    "                continue\n",
    "            if dist < -clamp:\n",
    "                dist = -clamp\n",
    "            if dist >  clamp:\n",
    "                dist =  clamp\n",
    "\n",
    "            rows.append((sid, wid, str(dist), toks[wid]))\n",
    "\n",
    "    df_tok  = pd.DataFrame(\n",
    "        rows,\n",
    "        columns=[\"sentence_id\",\"word_id\",\"head_dist_class\",\"word\"]\n",
    "    )\n",
    "    df_sent = df[[\"sentence_id\",\"tokens\"]].drop_duplicates(\"sentence_id\")\n",
    "\n",
    "    print(f\"✓ kept {len(df_tok):,} tokens with POS == {keep_pos_tag!r} and word_id > 0\")\n",
    "    return df_sent, df_tok\n",
    "\n",
    "def sample_raw(df_tok: pd.DataFrame, per_class_cap: int = RAW_MAX_PER_CLASS) -> pd.DataFrame:\n",
    "    picks = []\n",
    "    for c, sub in df_tok.groupby(\"head_dist_class\", sort=False):\n",
    "        n = min(len(sub), per_class_cap)\n",
    "        picks.append(sub.sample(n, random_state=RAND_SEED, replace=False))\n",
    "    return pd.concat(picks, ignore_index=True)\n",
    "\n",
    "def make_dist_palette(classes: List[str]) -> Dict[str, Tuple[float, float, float]]:\n",
    "    vals = sorted([int(c) for c in classes])\n",
    "    cmap = sns.color_palette(\"coolwarm\", len(vals))\n",
    "    return {str(v): cmap[i] for i, v in enumerate(vals)}\n",
    "\n",
    "ALL_METRICS = [ \"pca99\"]\n",
    "\n",
    "def run_headdist_from_col_pipeline():\n",
    "    # 1) Load token lists + distance classes from existing column\n",
    "    df_sent, hd_df = load_head_dist_from_column(\n",
    "        CSV_PATH, head_dist_col=HEAD_DIST_COL,\n",
    "        clamp=HEAD_DIST_CLAMP, include_zero=INCLUDE_ZERO_CLASS\n",
    "    )\n",
    "    classes = sorted(hd_df.head_dist_class.unique(), key=lambda s: int(s))\n",
    "    palette = make_dist_palette(classes)\n",
    "    print(f\"✓ corpus ready — {len(hd_df):,} tokens across head-dist classes {classes}\")\n",
    "\n",
    "    # 2) Optional per-class cap (currently unlimited for fast metrics)\n",
    "    raw_df = sample_raw(hd_df, RAW_MAX_PER_CLASS)\n",
    "    print(\"Sample sizes per head distance (raw cap):\")\n",
    "    counts = raw_df.head_dist_class.value_counts()\n",
    "    counts = counts.reindex(sorted(counts.index, key=lambda x: int(x)))\n",
    "    print(counts.to_dict())\n",
    "    # Warn if heavy estimators may be unreliable for small classes\n",
    "    too_small = {c:int(n) for c,n in counts.items() if n < MIN_N_FOR_HEAVY_WARN}\n",
    "    if too_small:\n",
    "        print(f\"⚠ Some classes have < {MIN_N_FOR_HEAVY_WARN} tokens (heavy ID may be noisy): {too_small}\")\n",
    "\n",
    "    # 3) Embed once\n",
    "    reps, filled = embed_subset(df_sent, raw_df, BASELINE, WORD_REP_MODE, BATCH_SIZE)\n",
    "    raw_df = raw_df.reset_index(drop=True).loc[filled].reset_index(drop=True)\n",
    "    cls_arr = raw_df.head_dist_class.values\n",
    "    L = reps.shape[0]; layers = np.arange(L)\n",
    "    print(f\"✓ embedded {len(raw_df):,} tokens  • layers={L}\")\n",
    "\n",
    "    # 4) Metric loop\n",
    "    for metric in ALL_METRICS:\n",
    "        print(f\"\\n→ Computing metric: {metric} …\")\n",
    "        compute_once = FAST_ONCE.get(metric) or HEAVY_ONCE.get(metric)\n",
    "        if compute_once is None:\n",
    "            print(f\"  (skipping {metric}: estimator unavailable)\")\n",
    "            continue\n",
    "        n_bs = N_BOOTSTRAP_FAST if metric in FAST_ONCE else N_BOOTSTRAP_HEAVY\n",
    "        Mcap = FAST_BS_MAX_SAMP_PER_CLASS if metric in FAST_ONCE else HEAVY_BS_MAX_SAMP_PER_CLASS\n",
    "\n",
    "        class_results: Dict[str, Dict[str, np.ndarray]] = {}\n",
    "        for c in classes:\n",
    "            idx = np.where(cls_arr == c)[0]\n",
    "            if idx.size < 3:\n",
    "                continue\n",
    "            sub = reps[:, idx]  # (L, n_c, D)\n",
    "            Nc = sub.shape[1]\n",
    "            M = min(Mcap, Nc)\n",
    "            mu, lo, hi = _bs_layer_loop(sub, M, n_bs, compute_once)\n",
    "            class_results[c] = {\"mean\": mu, \"lo\": lo, \"hi\": hi, \"n\": int(Nc)}\n",
    "\n",
    "        save_metric_csv_all_classes(metric, class_results, layers, BASELINE, subset_name=\"raw\")\n",
    "        plot_metric_with_ci(class_results, layers, metric,\n",
    "                            title=f\"{LABELS.get(metric, metric.upper())} • {BASELINE}\",\n",
    "                            out_path=PLOT_DIR / f\"headdist_raw_{metric}_{BASELINE}.png\",\n",
    "                            palette=palette)\n",
    "        print(f\"  ✓ saved: CSV= {CSV_DIR}/headdist_raw_{metric}_{BASELINE}.csv  \"\n",
    "              f\"plot= {PLOT_DIR}/headdist_raw_{metric}_{BASELINE}.png\")\n",
    "\n",
    "        del class_results; gc.collect()\n",
    "        if device == \"cuda\": torch.cuda.empty_cache()\n",
    "\n",
    "    del reps; gc.collect()\n",
    "    if device == \"cuda\": torch.cuda.empty_cache()\n",
    "    print(\"\\n✓ done (incremental outputs produced per metric).\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_headdist_from_col_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f701fd2a-89c8-4227-b674-897c9ec646c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20835cf3-acef-48ef-af55-58beb9273424",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
